[{"num_versions": 11, "url_citation": null, "title": "Two-stream convolutional networks for action recognition in videos", "url": "http://papers.nips.cc/paper/5353-two-stream-convolutional-networks-for-action-recognition-in-videos", "url_versions": "http://scholar.google.com/scholar?cluster=582514008712420788&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "K Simonyan, A Zisserman - Advances in Neural Information  \u2026", "excerpt": "Abstract We investigate architectures of discriminatively trained deep Convolutional Networks (ConvNets) for action recognition in video. The challenge is to capture the complementary information on appearance from still frames and motion between frames.  ...", "url_pdf": null, "num_citations": 91, "cluster_id": "582514008712420788", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=582514008712420788&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Fast multi-class action recognition by querying inverted index tables", "url": "http://link.springer.com/article/10.1007/s11042-014-2207-8", "url_versions": null, "authors": "L Pei, M Ye, P Xu, T Li - Multimedia Tools and Applications", "excerpt": "Abstract A fast inverted index based algorithm is proposed for multi-class action recognition. This approach represents an action as a sequence of action states. Here, the action states are cluster centers of the extracted shape-motion features. At first, we compute the shape- ...", "url_pdf": null, "num_citations": 1, "cluster_id": "6873824000826738493", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=6873824000826738493&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Multi-scale deep learning for gesture detection and localization", "url": "http://link.springer.com/chapter/10.1007/978-3-319-16178-5_33", "url_versions": null, "authors": "N Neverova, C Wolf, GW Taylor, F Nebout - Computer Vision-ECCV", "excerpt": "Abstract We present a method for gesture detection and localization based on multi-scale and multi-modal deep learning. Each visual modality captures spatial information at a particular spatial scale (such as motion of the upper body or a hand), and the whole  ...", "url_pdf": null, "num_citations": 13, "cluster_id": "16452851648660801174", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=16452851648660801174&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "A multi-scale approach to gesture detection and recognition", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6755936", "url_versions": "http://scholar.google.com/scholar?cluster=6459998463353265953&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "N Neverova, C Wolf, G Paci\u2026 - \u2026  (ICCVW)", "excerpt": "Abstract We propose a generalized approach to human gesture recognition based on multiple data modalities such as depth video, articulated pose and speech. In our system, each gesture is decomposed into large-scale body motion and local subtle movements  ...", "url_pdf": null, "num_citations": 8, "cluster_id": "6459998463353265953", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=6459998463353265953&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Qualitative and Quantitative Spatio-temporal Relations in Daily Living Activity Recognition", "url": "http://link.springer.com/chapter/10.1007/978-3-319-16814-2_8", "url_versions": "http://scholar.google.com/scholar?cluster=9705207658587263130&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Tayyub, A Tavanai, Y Gatsoulis, AG Cohn\u2026 - Computer Vision--ACCV \u2026", "excerpt": "Abstract For the effective operation of intelligent assistive systems working in real-world human environments, it is important to be able to recognise human activities and their intentions. In this paper we propose a novel approach to activity recognition from visual  ...", "url_pdf": null, "num_citations": 0, "cluster_id": null, "year": "2015", "url_citations": null}, {"num_versions": 5, "url_citation": null, "title": "Deep Boltzmann machines as hierarchical generative models of perceptual inference in the cortex", "url": "http://scholar.google.com/https://www.era.lib.ed.ac.uk/handle/1842/8300", "url_versions": "http://scholar.google.com/scholar?cluster=686158087539479136&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "DP Reichert -", "excerpt": "The mammalian neocortex is integral to all aspects of cognition, in particular perception across all sensory modalities. Whether computational principles can be identified that would explain why the cortex is so versatile and capable of adapting to various inputs is not clear ...", "url_pdf": null, "num_citations": 3, "cluster_id": "686158087539479136", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=686158087539479136&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Learning motion-difference features using Gaussian restricted Boltzmann machines for efficient human action recognition", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6889945", "url_versions": "http://scholar.google.com/scholar?cluster=8057968167860085084&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "SN Tran, E Benetos\u2026 - Neural Networks (IJCNN),  \u2026", "excerpt": "Abstract\u2014Learning visual words from video frames is challenging because deciding which word to assign to each subset of frames is a difficult task. For example, two similar frames may have different meanings in describing human actions such as starting to run and  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "8057968167860085084", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=8057968167860085084&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "A review of unsupervised feature learning and deep learning for time-series modeling", "url": "http://www.sciencedirect.com/science/article/pii/S0167865514000221", "url_versions": "http://scholar.google.com/scholar?cluster=12474236712650393344&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "M L\u00e4ngkvist, L Karlsson, A Loutfi - Pattern Recognition Letters", "excerpt": "Abstract This paper gives a review of the recent developments in deep learning and unsupervised feature learning for time-series problems. While these techniques have shown promise for modeling static data, such as computer vision, applying them to time-series  ...", "url_pdf": null, "num_citations": 18, "cluster_id": "12474236712650393344", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=12474236712650393344&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "ModDrop: adaptive multi-modal gesture recognition", "url": "http://arxiv.org/abs/1501.00102", "url_versions": "http://scholar.google.com/scholar?cluster=6604307997666455908&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "N Neverova, C Wolf, GW Taylor, F Nebout - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: We present a method for gesture detection and localisation based on multi-scale and multi-modal deep learning. Each visual modality captures spatial information at a particular spatial scale (such as motion of the upper body or a hand), and the whole  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "6604307997666455908", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=6604307997666455908&as_sdt=2005&sciodt=1,5&hl=en"}]