[{"num_versions": 12, "url_citation": null, "title": "A two-stage pretraining algorithm for deep boltzmann machines", "url": "http://link.springer.com/chapter/10.1007/978-3-642-40728-4_14", "url_versions": "http://scholar.google.com/scholar?cluster=972406428643825884&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract A deep Boltzmann machine (DBM) is a recently introduced Markov random field model that has multiple layers of hidden units. It has been shown empirically that it is difficult to train a DBM with approximate maximum-likelihood learning using the stochastic  ...", "url_pdf": null, "num_citations": 9, "cluster_id": "972406428643825884", "authors": "KH Cho, T Raiko, A Ilin, J Karhunen - Artificial Neural Networks and  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=972406428643825884&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Metric-free natural gradient for joint-training of boltzmann machines", "url": "http://arxiv.org/abs/1301.3545", "url_versions": "http://scholar.google.com/scholar?cluster=5058021713135303817&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: This paper introduces the Metric-Free Natural Gradient (MFNG) algorithm for training Boltzmann Machines. Similar in spirit to the Hessian-Free method of Martens [8], our algorithm belongs to the family of truncated Newton methods and exploits an efficient  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "5058021713135303817", "authors": "G Desjardins, R Pascanu, A Courville\u2026 - arXiv preprint arXiv: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=5058021713135303817&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Techniques for learning binary stochastic feedforward neural networks", "url": "http://arxiv.org/abs/1406.2989", "url_versions": "http://scholar.google.com/scholar?cluster=12715165618838965768&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: Stochastic binary hidden units in a multi-layer perceptron (MLP) network give at least three potential benefits when compared to deterministic MLP networks.(1) They allow to learn one-to-many type of mappings.(2) They can be used in structured prediction  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "12715165618838965768", "authors": "T Raiko, M Berglund, G Alain, L Dinh - arXiv preprint arXiv:1406.2989", "url_citations": "http://scholar.google.com/scholar?cites=12715165618838965768&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 16, "url_citation": null, "title": "On the importance of initialization and momentum in deep learning", "url": "http://machinelearning.wustl.edu/mlpapers/papers/icml2013_sutskever13", "url_versions": "http://scholar.google.com/scholar?cluster=7449004388220998591&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent  ...", "url_pdf": null, "num_citations": 154, "cluster_id": "7449004388220998591", "authors": "I Sutskever, J Martens, G Dahl\u2026 - Proceedings of the  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=7449004388220998591&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 9, "url_citation": null, "title": "Efficient gradient-based inference through transformations between bayes nets and neural nets", "url": "http://arxiv.org/abs/1402.0480", "url_versions": "http://scholar.google.com/scholar?cluster=10247073116756532709&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: Hierarchical Bayesian networks and neural networks with stochastic hidden units are commonly perceived as two separate types of models. We show that either of these types of models can often be transformed into an instance of the other, by switching  ...", "url_pdf": null, "num_citations": 11, "cluster_id": "10247073116756532709", "authors": "DP Kingma, M Welling - arXiv preprint arXiv:1402.0480", "url_citations": "http://scholar.google.com/scholar?cites=10247073116756532709&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Understanding dropout: training multi-layer perceptrons with auxiliary independent stochastic neurons", "url": "http://link.springer.com/chapter/10.1007/978-3-642-42054-2_59", "url_versions": "http://scholar.google.com/scholar?cluster=3057498576713890562&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract In this paper, a simple, general method of adding auxiliary stochastic neurons to a multi-layer perceptron is proposed. It is shown that the proposed method is a generalization of recently successful methods of dropout [5], explicit noise injection [12, 3] and semantic  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "3057498576713890562", "authors": "KH Cho - Neural Information Processing", "url_citations": "http://scholar.google.com/scholar?cites=3057498576713890562&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "Deep learning of representations: Looking forward", "url": "http://link.springer.com/chapter/10.1007/978-3-642-39593-2_1", "url_versions": "http://scholar.google.com/scholar?cluster=16988628068303769209&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract Deep learning research aims at discovering learning algorithms that discover multiple levels of distributed representations, with higher levels representing more abstract concepts. Although the study of deep learning has already led to impressive theoretical  ...", "url_pdf": null, "num_citations": 86, "cluster_id": "16988628068303769209", "authors": "Y Bengio - Statistical Language and Speech Processing", "url_citations": "http://scholar.google.com/scholar?cites=16988628068303769209&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 14, "url_citation": null, "title": "Deep learning in neural networks: An overview", "url": "http://www.sciencedirect.com/science/article/pii/S0893608014002135", "url_versions": "http://scholar.google.com/scholar?cluster=15932869302045479284&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow  ...", "url_pdf": null, "num_citations": 143, "cluster_id": "15932869302045479284", "authors": "J Schmidhuber - Neural Networks", "url_citations": "http://scholar.google.com/scholar?cites=15932869302045479284&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Binary/ternary extreme learning machines", "url": "http://www.sciencedirect.com/science/article/pii/S0925231214011515", "url_versions": "http://scholar.google.com/scholar?cluster=7987491655188680789&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract In this paper, a new hidden layer construction method for Extreme Learning Machines (ELMs) is investigated, aimed at generating a diverse set of weights. The paper proposes two new ELM variants: Binary ELM, with a weight initialization scheme based on  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "7987491655188680789", "authors": "M van Heeswijk, Y Miche - Neurocomputing", "url_citations": "http://scholar.google.com/scholar?cites=7987491655188680789&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Training restricted Boltzmann machines", "url": "http://link.springer.com/article/10.1007/s13218-015-0371-2", "url_versions": "http://scholar.google.com/scholar?cluster=3674069441945345384&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract Restricted Boltzmann Machines (RBMs), two-layered probabilistic graphical models that can also be interpreted as feed forward neural networks, enjoy much popularity for pattern analysis and generation. Training RBMs however is challenging. It is based on  ...", "url_pdf": null, "num_citations": 0, "cluster_id": null, "authors": "A Fischer - KI-K\u00fcnstliche Intelligenz", "url_citations": null}, {"num_versions": 3, "url_citation": null, "title": "How to pretrain deep Boltzmann machines in two stages", "url": "http://link.springer.com/chapter/10.1007/978-3-319-09903-3_10", "url_versions": "http://scholar.google.com/scholar?cluster=13140522796839549304&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract A deep Boltzmann machine (DBM) is a recently introduced Markov random field model that has multiple layers of hidden units. It has been shown empirically that it is difficult to train a DBM with approximate maximum-likelihood learning using the stochastic  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "13140522796839549304", "authors": "K Cho, T Raiko, A Ilin, J Karhunen - Artificial Neural Networks", "url_citations": "http://scholar.google.com/scholar?cites=13140522796839549304&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Knowledge matters: Importance of prior information for optimization", "url": "http://arxiv.org/abs/1301.4083", "url_versions": "http://scholar.google.com/scholar?cluster=16555444433184520296&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans  ...", "url_pdf": null, "num_citations": 19, "cluster_id": "16555444433184520296", "authors": "\u00c7 G\u00fcl\u00e7ehre, Y Bengio - arXiv preprint arXiv:1301.4083", "url_citations": "http://scholar.google.com/scholar?cites=16555444433184520296&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "How to construct deep recurrent neural networks", "url": "http://arxiv.org/abs/1312.6026", "url_versions": "http://scholar.google.com/scholar?cluster=3032210598922213468&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: In this paper, we explore different ways to extend a recurrent neural network (RNN) to a\\ textit {deep} RNN. We start by arguing that the concept of depth in an RNN is not as clear as it is in feedforward neural networks. By carefully analyzing and understanding the  ...", "url_pdf": null, "num_citations": 56, "cluster_id": "3032210598922213468", "authors": "R Pascanu, C Gulcehre, K Cho, Y Bengio - arXiv preprint arXiv:1312.6026", "url_citations": "http://scholar.google.com/scholar?cites=3032210598922213468&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Simplifying convnets for fast learning", "url": "http://link.springer.com/chapter/10.1007/978-3-642-33266-1_8", "url_versions": "http://scholar.google.com/scholar?cluster=4078553365682617839&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract In this paper, we propose different strategies for simplifying filters, used as feature extractors, to be learnt in convolutional neural networks (ConvNets) in order to modify the hypothesis space, and to speed-up learning and processing times. We study two kinds of  ...", "url_pdf": null, "num_citations": 10, "cluster_id": "4078553365682617839", "authors": "F Mamalet, C Garcia - Artificial Neural Networks and Machine Learning\u2013 \u2026", "url_citations": "http://scholar.google.com/scholar?cites=4078553365682617839&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 33, "url_citation": null, "title": "Representation learning: A review and new perspectives", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6472238", "url_versions": "http://scholar.google.com/scholar?cluster=559463397382443088&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract\u2014The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the  ...", "url_pdf": null, "num_citations": 685, "cluster_id": "559463397382443088", "authors": "Y Bengio, A Courville, P Vincent - Pattern Analysis and  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=559463397382443088&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Two-Layer Contractive Encodings with Shortcuts for Semi-Supervised Learning", "url": "http://link.springer.com/chapter/10.1007/978-3-642-42054-2_56", "url_versions": "http://scholar.google.com/scholar?cluster=111736919423873179&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract Supervised training of multi-layer perceptrons (MLP) with only few labeled examples is prone to overfitting. Pretraining an MLP with unlabeled samples of the input distribution may achieve better generalization. Usually, pretraining is done in a layer-wise,  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "111736919423873179", "authors": "H Schulz, K Cho, T Raiko, S Behnke - Neural Information Processing", "url_citations": "http://scholar.google.com/scholar?cites=111736919423873179&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Artificial Adaptive Systems to predict the magnitude of earthquakes.", "url": "http://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=00066729&AN=109054286&h=qtz4mDt9egLYNHwmQvARGvCWggXVrKSEuqTJf20ASP8sFKu56XFOKJtw1IpENf0GiS%2FOYf%2FdAhTBASeUFMcalg%3D%3D&crl=c", "url_versions": null, "year": "2015", "excerpt": "Abstract Currently, in the geological studies it is clear that the generation process and the dynamics of development of an earthquake belong to the highly nonlinear and nonstationary phenomena. For this reason, in recent years the authors, experts in the development of  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "14013022311977607505", "authors": "PM Buscema, G Massini\u2026 - Bollettino di Geofisica  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=14013022311977607505&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "\u6df1\u5ea6\u5b66\u4e60\u7814\u7a76\u8fdb\u5c55", "url": "http://www.arocmag.com/getarticle/?aid=1f0573c7eced12e9", "url_versions": "http://scholar.google.com/scholar?cluster=9455047291083555200&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "\u6458\u8981: \u9274\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u91cd\u8981\u6027, \u7efc\u8ff0\u4e86\u6df1\u5ea6\u5b66\u4e60\u7684\u7814\u7a76\u8fdb\u5c55. \u9996\u5148\u6982\u8ff0\u4e86\u6df1\u5ea6\u5b66\u4e60\u5177\u6709\u7684\u4f18\u70b9, \u7531\u6b64\u8bf4\u660e\u4e86\u5f15\u5165\u6df1\u5ea6\u5b66\u4e60\u7684\u5fc5\u8981\u6027; \u7136\u540e\u63cf\u8ff0\u4e86\u4e09\u79cd\u5178\u578b\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b, \u5305\u62ec\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6a21\u578b, \u6df1\u5ea6\u4fe1\u4efb\u7f51\u7edc\u6a21\u578b\u548c\u5806\u6808\u81ea\u7f16\u7801\u7f51\u7edc\u6a21\u578b, \u5e76\u5bf9\u8fd1\u51e0\u5e74\u6df1\u5ea6\u5b66\u4e60\u5728\u521d ...", "url_pdf": null, "num_citations": 1, "cluster_id": "9455047291083555200", "authors": "\u5218\u5efa\u4f1f\uff0c \u5218\u5a9b\uff0c \u7f57\u96c4\u9e9f - \u8ba1\u7b97\u673a\u5e94\u7528\u7814\u7a76", "url_citations": "http://scholar.google.com/scholar?cites=9455047291083555200&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Two-layer contractive encodings for learning stable nonlinear features", "url": "http://www.sciencedirect.com/science/article/pii/S0893608014002184", "url_versions": "http://scholar.google.com/scholar?cluster=36102498469657671&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract Unsupervised learning of feature hierarchies is often a good strategy to initialize deep architectures for supervised learning. Most existing deep learning methods build these feature hierarchies layer by layer in a greedy fashion using either auto-encoders or  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "36102498469657671", "authors": "H Schulz, K Cho, T Raiko, S Behnke - Neural Networks", "url_citations": "http://scholar.google.com/scholar?cites=36102498469657671&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Deep learning using linear support vector machines", "url": "http://arxiv.org/abs/1306.0239", "url_versions": "http://scholar.google.com/scholar?cluster=15737743364903648230&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: Recently, fully-connected and convolutional neural networks have been trained to achieve state-of-the-art performance on a wide variety of tasks such as speech recognition, image classification, natural language processing, and bioinformatics. For classification  ...", "url_pdf": null, "num_citations": 32, "cluster_id": "15737743364903648230", "authors": "Y Tang - arXiv preprint arXiv:1306.0239", "url_citations": "http://scholar.google.com/scholar?cites=15737743364903648230&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Practical recommendations for gradient-based training of deep architectures", "url": "http://link.springer.com/chapter/10.1007/978-3-642-35289-8_26", "url_versions": "http://scholar.google.com/scholar?cluster=13214514639523956782&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract Learning algorithms related to artificial neural networks and in particular for Deep Learning may seem to involve many bells and whistles, called hyper-parameters. This chapter is meant as a practical guide with recommendations for some of the most  ...", "url_pdf": null, "num_citations": 91, "cluster_id": "13214514639523956782", "authors": "Y Bengio - Neural Networks: Tricks of the Trade", "url_citations": "http://scholar.google.com/scholar?cites=13214514639523956782&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Online Machine Learning Algorithms For Currency Exchange Prediction", "url": "http://scholar.google.com/https://ftp.cs.nyu.edu/web/Research/TechReports/TR2013-953/TR2013-953.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=748039166205286549&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract Using Machine Learning Algorithms to analyze and predict security price patterns is an area of active interest. Most practical stock traders combine computational tools with their intuitions and knowledge to make decisions. This technical report describes methods for  ...", "url_pdf": "http://scholar.google.com/https://ftp.cs.nyu.edu/web/Research/TechReports/TR2013-953/TR2013-953.pdf", "num_citations": 1, "cluster_id": "748039166205286549", "authors": "E Soulas, D Shasha -", "url_citations": "http://scholar.google.com/scholar?cites=748039166205286549&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Training Very Deep Networks", "url": "http://arxiv.org/abs/1507.06228", "url_versions": null, "year": "2015", "excerpt": "Abstract: Theoretical and empirical evidence indicates that the depth of neural networks is crucial for their success. However, training becomes more difficult as depth increases, and training of very deep networks remains an open problem. Here we introduce a new  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "14374917385640982609", "authors": "RK Srivastava, K Greff, J Schmidhuber - arXiv preprint arXiv:1507.06228", "url_citations": "http://scholar.google.com/scholar?cites=14374917385640982609&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Expected energy-based restricted Boltzmann machine for classification", "url": "http://www.sciencedirect.com/science/article/pii/S0893608014002160", "url_versions": "http://scholar.google.com/scholar?cluster=15766943526633585756&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract In classification tasks, restricted Boltzmann machines (RBMs) have predominantly been used in the first stage, either as feature extractors or to provide initialization of neural networks. In this study, we propose a discriminative learning approach to provide a self- ...", "url_pdf": null, "num_citations": 1, "cluster_id": "15766943526633585756", "authors": "S Elfwing, E Uchibe, K Doya - Neural Networks", "url_citations": "http://scholar.google.com/scholar?cites=15766943526633585756&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Pushing stochastic gradient towards second-order methods\u2013backpropagation learning with transformations in nonlinearities", "url": "http://link.springer.com/chapter/10.1007/978-3-642-42054-2_55", "url_versions": "http://scholar.google.com/scholar?cluster=1599591192775745677&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract Recently, we proposed to transform the outputs of each hidden neuron in a multi-layer perceptron network to have zero output and zero slope on average, and use separate shortcut connections to model the linear dependencies instead. We continue the work by  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "1599591192775745677", "authors": "T Vatanen, T Raiko, H Valpola, Y LeCun - Neural Information Processing", "url_citations": "http://scholar.google.com/scholar?cites=1599591192775745677&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Mean-normalized stochastic gradient for large-scale deep learning", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6853582", "url_versions": "http://scholar.google.com/scholar?cluster=856138149399481455&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "ABSTRACT Deep neural networks are typically optimized with stochastic gradient descent (SGD). In this work, we propose a novel second-order stochastic optimization algorithm. The algorithm is based on analytic results showing that a non-zero mean of features is harmful  ...", "url_pdf": null, "num_citations": 13, "cluster_id": "856138149399481455", "authors": "S Wiesler, A Richard, R Schluter\u2026 - Acoustics, Speech and  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=856138149399481455&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Denoising autoencoder with modulated lateral connections learns invariant representations of natural images", "url": "http://arxiv.org/abs/1412.7210", "url_versions": "http://scholar.google.com/scholar?cluster=8795030311867440644&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: This paper demonstrates that suitable lateral connections between encoder and decoder allow higher layers of a deep denoising autoencoder to focus on representing invariant features. Without the lateral connections, the deep autoencoder has to carry  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "8795030311867440644", "authors": "A Rasmus, T Raiko, H Valpola - arXiv preprint arXiv:1412.7210", "url_citations": "http://scholar.google.com/scholar?cites=8795030311867440644&as_sdt=2005&sciodt=1,5&hl=en"}]