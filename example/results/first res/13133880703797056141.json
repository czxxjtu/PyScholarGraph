[{"num_versions": 0, "url_citation": null, "title": "Pointer networks", "url": "http://arxiv.org/abs/1506.03134", "url_versions": null, "authors": "O Vinyals, M Fortunato, N Jaitly - arXiv preprint arXiv:1506.03134", "excerpt": "Abstract: We introduce a new neural architecture to learn the conditional probability of an output sequence with elements that are discrete tokens corresponding to positions in an input sequence. Such problems cannot be trivially addressed by existent approaches  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "15940812059199267567", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=15940812059199267567&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Long Short-Term Memory Over Tree Structures", "url": "http://arxiv.org/abs/1503.04881", "url_versions": "http://scholar.google.com/scholar?cluster=14670708350344342798&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "X Zhu, P Sobhani, H Guo - arXiv preprint arXiv:1503.04881", "excerpt": "Abstract: The chain-structured long short-term memory (LSTM) has showed to be effective in a wide range of problems such as speech recognition and machine translation. In this paper, we propose to extend it to tree structures, in which a memory cell can reflect the history  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "14670708350344342798", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=14670708350344342798&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "DRAW: A recurrent neural network for image generation", "url": "http://arxiv.org/abs/1502.04623", "url_versions": "http://scholar.google.com/scholar?cluster=8022513888710268841&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "K Gregor, I Danihelka, A Graves, D Wierstra - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto- ...", "url_pdf": null, "num_citations": 26, "cluster_id": "8022513888710268841", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=8022513888710268841&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Investigations on phrase-based decoding with recurrent neural network language and translation models", "url": "http://www.aclweb.org/anthology/W/W15/W15-30.pdf#page=314", "url_versions": null, "authors": "T Alkhouli, F Rietig, H Ney - EMNLP", "excerpt": "Abstract This work explores the application of recurrent neural network (RNN) language and translation models during phrasebased decoding. Due to their use of unbounded context, the decoder integration of RNNs is more challenging compared to the integration of  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "13885641634164931179", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=13885641634164931179&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Multi-task learning for multiple language translation", "url": "http://www.anthology.aclweb.org/P/P15/P15-1166.pdf", "url_versions": null, "authors": "D Dong, H Wu, W He, D Yu, H Wang -", "excerpt": "Abstract In this paper, we investigate the problem of learning a machine translation model that can simultaneously translate sentences from one source language to multiple target languages. Our solution is inspired by the recently proposed neural machine translation  ...", "url_pdf": "http://www.anthology.aclweb.org/P/P15/P15-1166.pdf", "num_citations": 1, "cluster_id": "6980356795259585193", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=6980356795259585193&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Video description generation incorporating spatio-temporal features and a soft-attention mechanism", "url": "http://arxiv.org/abs/1502.08029", "url_versions": "http://scholar.google.com/scholar?cluster=8761564837485893612&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "L Yao, A Torabi, K Cho, N Ballas, C Pal\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Recent progress in using recurrent neural networks (RNNs) for image description has motivated us to explore the application of RNNs to video description. Recent work has also suggested that attention mechanisms may be able to increase performance. To this  ...", "url_pdf": null, "num_citations": 9, "cluster_id": "8761564837485893612", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=8761564837485893612&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Recurrent neural network regularization", "url": "http://arxiv.org/abs/1409.2329", "url_versions": "http://scholar.google.com/scholar?cluster=7960835754314140335&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "W Zaremba, I Sutskever, O Vinyals - arXiv preprint arXiv:1409.2329", "excerpt": "Abstract: We present a simple regularization technique for Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM) units. Dropout, the most successful technique for regularizing neural networks, does not work well with RNNs and LSTMs. In this paper,  ...", "url_pdf": null, "num_citations": 30, "cluster_id": "7960835754314140335", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=7960835754314140335&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Unsupervised learning of video representations using lstms", "url": "http://arxiv.org/abs/1502.04681", "url_versions": "http://scholar.google.com/scholar?cluster=6890473943204323716&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "N Srivastava, E Mansimov, R Salakhutdinov - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: We use multilayer Long Short Term Memory (LSTM) networks to learn representations of video sequences. Our model uses an encoder LSTM to map an input sequence into a fixed length representation. This representation is decoded using single  ...", "url_pdf": null, "num_citations": 22, "cluster_id": "6890473943204323716", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=6890473943204323716&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Addressing the Rare Word Problem in Neural Machine Translation", "url": "http://arxiv.org/abs/1410.8206", "url_versions": "http://scholar.google.com/scholar?cluster=1855379039969159341&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "T Luong, I Sutskever, QV Le, O Vinyals\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Neural Machine Translation (NMT) has recently attracted a lot of attention due to the very high performance achieved by deep neural networks in other domains. An inherent weakness in existing NMT systems is their inability to correctly translate rare words: end-to ...", "url_pdf": null, "num_citations": 7, "cluster_id": "1855379039969159341", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=1855379039969159341&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 14, "url_citation": null, "title": "Deep learning in neural networks: An overview", "url": "http://www.sciencedirect.com/science/article/pii/S0893608014002135", "url_versions": "http://scholar.google.com/scholar?cluster=15932869302045479284&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Schmidhuber - Neural Networks", "excerpt": "Abstract In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow  ...", "url_pdf": null, "num_citations": 143, "cluster_id": "15932869302045479284", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=15932869302045479284&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Attention-based models for speech recognition", "url": "http://arxiv.org/abs/1506.07503", "url_versions": null, "authors": "J Chorowski, D Bahdanau, D Serdyuk, K Cho\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Recurrent sequence generators conditioned on input data through an attention mechanism have recently shown very good performance on a range of tasks in-cluding machine translation, handwriting synthesis and image caption gen-eration. We extend the  ...", "url_pdf": null, "num_citations": 4, "cluster_id": "16516573035858419027", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=16516573035858419027&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Long short-term memory over recursive structures", "url": "http://machinelearning.wustl.edu/mlpapers/paper_files/icml2015_zhub15.pdf", "url_versions": null, "authors": "X Zhu, P Sobihani, H Guo - Proceedings of the 32nd  \u2026", "excerpt": "Abstract The chain-structured long short-term memory (LSTM) has showed to be effective in a wide range of problems such as speech recognition and machine translation. In this paper, we propose to extend it to tree structures, in which a memory cell can reflect the history  ...", "url_pdf": "http://machinelearning.wustl.edu/mlpapers/paper_files/icml2015_zhub15.pdf", "num_citations": 2, "cluster_id": "15043878037627773482", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=15043878037627773482&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 9, "url_citation": null, "title": "Long-term recurrent convolutional networks for visual recognition and description", "url": "http://arxiv.org/abs/1411.4389", "url_versions": "http://scholar.google.com/scholar?cluster=156001817367677897&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Donahue, LA Hendricks, S Guadarrama\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Models based on deep convolutional networks have dominated recent image interpretation tasks; we investigate whether models which are also recurrent, or\" temporally deep\", are effective for tasks involving sequences, visual and otherwise. We develop a  ...", "url_pdf": null, "num_citations": 72, "cluster_id": "156001817367677897", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=156001817367677897&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Translating videos to natural language using deep recurrent neural networks", "url": "http://arxiv.org/abs/1412.4729", "url_versions": "http://scholar.google.com/scholar?cluster=2018325242950133936&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Venugopalan, H Xu, J Donahue, M Rohrbach\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Solving the visual symbol grounding problem has long been a goal of artificial intelligence. The field appears to be advancing closer to this goal with recent breakthroughs in deep learning for natural language grounding in static images. In this paper, we  ...", "url_pdf": null, "num_citations": 22, "cluster_id": "2018325242950133936", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=2018325242950133936&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Deep Online Convex Optimization by Putting Forecaster to Sleep", "url": "http://arxiv.org/abs/1509.01851", "url_versions": null, "authors": "D Balduzzi - arXiv preprint arXiv:1509.01851", "excerpt": "Abstract: Methods from convex optimization such as accelerated gradient descent are widely used as building blocks for deep learning algorithms. However, the reasons for their empirical success are unclear, since neural networks are not convex and standard  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "1937498321554206888", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=1937498321554206888&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 19, "url_citation": null, "title": "Neural Turing Machines", "url": "http://arxiv.org/abs/1410.5401", "url_versions": "http://scholar.google.com/scholar?cluster=8413767524552071308&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "A Graves, G Wayne, I Danihelka - arXiv preprint arXiv:1410.5401", "excerpt": "Abstract: We extend the capabilities of neural networks by coupling them to external memory resources, which they can interact with by attentional processes. The combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-to- ...", "url_pdf": null, "num_citations": 36, "cluster_id": "8413767524552071308", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=8413767524552071308&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks", "url": "http://arxiv.org/abs/1506.03099", "url_versions": null, "authors": "S Bengio, O Vinyals, N Jaitly, N Shazeer - arXiv preprint arXiv:1506.03099", "excerpt": "Abstract: Recurrent Neural Networks can be trained to produce sequences of tokens given some input, as exemplified by recent results in machine translation and image captioning. The current approach to training them consists in maximizing the likelihood of each token  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "4523710212567339415", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=4523710212567339415&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Deep Recurrent Neural Networks for Acoustic Modelling", "url": "http://arxiv.org/abs/1504.01482", "url_versions": "http://scholar.google.com/scholar?cluster=13112805855737302826&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "W Chan, I Lane - arXiv preprint arXiv:1504.01482", "excerpt": "Abstract: We present a novel deep Recurrent Neural Network (RNN) model for acoustic modelling in Automatic Speech Recognition (ASR). We term our contribution as a TC-DNN-BLSTM-DNN model, the model combines a Deep Neural Network (DNN) with Time  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "13112805855737302826", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=13112805855737302826&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Statistical Machine Translation Features with Multitask Tensor Networks", "url": "http://arxiv.org/abs/1506.00698", "url_versions": null, "authors": "H Setiawan, Z Huang, J Devlin, T Lamar, R Zbib\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: We present a three-pronged approach to improving Statistical Machine Translation (SMT), building on recent success in the application of neural networks to SMT. First, we propose new features based on neural networks to model various non-local translation  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "17752969412744236328", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=17752969412744236328&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Skip-thought vectors", "url": "http://arxiv.org/abs/1506.06726", "url_versions": null, "authors": "R Kiros, Y Zhu, R Salakhutdinov, RS Zemel\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage.  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "10194299428367499234", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=10194299428367499234&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "A neural network approach to context-sensitive generation of conversational responses", "url": "http://arxiv.org/abs/1506.06714", "url_versions": null, "authors": "A Sordoni, M Galley, M Auli, C Brockett, Y Ji\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: We present a novel response generation system that can be trained end to end on large quantities of unstructured Twitter conversations. A neural network architecture is used to address sparsity issues that arise when integrating contextual information into classic  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "13228311168016753962", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=13228311168016753962&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Show, attend and tell: Neural image caption generation with visual attention", "url": "http://arxiv.org/abs/1502.03044", "url_versions": "http://scholar.google.com/scholar?cluster=9471583366007765258&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "K Xu, J Ba, R Kiros, A Courville\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard  ...", "url_pdf": null, "num_citations": 42, "cluster_id": "9471583366007765258", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=9471583366007765258&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Generative image modeling using spatial LSTMs", "url": "http://arxiv.org/abs/1506.03478", "url_versions": null, "authors": "L Theis, M Bethge - arXiv preprint arXiv:1506.03478", "excerpt": "Abstract: Modeling the distribution of natural images is challenging, partly because of strong statistical dependencies which can extend over hundreds of pixels. Recurrent neural networks have been successful in capturing long-range dependencies in a number of  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "14060348224594799467", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=14060348224594799467&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Deep Learning for Web Search and Natural Language Processing", "url": "http://research.microsoft.com:8082/en-us/um/people/jfgao/paper/2015/wsdm2015.v3.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=5620482570387470691&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Gao, X He, L Deng -", "excerpt": "Page 1. Deep Learning for Web Search and Natural Language Processing Jianfeng Gao DeepLearning Technology Center (DLTC) Microsoft Research, Redmond, USA WSDM 2015, Shanghai,China *Thank Li Deng and Xiaodong He, with whom we participated in the ...", "url_pdf": "http://research.microsoft.com:8082/en-us/um/people/jfgao/paper/2015/wsdm2015.v3.pdf", "num_citations": 1, "cluster_id": "5620482570387470691", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=5620482570387470691&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "On using very large target vocabulary for neural machine translation", "url": "http://arxiv.org/abs/1412.2007", "url_versions": "http://scholar.google.com/scholar?cluster=13222564911222792417&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Jean, K Cho, R Memisevic, Y Bengio - arXiv preprint arXiv:1412", "excerpt": "Abstract: Neural machine translation, a recently proposed approach to machine translation based purely on neural networks, has shown promising results compared to the existing approaches such as phrase-based statistical machine translation. Despite its recent  ...", "url_pdf": null, "num_citations": 15, "cluster_id": "13222564911222792417", "year": "2007", "url_citations": "http://scholar.google.com/scholar?cites=13222564911222792417&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Locally non-linear learning via feature induction and structured regularization in statistical machine translation", "url": "http://scholar.google.com/https://www.lti.cs.cmu.edu/sites/default/files/Clark,%20Jonathan%20-%20Locally%20Non-Linear%20Learning%20via%20Feature%20Induction%20and%20Structured%20Regularization%20in%20Statistical%20Machine%20Translation.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=12608839869390769611&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "JH Clark -", "excerpt": "Abstract Linear models, which support efficient learning and inference, are the workhorses of statistical machine translation; however, linear decision rules are less attractive from a modeling perspective. The combination of a simple learning technique and such a simple  ...", "url_pdf": "http://scholar.google.com/https://www.lti.cs.cmu.edu/sites/default/files/Clark,%20Jonathan%20-%20Locally%20Non-Linear%20Learning%20via%20Feature%20Induction%20and%20Structured%20Regularization%20in%20Statistical%20Machine%20Translation.pdf", "num_citations": 1, "cluster_id": "12608839869390769611", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=12608839869390769611&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Gated feedback recurrent neural networks", "url": "http://arxiv.org/abs/1502.02367", "url_versions": "http://scholar.google.com/scholar?cluster=9646941875979474208&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Chung, C Gulcehre, K Cho, Y Bengio - arXiv preprint arXiv:1502.02367", "excerpt": "Abstract: In this work, we propose a novel recurrent neural network (RNN) architecture. The proposed RNN, gated-feedback RNN (GF-RNN), extends the existing approach of stacking multiple recurrent layers by allowing and controlling signals flowing from upper recurrent  ...", "url_pdf": null, "num_citations": 12, "cluster_id": "9646941875979474208", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=9646941875979474208&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Grammar as a foreign language", "url": "http://arxiv.org/abs/1412.7449", "url_versions": "http://scholar.google.com/scholar?cluster=7860324232365010530&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "O Vinyals, L Kaiser, T Koo, S Petrov, I Sutskever\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Syntactic parsing is a fundamental problem in computational linguistics and Natural Language Processing. Traditional approaches to parsing are highly complex and problem specific. Recently, Sutskever et al.(2014) presented a domain-independent  ...", "url_pdf": null, "num_citations": 19, "cluster_id": "7860324232365010530", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=7860324232365010530&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Describing videos by exploiting temporal structure", "url": "http://ttic.uchicago.edu/%7Ehaotang/speech/1502.08029v4.pdf", "url_versions": null, "authors": "L Yao, A Torabi, K Cho, N Ballas, C Pal, H Larochelle\u2026 - stat", "excerpt": "Abstract Recent progress in using recurrent neural networks (RNNs) for image description has motivated the exploration of their application for video description. However, while images are static, working with videos requires modeling their dynamic temporal structure  ...", "url_pdf": "http://ttic.uchicago.edu/%7Ehaotang/speech/1502.08029v4.pdf", "num_citations": 5, "cluster_id": "17225606232504528023", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=17225606232504528023&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Ask Me Anything: Dynamic Memory Networks for Natural Language Processing", "url": "http://arxiv.org/abs/1506.07285", "url_versions": null, "authors": "A Kumar, O Irsoy, J Su, J Bradbury, R English\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Most tasks in natural language processing can be cast into question answering (QA) problems over language input. We introduce the dynamic memory network (DMN), a unified neural network framework which processes input sequences and questions, forms  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "15629663398316296180", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=15629663398316296180&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Show and tell: A neural image caption generator", "url": "http://arxiv.org/abs/1411.4555", "url_versions": "http://scholar.google.com/scholar?cluster=16151589378199132798&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "O Vinyals, A Toshev, S Bengio, D Erhan - arXiv preprint arXiv:1411.4555", "excerpt": "Abstract: Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that  ...", "url_pdf": null, "num_citations": 107, "cluster_id": "16151589378199132798", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=16151589378199132798&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Addressing the rare word problem in neural machine translation", "url": "http://www.aclweb.org/anthology/P15-1002.pdf", "url_versions": null, "authors": "MT Luong, I Sutskever, QV Le, O Vinyals\u2026 - Proceedings of  \u2026", "excerpt": "Abstract Neural Machine Translation (NMT) is a new approach to machine translation that has shown promising results that are comparable to traditional approaches. A significant weakness in conventional NMT systems is their inability to correctly translate very rare  ...", "url_pdf": "http://www.aclweb.org/anthology/P15-1002.pdf", "num_citations": 9, "cluster_id": "11928810202267240408", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=11928810202267240408&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "The minority report: some common assumptions to reconsider in the modelling of the brain and behaviour", "url": "http://www.tandfonline.com/doi/abs/10.1080/0952813X.2015.1042534", "url_versions": null, "authors": "S Edelman - Journal of Experimental & Theoretical Artificial  \u2026", "excerpt": "Reverse-engineering the brain involves adopting and testing a hierarchy of working hypotheses regarding the computational problems that it solves, the representations and algorithms that it employs and the manner in which these are implemented. Because  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "11211809683220310289", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=11211809683220310289&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Encoding Source Language with Convolutional Neural Network for Machine Translation", "url": "http://arxiv.org/abs/1503.01838", "url_versions": "http://scholar.google.com/scholar?cluster=6313709901777312023&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "F Meng, Z Lu, M Wang, H Li, W Jiang, Q Liu - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: The recently proposed neural network joint model (NNJM)(Devlin et al., 2014) arguments the n-gram target language model with a heuristically chosen source context window, achieving state-of-the-art performance in SMT. In this paper, we give a more  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "6313709901777312023", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=6313709901777312023&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "A Neural Attention Model for Abstractive Sentence Summarization", "url": "http://arxiv.org/abs/1509.00685", "url_versions": null, "authors": "AM Rush, S Chopra, J Weston - arXiv preprint arXiv:1509.00685", "excerpt": "Abstract: Summarization based on text extraction is inherently limited, but generation-style abstractive methods have proven challenging to build. In this work, we propose a fully data-driven approach to abstractive sentence summarization. Our method utilizes a local  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "14516757443030182405", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=14516757443030182405&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Learning to transduce with unbounded memory", "url": "http://arxiv.org/abs/1506.02516", "url_versions": null, "authors": "E Grefenstette, KM Hermann, M Suleyman\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Recently, strong results have been demonstrated by Deep Recurrent Neural Networks on natural language transduction problems. In this paper we explore the representational power of these models using synthetic grammars designed to exhibit  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "6724672567965731171", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=6724672567965731171&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Low precision arithmetic for deep learning", "url": "http://arxiv.org/abs/1412.7024", "url_versions": "http://scholar.google.com/scholar?cluster=8133488785133791315&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "M Courbariaux, Y Bengio, JP David - arXiv preprint arXiv:1412.7024", "excerpt": "Abstract: We simulate the training of a set of state of the art neural networks, the Maxout networks (Goodfellow et al., 2013a), on three benchmark datasets: the MNIST, CIFAR10 and SVHN, with three distinct arithmetics: floating point, fixed point and dynamic fixed point.  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "8133488785133791315", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=8133488785133791315&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Deep Learning", "url": "http://www.iro.umontreal.ca/%7Ebengioy/dlbook/front_matter.pdf", "url_versions": null, "authors": "Y Bengio, IJ Goodfellow, A Courville -", "excerpt": "2.1 Scalars, Vectors, Matrices and Tensors . . . . . . . . . . . . . . . . . . . 20 2.2 Multiplying Matrices and Vectors . . . . . . . . . . . . . . . . . . . . . . 22 2.3 Identity and Inverse Matrices . . . . . . . . . . . . . . . . . . . . . . . . 24 2.4 Linear Dependence, Span, and Rank . . . . . . . . . . . . . . . . . . . . 25 2.5 Norms . . . . . .  ... ", "url_pdf": "http://www.iro.umontreal.ca/%7Ebengioy/dlbook/front_matter.pdf", "num_citations": 14, "cluster_id": "12148644736204109944", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=12148644736204109944&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "url": "http://arxiv.org/abs/1412.3555", "url_versions": "http://scholar.google.com/scholar?cluster=8949247111056306593&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Chung, C Gulcehre, KH Cho, Y Bengio - arXiv preprint arXiv:1412.3555", "excerpt": "Abstract: In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated  ...", "url_pdf": null, "num_citations": 27, "cluster_id": "8949247111056306593", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=8949247111056306593&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Answer sequence learning with neural networks for answer selection in community question answering", "url": "http://arxiv.org/abs/1506.06490", "url_versions": null, "authors": "X Zhou, B Hu, Q Chen, B Tang, X Wang - arXiv preprint arXiv:1506.06490", "excerpt": "Abstract: In this paper, the answer selection problem in community question answering (CQA) is regarded as an answer sequence labeling task, and a novel approach is proposed based on the recurrent architecture for this problem. Our approach applies convolution  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "555704266608645237", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=555704266608645237&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Neural machine translation by jointly learning to align and translate", "url": "http://arxiv.org/abs/1409.0473", "url_versions": "http://scholar.google.com/scholar?cluster=9430221802571417838&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "D Bahdanau, K Cho, Y Bengio - arXiv preprint arXiv:1409.0473", "excerpt": "Abstract: Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize  ...", "url_pdf": null, "num_citations": 112, "cluster_id": "9430221802571417838", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=9430221802571417838&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Teaching machines to read and comprehend", "url": "http://arxiv.org/abs/1506.03340", "url_versions": null, "authors": "KM Hermann, T Ko\u010disk\u00fd, E Grefenstette\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Teaching machines to read natural language documents remains an elusive challenge. Machine reading systems can be tested on their ability to answer questions posed on the contents of documents that they have seen, but until now large scale training  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "5371787459515302436", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=5371787459515302436&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Transition-based dependency parsing with stack long short-term memory", "url": "http://arxiv.org/abs/1505.08075", "url_versions": null, "authors": "C Dyer, M Ballesteros, W Ling, A Matthews\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: We propose a technique for learning representations of parser states in transition-based dependency parsers. Our primary innovation is a new control structure for sequence-to-sequence neural networks---the stack LSTM. Like the conventional stack data  ...", "url_pdf": null, "num_citations": 10, "cluster_id": "14180674818440394404", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=14180674818440394404&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Sequence to Sequence--Video to Text", "url": "http://arxiv.org/abs/1505.00487", "url_versions": "http://scholar.google.com/scholar?cluster=2341786742021115670&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Venugopalan, M Rohrbach, J Donahue\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Real-world videos often have complex dynamics; methods for generating open-domain video descriptions should be senstive to temporal structure and allow both input (sequence of frames) and output (sequence of words) of variable length. To approach this  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "2341786742021115670", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=2341786742021115670&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Unifying visual-semantic embeddings with multimodal neural language models", "url": "http://arxiv.org/abs/1411.2539", "url_versions": "http://scholar.google.com/scholar?cluster=1451703473279047534&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "R Kiros, R Salakhutdinov, RS Zemel - arXiv preprint arXiv:1411.2539", "excerpt": "Abstract: Inspired by recent advances in multimodal learning and machine translation, we introduce an encoder-decoder pipeline that learns (a): a multimodal joint embedding space with images and text and (b): a novel language model for decoding distributed  ...", "url_pdf": null, "num_citations": 58, "cluster_id": "1451703473279047534", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=1451703473279047534&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Learning semantic word embeddings based on ordinal knowledge constraints", "url": "http://www.anthology.aclweb.org/P/P15/P15-1145.pdf", "url_versions": null, "authors": "Q Liu, H Jiang, S Wei, ZH Ling\u2026 - Proceedings of ACL,  \u2026", "excerpt": "Abstract In this paper, we propose a general framework to incorporate semantic knowledge into the popular data-driven learning process of word embeddings to improve the quality of them. Under this framework, we represent semantic knowledge as many ordinal ranking  ...", "url_pdf": "http://www.anthology.aclweb.org/P/P15/P15-1145.pdf", "num_citations": 1, "cluster_id": "15201799935264282731", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=15201799935264282731&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Describing Multimedia Content using Attention-based Encoder\u2013Decoder Networks", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7243334", "url_versions": null, "authors": "K Cho, A Courville, Y Bengio -", "excerpt": "Abstract\u2014Whereas deep neural networks were first mostly used for classification tasks, they are rapidly expanding in the realm of structured output problems, where the observed target is composed of multiple random variables that have a rich joint distribution, given the input ...", "url_pdf": null, "num_citations": 1, "cluster_id": "12875719958826891977", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=12875719958826891977&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Advances in natural language processing", "url": "http://www.sciencemag.org/content/349/6245/261.short", "url_versions": null, "authors": "J Hirschberg, CD Manning - Science", "excerpt": "Abstract Natural language processing employs computational techniques for the purpose of learning, understanding, and producing human language content. Early computational approaches to language research focused on automating the analysis of the linguistic  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "15805345448853140638", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=15805345448853140638&as_sdt=2005&sciodt=1,5&hl=en"}]