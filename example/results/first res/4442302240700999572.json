[{"num_versions": 6, "url_citation": null, "title": "Surpassing human-level face verification performance on LFW with GaussianFace", "url": "http://arxiv.org/abs/1404.3840", "url_versions": "http://scholar.google.com/scholar?cluster=18004656998485343077&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: Face verification remains a challenging problem in very complex conditions with large variations such as pose, illumination, expression, and occlusions. This problem is exacerbated when we rely unrealistically on a single training data source, which is often  ...", "url_pdf": null, "num_citations": 33, "cluster_id": "18004656998485343077", "authors": "C Lu, X Tang - arXiv preprint arXiv:1404.3840", "url_citations": "http://scholar.google.com/scholar?cites=18004656998485343077&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Visualization and interpretability in probabilistic dimensionality reduction models", "url": "http://tdcat.cesca.es/handle/10803/285013", "url_versions": "http://scholar.google.com/scholar?cluster=3059524642462913803&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: Over the last few decades, data analysis has swiftly evolved from being a task addressed mainly within the remit of multivariate statistics, to an endevour in which data heterogeneity, complexity and even sheer size, driven by computational advances, call for  ...", "url_pdf": null, "num_citations": 0, "cluster_id": null, "authors": "A Tosi - Materia (s)", "url_citations": null}, {"num_versions": 3, "url_citation": null, "title": "Hierarchical facial expression animation by motion capture data", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6890335", "url_versions": "http://scholar.google.com/scholar?cluster=1282094178116476386&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "ABSTRACT Mapping facial tracking data to avatars is very challenging and time consuming, where a simple, yet efficient approach is strongly required. State-of-the-art methods are either vulnerable to noise or heavily reliant on complicated sensor devices. To deal with  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "1282094178116476386", "authors": "S Wang, J Sha, H Wu, Y Fu - Multimedia and Expo (ICME),  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=1282094178116476386&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Variational inference for uncertainty on the inputs of gaussian process models", "url": "http://arxiv.org/abs/1409.2287", "url_versions": "http://scholar.google.com/scholar?cluster=1696446343301816143&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: The Gaussian process latent variable model (GP-LVM) provides a flexible approach for non-linear dimensionality reduction that has been widely applied. However, the current approach for training GP-LVMs is based on maximum likelihood, where the  ...", "url_pdf": null, "num_citations": 4, "cluster_id": "1696446343301816143", "authors": "AC Damianou, MK Titsias, ND Lawrence - arXiv preprint arXiv:1409.2287", "url_citations": "http://scholar.google.com/scholar?cites=1696446343301816143&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 11, "url_citation": null, "title": "Avoiding pathologies in very deep networks", "url": "http://arxiv.org/abs/1402.5836", "url_versions": "http://scholar.google.com/scholar?cluster=3368909721886951994&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: Choosing appropriate architectures and regularization strategies for deep networks is crucial to good predictive performance. To shed light on this problem, we analyze the analogous problem of constructing useful priors on compositions of functions. Specifically,  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "3368909721886951994", "authors": "D Duvenaud, O Rippel, RP Adams\u2026 - arXiv preprint arXiv: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=3368909721886951994&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Deep learning face representation from predicting 10,000 classes", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6909640", "url_versions": "http://scholar.google.com/scholar?cluster=17555805949905028113&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract This paper proposes to learn a set of high-level feature representations through deep learning, referred to as Deep hidden IDentity features (DeepID), for face verification. We argue that DeepID can be effectively learned through challenging multi-class face  ...", "url_pdf": null, "num_citations": 74, "cluster_id": "17555805949905028113", "authors": "Y Sun, X Wang, X Tang - Computer Vision and Pattern  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=17555805949905028113&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Manifold Gaussian Processes for Regression", "url": "http://arxiv.org/abs/1402.5876", "url_versions": "http://scholar.google.com/scholar?cluster=15103502779579951444&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: Off-the-shelf Gaussian Process (GP) covariance functions encode smoothness assumptions on the structure of the function to be modeled. To model complex and non-differentiable functions, these smoothness assumptions are often too restrictive. One way  ...", "url_pdf": null, "num_citations": 4, "cluster_id": "15103502779579951444", "authors": "R Calandra, J Peters, CE Rasmussen\u2026 - arXiv preprint arXiv: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=15103502779579951444&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Dropout as a Bayesian approximation: Representing model uncertainty in deep learning", "url": "http://arxiv.org/abs/1506.02142", "url_versions": null, "year": "2015", "excerpt": "Abstract: Deep learning tools have recently gained much attention in applied machine learning. However such tools for regression and classification do not allow us to capture model uncertainty. Bayesian models offer us the ability to reason about model uncertainty,  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "13174052014464344175", "authors": "Y Gal, Z Ghahramani - arXiv preprint arXiv:1506.02142", "url_citations": "http://scholar.google.com/scholar?cites=13174052014464344175&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Stochastic backpropagation and approximate inference in deep generative models", "url": "http://arxiv.org/abs/1401.4082", "url_versions": "http://scholar.google.com/scholar?cluster=16288343975294201511&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition  ...", "url_pdf": null, "num_citations": 65, "cluster_id": "16288343975294201511", "authors": "DJ Rezende, S Mohamed, D Wierstra - arXiv preprint arXiv:1401.4082", "url_citations": "http://scholar.google.com/scholar?cites=16288343975294201511&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Emulation and interpretation of high-dimensional climate model outputs", "url": "http://www.tandfonline.com/doi/abs/10.1080/02664763.2015.1016412", "url_versions": "http://scholar.google.com/scholar?cluster=4393494662451128881&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Running complex computer models can be expensive in computer time, while learning about the relationships between input and output variables can be difficult. An emulator is a fast approximation to a computationally expensive model that can be used as a surrogate  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "4393494662451128881", "authors": "PB Holden, NR Edwards, PH Garthwaite\u2026 - Journal of Applied  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=4393494662451128881&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Gaussian Process Models with Parallelization and GPU acceleration", "url": "http://arxiv.org/abs/1410.4984", "url_versions": "http://scholar.google.com/scholar?cluster=15951905155784860703&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: In this work, we present an extension of Gaussian process (GP) models with sophisticated parallelization and GPU acceleration. The parallelization scheme arises naturally from the modular computational structure wrt datapoints in the sparse Gaussian  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "15951905155784860703", "authors": "Z Dai, A Damianou, J Hensman\u2026 - arXiv preprint arXiv: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=15951905155784860703&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Hierarchical Mixture-of-Experts Model for Large-Scale Gaussian Process Regression", "url": "http://arxiv.org/abs/1412.3078", "url_versions": "http://scholar.google.com/scholar?cluster=17516952853873733124&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: We propose a practical and scalable Gaussian process model for large-scale nonlinear probabilistic regression. Our mixture-of-experts model is conceptually simple and hierarchically recombines computations for an overall approximation of a full Gaussian  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "17516952853873733124", "authors": "JW Ng, MP Deisenroth - arXiv preprint arXiv:1412.3078", "url_citations": "http://scholar.google.com/scholar?cites=17516952853873733124&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Deep Gaussian Processes and Variational Propagation of Uncertainty", "url": "http://etheses.whiterose.ac.uk/id/eprint/9968", "url_versions": null, "year": "2015", "excerpt": "Uncertainty propagation across components of complex probabilistic models is vital for improving regularisation. Unfortunately, for many interesting models based on non-linear Gaussian processes (GPs), straightforward propagation of uncertainty is computationally  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "13543986365025121375", "authors": "A Damianou -", "url_citations": "http://scholar.google.com/scholar?cites=13543986365025121375&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Machines Learning-Towards a New Synthetic Autobiographical Memory", "url": "http://link.springer.com/chapter/10.1007/978-3-319-09435-9_8", "url_versions": "http://scholar.google.com/scholar?cluster=14627747013512512995&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract Autobiographical memory is the organisation of episodes and contextual information from an individual's experiences into a coherent narrative, which is key to our sense of self. Formation and recall of autobiographical memories is essential for effective,  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "14627747013512512995", "authors": "MH Evans, CW Fox, TJ Prescott - Biomimetic and Biohybrid Systems", "url_citations": "http://scholar.google.com/scholar?cites=14627747013512512995&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Dropout as a Bayesian approximation: Insights and applications", "url": "http://mlg.eng.cam.ac.uk/yarin/website/PDFs/Dropout_as_a_Bayesian_approximation.pdf", "url_versions": null, "year": "2015", "excerpt": "Abstract Deep learning techniques are used more and more often, but they lack the ability to reason about uncertainty over the features. Features extracted from a dataset are given as point estimates, and do not capture how much the model is confident in its estimation. This  ...", "url_pdf": "http://mlg.eng.cam.ac.uk/yarin/website/PDFs/Dropout_as_a_Bayesian_approximation.pdf", "num_citations": 1, "cluster_id": "9335842880058910678", "authors": "Y Gal, Z Ghahramani - Deep Learning Workshop, ICML", "url_citations": "http://scholar.google.com/scholar?cites=9335842880058910678&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "On Sparse variational methods and the Kullback-Leibler divergence between stochastic processes", "url": "http://arxiv.org/abs/1504.07027", "url_versions": "http://scholar.google.com/scholar?cluster=1742360416134799322&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract: The variational framework for learning inducing variables Titsias (2009) has had a large impact on the Gaussian process literature. The framework may be interpreted as minimizing a rigorously defined Kullback-Leibler divergence between the approximate  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "1742360416134799322", "authors": "AGG Matthews, J Hensman, RE Turner\u2026 - arXiv preprint arXiv: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=1742360416134799322&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Scalable Variational Gaussian Process Classification", "url": "http://arxiv.org/abs/1411.2005", "url_versions": "http://scholar.google.com/scholar?cluster=17304542294521882461&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2005", "excerpt": "Abstract: Gaussian process classification is a popular method with a number of appealing properties. We show how to scale the model within a variational inducing point framework, outperforming the state of the art on benchmark datasets. Importantly, the variational  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "17304542294521882461", "authors": "J Hensman, A Matthews, Z Ghahramani - arXiv preprint arXiv:1411", "url_citations": "http://scholar.google.com/scholar?cites=17304542294521882461&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Bayesian Convolutional Neural Networks with Bernoulli Approximate Variational Inference", "url": "http://arxiv.org/abs/1506.02158", "url_versions": null, "year": "2015", "excerpt": "Abstract: We present an efficient Bayesian convolutional neural network (convnet). The model offers better robustness to over-fitting on small data than traditional approaches. This is by placing a probability distribution over the convnet's kernels (also known as filters).  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "4712529334299298768", "authors": "Y Gal, Z Ghahramani - arXiv preprint arXiv:1506.02158", "url_citations": "http://scholar.google.com/scholar?cites=4712529334299298768&as_sdt=2005&sciodt=1,5&hl=en"}]