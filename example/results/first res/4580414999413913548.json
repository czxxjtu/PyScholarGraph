[{"num_versions": 3, "url_citation": null, "title": "Bounding the test log-likelihood of generative models", "url": "http://arxiv.org/abs/1311.6184", "url_versions": "http://scholar.google.com/scholar?cluster=18017364576419179310&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: Several interesting generative learning algorithms involve a complex probability distribution over many random variables, involving intractable normalization constants or latent variable normalization. Some of them may even not have an analytic expression for  ...", "url_pdf": null, "num_citations": 11, "cluster_id": "18017364576419179310", "authors": "Y Bengio, L Yao, K Cho - arXiv preprint arXiv:1311.6184", "url_citations": "http://scholar.google.com/scholar?cites=18017364576419179310&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Learning to disentangle factors of variation with manifold interaction", "url": "http://machinelearning.wustl.edu/mlpapers/papers/icml2014c2_reed14", "url_versions": "http://scholar.google.com/scholar?cluster=15396194608488950557&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: Many latent factors of variation interact to generate sensory data; for example pose, morphology and expression in face images. We propose to learn manifold coordinates for the relevant factors of variation and to model their joint interaction. Most existing feature  ...", "url_pdf": null, "num_citations": 7, "cluster_id": "15396194608488950557", "authors": "S Reed, K Sohn, Y Zhang\u2026 - Proceedings of the  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=15396194608488950557&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Conditional generative adversarial nets", "url": "http://arxiv.org/abs/1411.1784", "url_versions": "http://scholar.google.com/scholar?cluster=15692266515007774871&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "15692266515007774871", "authors": "M Mirza, S Osindero - arXiv preprint arXiv:1411.1784", "url_citations": "http://scholar.google.com/scholar?cites=15692266515007774871&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "NICE: Non-linear Independent Components Estimation", "url": "http://arxiv.org/abs/1410.8516", "url_versions": "http://scholar.google.com/scholar?cluster=8889086958261298527&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: We propose a deep learning framework for modeling complex high-dimensional densities via Non-linear Independent Component Estimation (NICE). It is based on the idea that a good representation is one in which the data has a distribution that is easy to model.  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "8889086958261298527", "authors": "L Dinh, D Krueger, Y Bengio - arXiv preprint arXiv:1410.8516", "url_citations": "http://scholar.google.com/scholar?cites=8889086958261298527&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Generative Moment Matching Networks", "url": "http://arxiv.org/abs/1502.02761", "url_versions": "http://scholar.google.com/scholar?cluster=18115566463777766587&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract: We consider the problem of learning deep generative models from data. We formulate a method that generates an independent sample via a single feedforward pass through a multilayer perceptron, as in the recently proposed generative adversarial  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "18115566463777766587", "authors": "Y Li, K Swersky, R Zemel - arXiv preprint arXiv:1502.02761", "url_citations": "http://scholar.google.com/scholar?cites=18115566463777766587&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Deep directed generative autoencoders", "url": "http://arxiv.org/abs/1410.0630", "url_versions": "http://scholar.google.com/scholar?cluster=13319270084514804160&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: For discrete data, the likelihood $ P (x) $ can be rewritten exactly and parametrized into $ P (X= x)= P (X= x| H= f (x)) P (H= f (x)) $ if $ P (X| H) $ has enough capacity to put no probability mass on any $ x'$ for which $ f (x')\\ neq f (x) $, where $ f (\\ cdot) $ is a  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "13319270084514804160", "authors": "S Ozair, Y Bengio - arXiv preprint arXiv:1410.0630", "url_citations": "http://scholar.google.com/scholar?cites=13319270084514804160&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Generative adversarial nets", "url": "http://papers.nips.cc/paper/5423-generative-adversarial-nets", "url_versions": "http://scholar.google.com/scholar?cluster=11977070277539609369&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract We propose a new framework for estimating generative models via adversarial nets, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample  ...", "url_pdf": null, "num_citations": 26, "cluster_id": "11977070277539609369", "authors": "I Goodfellow, J Pouget-Abadie, M Mirza\u2026 - Advances in Neural  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=11977070277539609369&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Reweighted wake-sleep", "url": "http://arxiv.org/abs/1406.2751", "url_versions": "http://scholar.google.com/scholar?cluster=1461568663093627733&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: Training deep directed graphical models with many hidden variables and performing inference remains a major challenge. Helmholtz machines and deep belief networks are such models, and the wake-sleep algorithm has been proposed to train them ...", "url_pdf": null, "num_citations": 8, "cluster_id": "1461568663093627733", "authors": "J Bornschein, Y Bengio - arXiv preprint arXiv:1406.2751", "url_citations": "http://scholar.google.com/scholar?cites=1461568663093627733&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Generalized denoising auto-encoders as generative models", "url": "http://papers.nips.cc/paper/5023-generalized-denoising-auto-encoders-as-generative-models", "url_versions": "http://scholar.google.com/scholar?cluster=5579395029777847587&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract Recent work has shown how denoising and contractive autoencoders implicitly capture the structure of the data generating density, in the case where the corruption noise is Gaussian, the reconstruction error is the squared error, and the data is continuous-valued.  ...", "url_pdf": null, "num_citations": 60, "cluster_id": "5579395029777847587", "authors": "Y Bengio, L Yao, G Alain, P Vincent - Advances in Neural  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=5579395029777847587&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Stochastic ratio matching of rbms for sparse high-dimensional inputs", "url": "http://papers.nips.cc/paper/5022-stochastic-ratio-matching-of-rbms-for-sparse-high-dimensional-inputs", "url_versions": "http://scholar.google.com/scholar?cluster=3743324182420266646&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract Sparse high-dimensional data vectors are common in many application domains where a very large number of rarely non-zero features can be devised. Unfortunately, this creates a computational bottleneck for unsupervised feature learning algorithms such as  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "3743324182420266646", "authors": "Y Dauphin, Y Bengio - Advances in Neural Information Processing  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=3743324182420266646&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Improving mixing rate with tempered transition for learning restricted Boltzmann machines", "url": "http://www.sciencedirect.com/science/article/pii/S0925231214004196", "url_versions": "http://scholar.google.com/scholar?cluster=13518443480842059344&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract Recently, as the building block of deep generative models such as Deep Belief Networks (DBNs), Restricted Boltzmann Machines (RBMs) have attracted much attention. RBM is a Markov Random Field (MRF) associated with a bipartite undirected graph which  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "13518443480842059344", "authors": "J Xu, H Li, S Zhou - Neurocomputing", "url_citations": "http://scholar.google.com/scholar?cites=13518443480842059344&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "How to construct deep recurrent neural networks", "url": "http://arxiv.org/abs/1312.6026", "url_versions": "http://scholar.google.com/scholar?cluster=3032210598922213468&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: In this paper, we explore different ways to extend a recurrent neural network (RNN) to a\\ textit {deep} RNN. We start by arguing that the concept of depth in an RNN is not as clear as it is in feedforward neural networks. By carefully analyzing and understanding the  ...", "url_pdf": null, "num_citations": 56, "cluster_id": "3032210598922213468", "authors": "R Pascanu, C Gulcehre, K Cho, Y Bengio - arXiv preprint arXiv:1312.6026", "url_citations": "http://scholar.google.com/scholar?cites=3032210598922213468&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "GSNs: Generative Stochastic Networks", "url": "http://arxiv.org/abs/1503.05571", "url_versions": "http://scholar.google.com/scholar?cluster=10321016676192835414&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract: We introduce a novel training principle for probabilistic models that is an alternative to maximum likelihood. The proposed Generative Stochastic Networks (GSN) framework is based on learning the transition operator of a Markov chain whose stationary distribution  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "10321016676192835414", "authors": "G Alain, Y Bengio, L Yao, J Yosinski\u2026 - arXiv preprint arXiv: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=10321016676192835414&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Unsupervised Pretraining Encourages Moderate-Sparseness", "url": "http://arxiv.org/abs/1312.5813", "url_versions": "http://scholar.google.com/scholar?cluster=8820690961336368137&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: It is well known that direct training of deep neural networks will generally lead to poor results. A major progress in recent years is the invention of various pretraining methods to initialize network parameters and it was shown that such methods lead to good  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "8820690961336368137", "authors": "J Li, W Luo, J Yang, X Yuan - arXiv preprint arXiv:1312.5813", "url_citations": "http://scholar.google.com/scholar?cites=8820690961336368137&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "How auto-encoders could provide credit assignment in deep networks via target propagation", "url": "http://arxiv.org/abs/1407.7906", "url_versions": "http://scholar.google.com/scholar?cluster=11714052021876558153&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: In this paper we propose to exploit {\\ em reconstruction} as a layer-local training signal for deep learning, be it generative or discriminant, single or multi-modal, supervised, semi-supervised or unsupervised, feedforward or recurrent. Reconstructions can be  ...", "url_pdf": null, "num_citations": 8, "cluster_id": "11714052021876558153", "authors": "Y Bengio - arXiv preprint arXiv:1407.7906", "url_citations": "http://scholar.google.com/scholar?cites=11714052021876558153&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Algorithmes d'apprentissage profonds supervis\u00e9s et non-supervis\u00e9s: applications et r\u00e9sultats th\u00e9oriques", "url": "http://scholar.google.com/https://papyrus.bib.umontreal.ca/xmlui/handle/1866/10689", "url_versions": "http://scholar.google.com/scholar?cluster=2843024304991296233&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "La liste des domaines touch\u00e9s par l'apprentissage machine s' allonge rapidement. Au fur et \u00e0 mesure que la quantit\u00e9 de donn\u00e9es disponibles augmente, le d\u00e9veloppement d'algorithmes d'apprentissage de plus en plus puissants est crucial. Ce m\u00e9moire est  ...", "url_pdf": null, "num_citations": 0, "cluster_id": null, "authors": "E Thibodeau-Laufer -", "url_citations": null}, {"num_versions": 5, "url_citation": null, "title": "Iterative neural autoregressive distribution estimator nade-k", "url": "http://papers.nips.cc/paper/5277-iterative-neural-autoregressive-distribution-estimator-nade-k", "url_versions": "http://scholar.google.com/scholar?cluster=16368724010911710149&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract Training of the neural autoregressive density estimator (NADE) can be viewed as doing one step of probabilistic inference on missing values in data. We propose a new model that extends this inference scheme to multiple steps, arguing that it is easier to  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "16368724010911710149", "authors": "T Raiko, Y Li, K Cho, Y Bengio - Advances in Neural Information  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=16368724010911710149&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "What regularized auto-encoders learn from the data-generating distribution", "url": "http://dl.acm.org/citation.cfm?id=2750359", "url_versions": "http://scholar.google.com/scholar?cluster=11194404029406866477&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract What do auto-encoders learn about the underlying data-generating distribution? Recent work suggests that some auto-encoder variants do a good job of capturing the local manifold structure of data. This paper clarifies some of these previous observations by  ...", "url_pdf": null, "num_citations": 38, "cluster_id": "11194404029406866477", "authors": "G Alain, Y Bengio - The Journal of Machine Learning Research", "url_citations": "http://scholar.google.com/scholar?cites=11194404029406866477&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Optimizing Neural Networks that Generate Images", "url": "http://www.cs.utoronto.ca/%7Etijmen/tijmen_thesis.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=15111403315546889747&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Image recognition, also known as computer vision, is one of the most prominent applications of neural networks. The image recognition methods presented in this thesis are based on the reverse process: generating images. Generating images is easier than recognizing  ...", "url_pdf": "http://www.cs.utoronto.ca/%7Etijmen/tijmen_thesis.pdf", "num_citations": 4, "cluster_id": "15111403315546889747", "authors": "T Tieleman -", "url_citations": "http://scholar.google.com/scholar?cites=15111403315546889747&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Texture modeling with convolutional spike-and-slab RBMs and deep extensions", "url": "http://arxiv.org/abs/1211.5687", "url_versions": "http://scholar.google.com/scholar?cluster=4774216972617681852&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract: We apply the spike-and-slab Restricted Boltzmann Machine (ssRBM) to texture modeling. The ssRBM with tiled-convolution weight sharing (TssRBM) achieves or surpasses the state-of-the-art on texture synthesis and inpainting by parametric models.  ...", "url_pdf": null, "num_citations": 20, "cluster_id": "4774216972617681852", "authors": "H Luo, PL Carrier, A Courville, Y Bengio - arXiv preprint arXiv:1211.5687", "url_citations": "http://scholar.google.com/scholar?cites=4774216972617681852&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 33, "url_citation": null, "title": "Representation learning: A review and new perspectives", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6472238", "url_versions": "http://scholar.google.com/scholar?cluster=559463397382443088&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract\u2014The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the  ...", "url_pdf": null, "num_citations": 685, "cluster_id": "559463397382443088", "authors": "Y Bengio, A Courville, P Vincent - Pattern Analysis and  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=559463397382443088&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "The flip-the-state transition operator for restricted Boltzmann machines", "url": "http://link.springer.com/article/10.1007/s10994-013-5390-3", "url_versions": "http://scholar.google.com/scholar?cluster=16592792472370495525&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract Most learning and sampling algorithms for restricted Boltzmann machines (RMBs) rely on Markov chain Monte Carlo (MCMC) methods using Gibbs sampling. The most prominent examples are Contrastive Divergence learning (CD) and its variants as well as  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "16592792472370495525", "authors": "K Br\u00fcgge, A Fischer, C Igel - Machine learning", "url_citations": "http://scholar.google.com/scholar?cites=16592792472370495525&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Learning deep representations via extreme learning machines", "url": "http://www.sciencedirect.com/science/article/pii/S0925231214011461", "url_versions": "http://scholar.google.com/scholar?cluster=3329383428404477352&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract Extreme learning machine (ELM) as an emerging technology has achieved exceptional performance in large-scale settings, and is well suited to binary and multi-class classification, as well as regression tasks. However, existing ELM and its variants  ...", "url_pdf": null, "num_citations": 4, "cluster_id": "3329383428404477352", "authors": "W Yu, F Zhuang, Q He, Z Shi - Neurocomputing", "url_citations": "http://scholar.google.com/scholar?cites=3329383428404477352&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "Deep learning of representations: Looking forward", "url": "http://link.springer.com/chapter/10.1007/978-3-642-39593-2_1", "url_versions": "http://scholar.google.com/scholar?cluster=16988628068303769209&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract Deep learning research aims at discovering learning algorithms that discover multiple levels of distributed representations, with higher levels representing more abstract concepts. Although the study of deep learning has already led to impressive theoretical  ...", "url_pdf": null, "num_citations": 86, "cluster_id": "16988628068303769209", "authors": "Y Bengio - Statistical Language and Speech Processing", "url_citations": "http://scholar.google.com/scholar?cites=16988628068303769209&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 13, "url_citation": null, "title": "Deep generative stochastic networks trainable by backprop", "url": "http://arxiv.org/abs/1306.1091", "url_versions": "http://scholar.google.com/scholar?cluster=16609644497959987803&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: We introduce a novel training principle for probabilistic models that is an alternative to maximum likelihood. The proposed Generative Stochastic Networks (GSN) framework is based on learning the transition operator of a Markov chain whose stationary distribution  ...", "url_pdf": null, "num_citations": 72, "cluster_id": "16609644497959987803", "authors": "Y Bengio, E Thibodeau-Laufer, G Alain\u2026 - arXiv preprint arXiv: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=16609644497959987803&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics", "url": "http://arxiv.org/abs/1503.03585", "url_versions": "http://scholar.google.com/scholar?cluster=7270166379090138707&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract: A central unsolved problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Previous  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "7270166379090138707", "authors": "J Sohl-Dickstein, EA Weiss\u2026 - arXiv preprint arXiv: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=7270166379090138707&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 9, "url_citation": null, "title": "Image reconstruction from bag-of-visual-words", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6909522", "url_versions": "http://scholar.google.com/scholar?cluster=2705066254729280200&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract The objective of this study is to reconstruct images from Bag-of-Visual-Words (BoVW), which is the de facto standard feature for image retrieval and recognition. BoVW is defined here as a histogram of quantized descriptors extracted densely on a regular grid  ...", "url_pdf": null, "num_citations": 11, "cluster_id": "2705066254729280200", "authors": "H Kato, T Harada - Computer Vision and Pattern Recognition ( \u2026", "url_citations": "http://scholar.google.com/scholar?cites=2705066254729280200&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Multimodal transitions for generative stochastic networks", "url": "http://arxiv.org/abs/1312.5578", "url_versions": "http://scholar.google.com/scholar?cluster=210664912882124985&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: Generative Stochastic Networks (GSNs) have been recently introduced as an alternative to traditional probabilistic modeling: instead of parametrizing the data distribution directly, one parametrizes a transition operator for a Markov chain whose stationary  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "210664912882124985", "authors": "S Ozair, L Yao, Y Bengio - arXiv preprint arXiv:1312.5578", "url_citations": "http://scholar.google.com/scholar?cites=210664912882124985&as_sdt=2005&sciodt=1,5&hl=en"}]