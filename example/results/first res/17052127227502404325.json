[{"num_versions": 8, "url_citation": null, "title": "Autoincsfa and vision-based developmental learning for humanoid robots", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6100865", "url_versions": "http://scholar.google.com/scholar?cluster=9310704903427403621&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "VR Kompella, L Pape, J Masci, M Frank\u2026 - \u2026 )", "excerpt": "Abstract\u2014Humanoids have to deal with novel, unsupervised high-dimensional visual input streams. Our new method AutoIncSFA learns to compactly represent such complex sensory input sequences by very few meaningful features corresponding to high-level spatio- ...", "url_pdf": null, "num_citations": 8, "cluster_id": "9310704903427403621", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=9310704903427403621&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Regularization in reinforcement learning", "url": "http://scholar.google.com/https://era.library.ualberta.ca/public/datastream/get/uuid:388596e8-f743-4db7-a682-da62a3b21f44/DS1/Farahmand_Amir-massoud_Fall%202011.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=198583344894800354&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "A Farahmand -", "excerpt": "Permission is hereby granted to the University of Alberta Libraries to reproduce single copies of this thesis and to lend or sell such copies for private, scholarly or scientific research purposes only. Where the thesis is converted to, or otherwise made available in digital form, the  ... ", "url_pdf": "http://scholar.google.com/https://era.library.ualberta.ca/public/datastream/get/uuid:388596e8-f743-4db7-a682-da62a3b21f44/DS1/Farahmand_Amir-massoud_Fall%202011.pdf", "num_citations": 4, "cluster_id": "198583344894800354", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=198583344894800354&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 14, "url_citation": null, "title": "Deep learning in neural networks: An overview", "url": "http://www.sciencedirect.com/science/article/pii/S0893608014002135", "url_versions": "http://scholar.google.com/scholar?cluster=15932869302045479284&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Schmidhuber - Neural Networks", "excerpt": "Abstract In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow  ...", "url_pdf": null, "num_citations": 143, "cluster_id": "15932869302045479284", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=15932869302045479284&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 9, "url_citation": null, "title": "Modular deep belief networks that do not forget", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6033359", "url_versions": "http://scholar.google.com/scholar?cluster=867089321108406558&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "L Pape, F Gomez, M Ring\u2026 - Neural Networks (IJCNN \u2026", "excerpt": "Abstract\u2014Deep belief networks (DBNs) are popular for learning compact representations of highdimensional data. However, most approaches so far rely on having a single, complete training set. If the distribution of relevant features changes during subsequent training  ...", "url_pdf": null, "num_citations": 8, "cluster_id": "867089321108406558", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=867089321108406558&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images", "url": "http://arxiv.org/abs/1506.07365", "url_versions": null, "authors": "M Watter, JT Springenberg, J Boedecker\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: We introduce Embed to Control (E2C), a method for model learning and control of non-linear dynamical systems from raw pixel images. E2C consists of a deep generative model, belonging to the family of variational autoencoders, that learns to generate image  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "14464025381144196926", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=14464025381144196926&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "Intrinsically motivated neuroevolution for vision-based reinforcement learning", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6037324", "url_versions": "http://scholar.google.com/scholar?cluster=1785617325793698878&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "G Cuccu, M Luciw, J Schmidhuber\u2026 - \u2026  and Learning (ICDL),  \u2026", "excerpt": "Abstract-Neuroevolution, the artificial evolution of neural networks, has shown great promise on continuous reinforcement learning tasks that require memory. However, it is not yet directly applicable to realistic embedded agents using high-dimensional (eg raw video  ...", "url_pdf": null, "num_citations": 19, "cluster_id": "1785617325793698878", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=1785617325793698878&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "10 Steps and Some Tricks to Set up Neural Reinforcement Controllers", "url": "http://link.springer.com/chapter/10.1007/978-3-642-35289-8_39", "url_versions": "http://scholar.google.com/scholar?cluster=3650768776385872228&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "M Riedmiller - Neural Networks: Tricks of the Trade", "excerpt": "Abstract The paper discusses the steps necessary to set up a neural reinforcement controller for successfully solving typical (real world) control tasks. The major intention is to provide a code of practice of crucial steps that show how to transform control task requirements into  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "3650768776385872228", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=3650768776385872228&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Evolving deep unsupervised convolutional networks for vision-based reinforcement learning", "url": "http://dl.acm.org/citation.cfm?id=2598358", "url_versions": "http://scholar.google.com/scholar?cluster=761036956935637416&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Koutn\u00edk, J Schmidhuber, F Gomez - \u2026  of the", "excerpt": "Abstract Dealing with high-dimensional input spaces, like visual input, is a challenging task for reinforcement learning (RL). Neuroevolution (NE), used for continuous RL problems, has to either reduce the problem dimensionality by (1) compressing the representation of the  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "761036956935637416", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=761036956935637416&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 13, "url_citation": null, "title": "Human-level control through deep reinforcement learning", "url": "http://www.nature.com/nature/journal/v518/n7540/abs/nature14236.html", "url_versions": "http://scholar.google.com/scholar?cluster=12439121588427761338&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "V Mnih, K Kavukcuoglu, D Silver, AA Rusu, J Veness\u2026 - Nature", "excerpt": "The theory of reinforcement learning provides a normative account 1, deeply rooted in psychological 2 and neuroscientific 3 perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in  ...", "url_pdf": null, "num_citations": 78, "cluster_id": "12439121588427761338", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=12439121588427761338&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 11, "url_citation": null, "title": "Construction of approximation spaces for reinforcement learning", "url": "http://dl.acm.org/citation.cfm?id=2567728", "url_versions": "http://scholar.google.com/scholar?cluster=12764863664474690978&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "W B\u00f6hmer, S Gr\u00fcnew\u00e4lder, Y Shen, M Musial\u2026 - The Journal of Machine \u2026", "excerpt": "Abstract Linear reinforcement learning (RL) algorithms like least-squares temporal difference learning (LSTD) require basis functions that span approximation spaces of potential value functions. This article investigates methods to construct these bases from  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "12764863664474690978", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=12764863664474690978&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Apprentissage de repr\u00e9sentations et robotique d\u00e9veloppementale: quelques apports de l'apprentissage profond pour la robotique autonome", "url": "http://www.theses.fr/2015PA066056", "url_versions": "http://scholar.google.com/scholar?cluster=6285727561458018984&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "A Droniou -", "excerpt": "R\u00e9sum\u00e9 Afin de pouvoir \u00e9voluer de mani\u00e8re autonome et s\u00fbre dans leur environnement, les robots doivent \u00eatre capables d\u00bf en construire un mod\u00e8le fiable et pertinent. Pour des t\u00e2ches vari\u00e9es dans des environnements complexes, il est difficile de pr\u00e9voir de mani\u00e8re  ...", "url_pdf": null, "num_citations": 0, "cluster_id": null, "year": "2015", "url_citations": null}, {"num_versions": 2, "url_citation": null, "title": "A Folded Neural Network Autoencoder for Dimensionality Reduction", "url": "http://www.sciencedirect.com/science/article/pii/S1877050912007272", "url_versions": "http://scholar.google.com/scholar?cluster=9917217964382536143&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Wang, H He, DV Prokhorov - Procedia Computer Science", "excerpt": "Dimensionality reduction has been a long-standing research topic in academia and industry for two major reasons. First, in al\u2013most every domain, ranging from biology, social science, economics, to military data processing applications, the increasingly large volume of data  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "9917217964382536143", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=9917217964382536143&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 11, "url_citation": null, "title": "Unsupervised modeling of partially observable environments", "url": "http://link.springer.com/chapter/10.1007/978-3-642-23780-5_42", "url_versions": "http://scholar.google.com/scholar?cluster=6933566854635697777&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "V Graziano, J Koutn\u00edk, J Schmidhuber - Machine Learning and Knowledge \u2026", "excerpt": "Abstract We present an architecture based on self-organizing maps for learning a sensory layer in a learning system. The architecture, temporal network for transitions (TNT), enjoys the freedoms of unsupervised learning, works on-line, in non-episodic environments, is  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "6933566854635697777", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=6933566854635697777&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 12, "url_citation": null, "title": "Low complexity proto-value function learning from sensory observations with incremental slow feature analysis", "url": "http://link.springer.com/chapter/10.1007/978-3-642-33266-1_35", "url_versions": "http://scholar.google.com/scholar?cluster=17187313553909040123&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "M Luciw, J Schmidhuber - \u2026  Networks and Machine Learning\u2013ICANN", "excerpt": "Abstract We show that Incremental Slow Feature Analysis (IncSFA) provides a low complexity method for learning Proto-Value Functions (PVFs). It has been shown that a small number of PVFs provide a good basis set for linear approximation of value functions  ...", "url_pdf": null, "num_citations": 13, "cluster_id": "17187313553909040123", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=17187313553909040123&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Deep process neural network for temporal deep learning", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6889533", "url_versions": null, "authors": "W Huang, H Hong, G Song, K Xie - Neural Networks (IJCNN),  \u2026", "excerpt": "Abstract\u2014Process neural network is widely used in modeling temporal process inputs in neural networks. Traditional process neural network is usually limited in structure of single hidden layer due to the unfavorable training strategies of neural network with multiple  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "4233416864836248756", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=4233416864836248756&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 18, "url_citation": null, "title": "Sequential constant size compressors for reinforcement learning", "url": "http://link.springer.com/chapter/10.1007/978-3-642-22887-2_4", "url_versions": "http://scholar.google.com/scholar?cluster=13642063043675678784&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "L Gissl\u00e9n, M Luciw, V Graziano\u2026 - Artificial General  \u2026", "excerpt": "Abstract Traditional Reinforcement Learning methods are insufficient for AGIs who must be able to learn to deal with Partially Observable Markov Decision Processes. We investigate a novel method for dealing with this problem: standard RL techniques using as input the  ...", "url_pdf": null, "num_citations": 18, "cluster_id": "13642063043675678784", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=13642063043675678784&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 24, "url_citation": null, "title": "Playing atari with deep reinforcement learning", "url": "http://arxiv.org/abs/1312.5602", "url_versions": "http://scholar.google.com/scholar?cluster=10603651548644623407&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "V Mnih, K Kavukcuoglu, D Silver, A Graves\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw  ...", "url_pdf": null, "num_citations": 98, "cluster_id": "10603651548644623407", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=10603651548644623407&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Autonomous reinforcement learning on raw visual input data in a real world application", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6252823", "url_versions": "http://scholar.google.com/scholar?cluster=6020753373057975328&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Lange, M Riedmiller\u2026 - Neural Networks (IJCNN),  \u2026", "excerpt": "Abstract-We propose a learning architecture, that is able to do reinforcement learning based on raw visual input data. In contrast to previous approaches, not only the control policy is learned. In order to be successful, the system must also autonomously learn, how to  ...", "url_pdf": null, "num_citations": 22, "cluster_id": "6020753373057975328", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=6020753373057975328&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Batch reinforcement learning", "url": "http://link.springer.com/chapter/10.1007/978-3-642-27645-3_2", "url_versions": "http://scholar.google.com/scholar?cluster=6850154475027443434&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Lange, T Gabel, M Riedmiller - Reinforcement Learning", "excerpt": "Abstract Batch reinforcement learning is a subfield of dynamic programming-based reinforcement learning. Originally defined as the task of learning the best possible policy from a fixed set of a priori-known transition samples, the (batch) algorithms developed in  ...", "url_pdf": null, "num_citations": 23, "cluster_id": "6850154475027443434", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=6850154475027443434&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "\u57fa DeepLearning \u7f51\u7edc\u6001\u52bf\u611f\u77e5\u5efa\u6a21\u65b9\u6cd5\u7814\u7a76", "url": "http://www.cqvip.com/qk/90164a/201305/46356933.html", "url_versions": "http://scholar.google.com/scholar?cluster=1899006932289271317&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "\u5468\u957f\u5efa\uff0c \u53f8\u9707\u5b87\uff0c \u90a2\u91d1\u9601\uff0c \u5218\u6d77\u6ce2 - \u4e1c\u5317\u519c\u4e1a\u5927\u5b66\u5b66\u62a5", "excerpt": "\u7f51\u7edc\u7ec4\u7ec7\u548c\u751f\u957f\u65b9\u5f0f\u591a\u53d8, \u73b0\u4ee3\u7f51\u7edc\u5448\u62d3\u6251\u7ed3\u6784\u590d\u6742\u5316, \u7f51\u7edc\u8bbe\u5907\u5f02\u6784, \u4fe1\u606f\u4ea4\u4e92\u9891\u7e41\u7b49\u7279\u5f81, \u589e\u52a0\u7f51\u7edc\u6001\u52bf\u5206\u6790\u4e0e\u51b3\u7b56\u96be\u5ea6, \u9700\u52a0\u5f3a\u5bf9\u7f51\u7edc\u6001\u52bf\u611f\u77e5\u5206\u6790\u7684\u7814\u7a76, \u901a\u8fc7\u4e0eBP \u795e\u7ecf\u7f51\u7edc\u6bd4\u8f83\u8fdb\u884c\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u6001\u52bf\u7814\u7a76, \u7ed3\u679c\u8868\u660e, \u6df1\u5ea6\u5b66\u4e60\u8f83BP \u795e\u7ecf\u7f51\u7edc\u5728\u7f51\u7edc\u6001\u52bf\u611f\u77e5 ...", "url_pdf": null, "num_citations": 4, "cluster_id": "1899006932289271317", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=1899006932289271317&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 11, "url_citation": null, "title": "Artificial curiosity with planning for autonomous perceptual and cognitive development", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6037356", "url_versions": "http://scholar.google.com/scholar?cluster=516622354637007093&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "M Luciw, V Graziano, M Ring\u2026 - \u2026  and Learning (ICDL),  \u2026", "excerpt": "Abstract-Autonomous agents that learn from reward on high dimensional visual observations must learn to simplify the raw observations in both space (ie, dimensionality reduction) and time (ie, prediction), so that reinforcement learning becomes tractable and  ...", "url_pdf": null, "num_citations": 23, "cluster_id": "516622354637007093", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=516622354637007093&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Online Evolution of Deep Convolutional Network for Vision-Based Reinforcement Learning", "url": "http://link.springer.com/chapter/10.1007/978-3-319-08864-8_25", "url_versions": "http://scholar.google.com/scholar?cluster=2947461586657136175&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Koutn\u00edk, J Schmidhuber, F Gomez - From Animals to Animats 13", "excerpt": "Abstract Dealing with high-dimensional input spaces, like visual input, is a challenging task for reinforcement learning (RL). Neuroevolution (NE), used for continuous RL problems, has to either reduce the problem dimensionality by (1) compressing the representation of the  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "2947461586657136175", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=2947461586657136175&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Exploring deep and recurrent architectures for optimal control", "url": "http://arxiv.org/abs/1311.1761", "url_versions": "http://scholar.google.com/scholar?cluster=10164277966305204521&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Levine - arXiv preprint arXiv:1311.1761", "excerpt": "Abstract: Sophisticated multilayer neural networks have achieved state of the art results on multiple supervised tasks. However, successful applications of such multilayer networks to control have so far been limited largely to the perception portion of the control pipeline. In  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "10164277966305204521", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=10164277966305204521&as_sdt=2005&sciodt=1,5&hl=en"}]