[{"num_versions": 6, "url_citation": null, "title": "Automatic language identification using Long Short-Term Memory recurrent neural networks", "url": "http://scholar.google.com/https://mazsola.iit.uni-miskolc.hu/%7Eczap/letoltes/IS14/IS2014/PDF/AUTHOR/IS141348.PDF", "url_versions": "http://scholar.google.com/scholar?cluster=3799047937436030496&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Gonzalez-Dominguez, I Lopez-Moreno\u2026 - Proc.  \u2026", "excerpt": "Abstract This work explores the use of Long Short-Term Memory (LSTM) recurrent neural networks (RNNs) for automatic language identification (LID). The use of RNNs is motivated by their better ability in modeling sequences with respect to feed forward networks used in  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "3799047937436030496", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=3799047937436030496&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Audio-Visual Speech Recognition Using Convolutive Bottleneck Networks for a Person with Severe Hearing Loss", "url": "http://ci.nii.ac.jp/naid/130005091225/", "url_versions": null, "authors": "Y Takashima, Y Kakihara, R Aihara\u2026 - IPSJ Transactions on  \u2026", "excerpt": "\u6284\u9332 In this paper, we propose an audio-visual speech recognition system for a person with an articulation disorder resulting from severe hearing loss. In the case of a person with this type of articulation disorder, the speech style is quite different from with the result that of  ...", "url_pdf": null, "num_citations": 0, "cluster_id": null, "year": "2015", "url_citations": null}, {"num_versions": 5, "url_citation": null, "title": "Local-feature-map Integration Using Convolutional Neural Networks for Music Genre Classification.", "url": "http://liris.cnrs.fr/Documents/Liris-5602.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=17017548577442859537&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "T Nakashika, C Garcia, T Takiguchi, I De Lyon - INTERSPEECH", "excerpt": "Abstract A map-based approach, which treats 2-dimensional acoustic features using image analysis, has recently attracted attention in music genre classification. While this is successful at extracting local music-patterns compared with other frame-based methods,  ...", "url_pdf": "http://liris.cnrs.fr/Documents/Liris-5602.pdf", "num_citations": 4, "cluster_id": "17017548577442859537", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=17017548577442859537&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Convolutive Bottleneck Network with Dropout for Dysarthric Speech Recognition", "url": "http://www.me.cs.scitec.kobe-u.ac.jp/publications/papers/2014/150-481-1-PB.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=1144509274064238584&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "T Nakashika, T Yoshioka\u2026 - EDITORIAL  \u2026", "excerpt": "ABSTRACT In this paper, we investigate the recognition of speech produced by a person with an articulation disorder resulting from athetoid cerebral palsy. The articulation of the first spoken words tends to become unstable due to strain on speech muscles, and that  ...", "url_pdf": "http://www.me.cs.scitec.kobe-u.ac.jp/publications/papers/2014/150-481-1-PB.pdf", "num_citations": 1, "cluster_id": "1144509274064238584", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=1144509274064238584&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Automatic language identification using deep neural networks", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6854622", "url_versions": "http://scholar.google.com/scholar?cluster=14559110042981765647&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "I Lopez-Moreno, J Gonzalez-Dominguez\u2026 - \u2026 , Speech and Signal  \u2026", "excerpt": "ABSTRACT This work studies the use of deep neural networks (DNNs) to address automatic language identification (LID). Motivated by their recent success in acoustic modelling, we adapt DNNs to the problem of identifying the language of a given spoken utterance from  ...", "url_pdf": null, "num_citations": 20, "cluster_id": "14559110042981765647", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=14559110042981765647&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Phonotactic language recognition based on DNN-HMM acoustic model", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6936704", "url_versions": "http://scholar.google.com/scholar?cluster=17995027552470380046&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "WW Liu, M Cai, H Yuan, XB Shi\u2026 - \u2026  (ISCSLP)", "excerpt": "Abstract A recently introduced deep neural network (DNN) has achieved some unprecedented gains in many challenging automatic speech recognition (ASR) tasks. In this paper deep neural network hidden Markov model (DNN-HMM) acoustic models is  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "17995027552470380046", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=17995027552470380046&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Dysarthric speech recognition using a convolutive bottleneck network", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7015056", "url_versions": "http://scholar.google.com/scholar?cluster=3746881878925235700&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "T Nakashika, T Yoshioka, T Takiguchi\u2026 - \u2026  (ICSP)", "excerpt": "Abstract\u2014In this paper, we investigate the recognition of speech produced by a person with an articulation disorder resulting from athetoid cerebral palsy. The articulation of the first spoken words tends to become unstable due to strain on speech muscles, and that  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "3746881878925235700", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=3746881878925235700&as_sdt=2005&sciodt=1,5&hl=en"}]