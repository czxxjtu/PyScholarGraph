[{"num_versions": 4, "url_citation": null, "title": "Optimization techniques to improve training speed of deep neural networks for large speech tasks", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6619439", "url_versions": "http://scholar.google.com/scholar?cluster=8342459325676772309&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract\u2014While Deep Neural Networks (DNNs) have achieved tremendous success for large vocabulary continuous speech recognition (LVCSR) tasks, training these networks is slow. Even to date, the most common approach to train DNNs is via stochastic gradient  ...", "url_pdf": null, "num_citations": 21, "cluster_id": "8342459325676772309", "authors": "TN Sainath, B Kingsbury, H Soltau\u2026 - Audio, Speech, and  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=8342459325676772309&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Convolutional deep rectifier neural nets for phone recognition.", "url": "http://lpp.ilpga.fr/PDF/IS130125/IS130125.PDF", "url_versions": "http://scholar.google.com/scholar?cluster=8530843942923714117&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract Rectifier neurons differ from standard ones only in that the sigmoid activation function is replaced by the rectifier function, max (0, x). Several recent studies suggest that rectifier units may be more suitable building units for deep nets. For example, we found  ...", "url_pdf": null, "num_citations": 17, "cluster_id": "8530843942923714117", "authors": "L T\u00f3th - INTERSPEECH", "url_citations": "http://scholar.google.com/scholar?cites=8530843942923714117&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Network anomaly detection with the restricted Boltzmann machine", "url": "http://www.sciencedirect.com/science/article/pii/S0925231213005547", "url_versions": "http://scholar.google.com/scholar?cluster=16295884390318256584&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract With the rapid growth and the increasing complexity of network infrastructures and the evolution of attacks, identifying and preventing network abuses is getting more and more strategic to ensure an adequate degree of protection from both external and internal  ...", "url_pdf": null, "num_citations": 31, "cluster_id": "16295884390318256584", "authors": "U Fiore, F Palmieri, A Castiglione, A De Santis - Neurocomputing", "url_citations": "http://scholar.google.com/scholar?cites=16295884390318256584&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 11, "url_citation": null, "title": "Translating embeddings for modeling multi-relational data", "url": "http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data", "url_versions": "http://scholar.google.com/scholar?cluster=8246464320979790535&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract We consider the problem of embedding entities and relationships of multi-relational data in low-dimensional vector spaces. Our objective is to propose a canonical model which is easy to train, contains a reduced number of parameters and can scale up to very large  ...", "url_pdf": null, "num_citations": 79, "cluster_id": "8246464320979790535", "authors": "A Bordes, N Usunier, A Garcia-Duran\u2026 - Advances in Neural  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=8246464320979790535&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 16, "url_citation": null, "title": "On the importance of initialization and momentum in deep learning", "url": "http://machinelearning.wustl.edu/mlpapers/papers/icml2013_sutskever13", "url_versions": "http://scholar.google.com/scholar?cluster=7449004388220998591&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent  ...", "url_pdf": null, "num_citations": 154, "cluster_id": "7449004388220998591", "authors": "I Sutskever, J Martens, G Dahl\u2026 - Proceedings of the  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=7449004388220998591&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "The importance of topology evolution in neuroevolution: a case study using Cartesian genetic programming of artificial neural networks", "url": "http://link.springer.com/chapter/10.1007/978-3-319-02621-3_15", "url_versions": "http://scholar.google.com/scholar?cluster=9090227694669059988&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract NeuroEvolution (NE) is the application of evolutionary algorithms to Artificial Neural Networks (ANN). This paper reports on an investigation into the relative importance of weight evolution and topology evolution when training ANN using NE. This investigation  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "9090227694669059988", "authors": "AJ Turner, JF Miller - Research and Development in Intelligent Systems  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=9090227694669059988&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Neural networks for distant speech recognition", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6843274", "url_versions": "http://scholar.google.com/scholar?cluster=9495285611538367285&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "ABSTRACT Distant conversational speech recognition is challenging owing to the presence of multiple, overlapping talkers, additional non-speech acoustic sources, and the effects of reverberation. In this paper we review work on distant speech recognition, with an  ...", "url_pdf": null, "num_citations": 7, "cluster_id": "9495285611538367285", "authors": "S Renals, P Swietojanski - Hands-free Speech Communication  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=9495285611538367285&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Very deep convolutional networks for large-scale image recognition", "url": "http://arxiv.org/abs/1409.1556", "url_versions": "http://scholar.google.com/scholar?cluster=15993525775437884507&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on  ...", "url_pdf": null, "num_citations": 294, "cluster_id": "15993525775437884507", "authors": "K Simonyan, A Zisserman - arXiv preprint arXiv:1409.1556", "url_citations": "http://scholar.google.com/scholar?cites=15993525775437884507&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "SKYNET: an efficient and robust neural network training tool for machine learning in astronomy", "url": "http://mnras.oxfordjournals.org/content/441/2/1741.short", "url_versions": "http://scholar.google.com/scholar?cluster=2639247557162041654&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract We present the first public release of our generic neural network training algorithm, called S ky N et. This efficient and robust machine learning tool is able to train large and deep feed-forward neural networks, including autoencoders, for use in a wide range of  ...", "url_pdf": null, "num_citations": 15, "cluster_id": "2639247557162041654", "authors": "P Graff, F Feroz, MP Hobson\u2026 - Monthly Notices of the  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=2639247557162041654&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Image denoising with multi-layer perceptrons, part 1: comparison with existing algorithms and with bounds", "url": "http://arxiv.org/abs/1211.1544", "url_versions": "http://scholar.google.com/scholar?cluster=18064963871950324471&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract: Image denoising can be described as the problem of mapping from a noisy image to a noise-free image. The best currently available denoising methods approximate this mapping with cleverly engineered algorithms. In this work we attempt to learn this  ...", "url_pdf": null, "num_citations": 8, "cluster_id": "18064963871950324471", "authors": "HC Burger, CJ Schuler, S Harmeling - arXiv preprint arXiv:1211.1544", "url_citations": "http://scholar.google.com/scholar?cites=18064963871950324471&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "Deep learning of representations: Looking forward", "url": "http://link.springer.com/chapter/10.1007/978-3-642-39593-2_1", "url_versions": "http://scholar.google.com/scholar?cluster=16988628068303769209&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract Deep learning research aims at discovering learning algorithms that discover multiple levels of distributed representations, with higher levels representing more abstract concepts. Although the study of deep learning has already led to impressive theoretical  ...", "url_pdf": null, "num_citations": 86, "cluster_id": "16988628068303769209", "authors": "Y Bengio - Statistical Language and Speech Processing", "url_citations": "http://scholar.google.com/scholar?cites=16988628068303769209&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Learning hidden unit contributions for unsupervised speaker adaptation of neural network acoustic models", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7078569", "url_versions": "http://scholar.google.com/scholar?cluster=17182321332313987386&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "ABSTRACT This paper proposes a simple yet effective model-based neural network speaker adaptation technique that learns speakerspecific hidden unit contributions given adaptation data, without requiring any form of speaker-adaptive training, or labelled  ...", "url_pdf": null, "num_citations": 15, "cluster_id": "17182321332313987386", "authors": "P Swietojanski, S Renals - Spoken Language Technology  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=17182321332313987386&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "The IBM 2011 GALE Arabic speech transcription system", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6163943", "url_versions": "http://scholar.google.com/scholar?cluster=2884059498927780169&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2011", "excerpt": "Abstract\u2014We describe the Arabic broadcast transcription system fielded by IBM in the GALE Phase 5 machine translation evaluation. Key advances over our Phase 4 system include a new Bayesian Sensing HMM acoustic model; multistream neural network features; a  ...", "url_pdf": null, "num_citations": 23, "cluster_id": "2884059498927780169", "authors": "L Mangu, HK Kuo, S Chu, B Kingsbury\u2026 - \u2026  (ASRU)", "url_citations": "http://scholar.google.com/scholar?cites=2884059498927780169&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Large-scale Multi-label Text Classification\u2014Revisiting Neural Networks", "url": "http://link.springer.com/chapter/10.1007/978-3-662-44851-9_28", "url_versions": "http://scholar.google.com/scholar?cluster=9765327466355776433&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract Neural networks have recently been proposed for multi-label classification because they are able to capture and model label dependencies in the output layer. In this work, we investigate limitations of BP-MLL, a neural network (NN) architecture that aims at  ...", "url_pdf": null, "num_citations": 10, "cluster_id": "9765327466355776433", "authors": "J Nam, J Kim, EL Menc\u00eda, I Gurevych\u2026 - Machine Learning and  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=9765327466355776433&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Roles of pre-training and fine-tuning in context-dependent DBN-HMMs for real-world speech recognition", "url": "http://www.msr-waypoint.com/pubs/143619/dbn4asr-nips2010.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=2085230840263552626&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2010", "excerpt": "Abstract Recently, deep learning techniques have been successfully applied to automatic speech recognition tasks--first to phonetic recognition with context-independent deep belief network (DBN) hidden Markov models (HMMs) and later to large vocabulary continuous  ...", "url_pdf": "http://www.msr-waypoint.com/pubs/143619/dbn4asr-nips2010.pdf", "num_citations": 99, "cluster_id": "2085230840263552626", "authors": "D Yu, L Deng, G Dahl - Proc. NIPS Workshop on Deep Learning  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=2085230840263552626&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Non-linear coding and decoding strategies exploiting spatial correlation in wireless sensor networks", "url": "http://digital-library.theiet.org/content/journals/10.1049/iet-com.2011.0799", "url_versions": "http://scholar.google.com/scholar?cluster=3257953294492543569&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "The authors consider the acquisition of measurements from a source, representing a physical phenomenon, by means of sensors deployed at different distances, and measuring random variables (rv's) that are correlated with the source output. The acquired values are  ...", "url_pdf": null, "num_citations": 10, "cluster_id": "3257953294492543569", "authors": "F Davoli, M Marchese, M Mongelli - IET communications", "url_citations": "http://scholar.google.com/scholar?cites=3257953294492543569&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 23, "url_citation": null, "title": "No more pesky learning rates", "url": "http://arxiv.org/abs/1206.1106", "url_versions": "http://scholar.google.com/scholar?cluster=4544789299729524763&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract: The performance of stochastic gradient descent (SGD) depends critically on how learning rates are tuned and decreased over time. We propose a method to automatically adjust multiple learning rates so as to minimize the expected error at any one time. The  ...", "url_pdf": null, "num_citations": 68, "cluster_id": "4544789299729524763", "authors": "T Schaul, S Zhang, Y LeCun - arXiv preprint arXiv:1206.1106", "url_citations": "http://scholar.google.com/scholar?cites=4544789299729524763&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "Deeply-supervised nets", "url": "http://arxiv.org/abs/1409.5185", "url_versions": "http://scholar.google.com/scholar?cluster=6919613780007941823&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: Our proposed deeply-supervised nets (DSN) method simultaneously minimizes classification error while making the learning process of hidden layers direct and transparent. We make an attempt to boost the classification performance by studying a  ...", "url_pdf": null, "num_citations": 45, "cluster_id": "6919613780007941823", "authors": "CY Lee, S Xie, P Gallagher, Z Zhang, Z Tu - arXiv preprint arXiv: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=6919613780007941823&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Suitability of V1 energy models for object classification", "url": "http://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00084", "url_versions": "http://scholar.google.com/scholar?cluster=3296239020464391981&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2011", "excerpt": "Simulations of cortical computation have often focused on networks built from simplified neuron models similar to rate models hypothesized for V1 simple cells. However, physiological research has revealed that even V1 simple cells have surprising complexity.  ...", "url_pdf": null, "num_citations": 8, "cluster_id": "3296239020464391981", "authors": "J Bergstra, Y Bengio, J Louradour - Neural computation", "url_citations": "http://scholar.google.com/scholar?cites=3296239020464391981&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Discriminative deep metric learning for face verification in the wild", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6909638", "url_versions": "http://scholar.google.com/scholar?cluster=2945321669966143066&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract This paper presents a new discriminative deep metric learning (DDML) method for face verification in the wild. Different from existing metric learning-based face verification methods which aim to learn a Mahalanobis distance metric to maximize the inter-class  ...", "url_pdf": null, "num_citations": 40, "cluster_id": "2945321669966143066", "authors": "J Hu, J Lu, YP Tan - Computer Vision and Pattern Recognition ( \u2026", "url_citations": "http://scholar.google.com/scholar?cites=2945321669966143066&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 12, "url_citation": null, "title": "Gaussian-binary restricted boltzmann machines on modeling natural image statistics", "url": "http://arxiv.org/abs/1401.5900", "url_versions": "http://scholar.google.com/scholar?cluster=6804412950881133910&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: We present a theoretical analysis of Gaussian-binary restricted Boltzmann machines (GRBMs) from the perspective of density models. The key aspect of this analysis is to show that GRBMs can be formulated as a constrained mixture of Gaussians, which  ...", "url_pdf": null, "num_citations": 7, "cluster_id": "6804412950881133910", "authors": "N Wang, J Melchior, L Wiskott - arXiv preprint arXiv:1401.5900", "url_citations": "http://scholar.google.com/scholar?cites=6804412950881133910&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 19, "url_citation": null, "title": "Krylov subspace descent for deep learning", "url": "http://arxiv.org/abs/1111.4259", "url_versions": "http://scholar.google.com/scholar?cluster=9397394098242250506&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2011", "excerpt": "Abstract: In this paper, we propose a second order optimization method to learn models where both the dimensionality of the parameter space and the number of training samples is high. In our method, we construct on each iteration a Krylov subspace formed by the  ...", "url_pdf": null, "num_citations": 33, "cluster_id": "9397394098242250506", "authors": "O Vinyals, D Povey - arXiv preprint arXiv:1111.4259", "url_citations": "http://scholar.google.com/scholar?cites=9397394098242250506&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 11, "url_citation": null, "title": "Generalization and properties of the neural response", "url": "http://18.7.29.232/handle/1721.1/60024", "url_versions": "http://scholar.google.com/scholar?cluster=2610532637117314282&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2010", "excerpt": "Hierarchical learning algorithms have enjoyed tremendous growth in recent years, with many new algorithms being proposed and applied to a wide range of applications. However, despite the apparent success of hierarchical algorithms in practice, the theory of  ...", "url_pdf": null, "num_citations": 7, "cluster_id": "2610532637117314282", "authors": "J Bouvrie, T Poggio, L Rosasco, S Smale, A Wibisono -", "url_citations": "http://scholar.google.com/scholar?cites=2610532637117314282&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "Random search for hyper-parameter optimization", "url": "http://dl.acm.org/citation.cfm?id=2188395", "url_versions": "http://scholar.google.com/scholar?cluster=7473940110210462469&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid.  ...", "url_pdf": null, "num_citations": 324, "cluster_id": "7473940110210462469", "authors": "J Bergstra, Y Bengio - The Journal of Machine Learning Research", "url_citations": "http://scholar.google.com/scholar?cites=7473940110210462469&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Training deep and recurrent networks with hessian-free optimization", "url": "http://link.springer.com/chapter/10.1007/978-3-642-35289-8_27", "url_versions": "http://scholar.google.com/scholar?cluster=3256736991833741484&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract In this chapter we will first describe the basic HF approach, and then examine well-known performance-improving techniques such as preconditioning which we have found to be beneficial for neural network training, as well as others of a more heuristic nature which  ...", "url_pdf": null, "num_citations": 34, "cluster_id": "3256736991833741484", "authors": "J Martens, I Sutskever - Neural Networks: Tricks of the Trade", "url_citations": "http://scholar.google.com/scholar?cites=3256736991833741484&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "An overview of deep-structured learning for information processing", "url": "http://131.107.65.14/pubs/155609/DENG-APSIPA.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=1255369059227179273&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2011", "excerpt": "Abstract\u2014In this paper, I will introduce to the APSIPA audience an emerging area of machine learning, deep-structured learning. It refers to a class of machine learning techniques, developed mostly since 2006, where many layers of information processing  ...", "url_pdf": "http://131.107.65.14/pubs/155609/DENG-APSIPA.pdf", "num_citations": 22, "cluster_id": "1255369059227179273", "authors": "L Deng - Proceedings of Asian-Pacific Signal & Information  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=1255369059227179273&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "A tutorial survey of architectures, algorithms, and applications for deep learning", "url": "http://journals.cambridge.org/abstract_S2048770313000097", "url_versions": "http://scholar.google.com/scholar?cluster=4381743472348703222&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract In this invited paper, my overview material on the same topic as presented in the plenary overview session of APSIPA-2011 and the tutorial material presented in the same conference [1] are expanded and updated to include more recent developments in deep  ...", "url_pdf": null, "num_citations": 18, "cluster_id": "4381743472348703222", "authors": "L Deng - APSIPA Transactions on Signal and Information  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=4381743472348703222&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Learning feature hierarchies with centered deep Boltzmann machines", "url": "http://arxiv.org/abs/1203.3783", "url_versions": "http://scholar.google.com/scholar?cluster=13848019087950107027&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract: Deep Boltzmann machines are in principle powerful models for extracting the hierarchical structure of data. Unfortunately, attempts to train layers jointly (without greedy layer-wise pretraining) have been largely unsuccessful. We propose a modification of the  ...", "url_pdf": null, "num_citations": 7, "cluster_id": "13848019087950107027", "authors": "G Montavon, KR M\u00fcller - arXiv preprint arXiv:1203.3783", "url_citations": "http://scholar.google.com/scholar?cites=13848019087950107027&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Cross-entropy vs. squared error training: a theoretical and experimental comparison.", "url": "http://scholar.google.com/https://www-i6.informatik.rwth-aachen.de/publications/download/861/GolikPavelDoetschPatrickNeyHermann--Cross-Entropyvs.SquaredErrorTrainingaTheoreticalExperimentalComparison--2013.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=8444873502704382142&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract In this paper we investigate the error criteria that are optimized during the training of artificial neural networks (ANN). We compare the bounds of the squared error (SE) and the crossentropy (CE) criteria being the most popular choices in stateof-the art  ...", "url_pdf": "http://scholar.google.com/https://www-i6.informatik.rwth-aachen.de/publications/download/861/GolikPavelDoetschPatrickNeyHermann--Cross-Entropyvs.SquaredErrorTrainingaTheoreticalExperimentalComparison--2013.pdf", "num_citations": 13, "cluster_id": "8444873502704382142", "authors": "P Golik, P Doetsch, H Ney - INTERSPEECH", "url_citations": "http://scholar.google.com/scholar?cites=8444873502704382142&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Knowledge matters: Importance of prior information for optimization", "url": "http://arxiv.org/abs/1301.4083", "url_versions": "http://scholar.google.com/scholar?cluster=16555444433184520296&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans  ...", "url_pdf": null, "num_citations": 19, "cluster_id": "16555444433184520296", "authors": "\u00c7 G\u00fcl\u00e7ehre, Y Bengio - arXiv preprint arXiv:1301.4083", "url_citations": "http://scholar.google.com/scholar?cites=16555444433184520296&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 15, "url_citation": null, "title": "A unified multitask architecture for predicting local protein properties", "url": "http://dx.plos.org/10.1371/journal.pone.0032235", "url_versions": "http://scholar.google.com/scholar?cluster=15823326548562981179&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract A variety of functionally important protein properties, such as secondary structure, transmembrane topology and solvent accessibility, can be encoded as a labeling of amino acids. Indeed, the prediction of such properties from the primary amino acid sequence is  ...", "url_pdf": null, "num_citations": 7, "cluster_id": "15823326548562981179", "authors": "Y Qi, M Oja, J Weston, WS Noble - PloS one", "url_citations": "http://scholar.google.com/scholar?cites=15823326548562981179&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Learning in modular systems", "url": "http://oai.dtic.mil/oai/oai?verb=getRecord&metadataPrefix=html&identifier=ADA543141", "url_versions": "http://scholar.google.com/scholar?cluster=12500155409300383833&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2010", "excerpt": "Abstract: Complex robotics systems are often built as a system of modules, where each module solves a separate data processing task to produce the complex overall behavior that is required of the robot. For instance, the perception system for autonomous off-road  ...", "url_pdf": null, "num_citations": 8, "cluster_id": "12500155409300383833", "authors": "DM Bradley -", "url_citations": "http://scholar.google.com/scholar?cites=12500155409300383833&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 15, "url_citation": null, "title": "Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5740583", "url_versions": "http://scholar.google.com/scholar?cluster=1536831630272977838&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract\u2014We propose a novel context-dependent (CD) model for large-vocabulary speech recognition (LVSR) that leverages recent advances in using deep belief networks for phone recognition. We describe a pre-trained deep neural network hidden Markov model (DNN- ...", "url_pdf": null, "num_citations": 739, "cluster_id": "1536831630272977838", "authors": "GE Dahl, D Yu, L Deng, A Acero - Audio, Speech, and  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=1536831630272977838&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Training recurrent neural networks", "url": "http://www.cs.utoronto.ca/%7Eilya/pubs/ilya_sutskever_phd_thesis.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=11547556497378421036&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Recurrent Neural Networks (RNNs) are artificial neural network models that are well-suited for pattern classification tasks whose inputs and outputs are sequences. The importance of developing methods for mapping sequences to sequences is exemplified by tasks such as  ...", "url_pdf": "http://www.cs.utoronto.ca/%7Eilya/pubs/ilya_sutskever_phd_thesis.pdf", "num_citations": 43, "cluster_id": "11547556497378421036", "authors": "I Sutskever -", "url_citations": "http://scholar.google.com/scholar?cites=11547556497378421036&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 15, "url_citation": null, "title": "Deep learning made easier by linear transformations in perceptrons", "url": "http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2012_RaikoVL12.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=623608584055994978&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract We transform the outputs of each hidden neuron in a multi-layer perceptron network to have zero output and zero slope on average, and use separate shortcut connections to model the linear dependencies instead. This transformation aims at separating the  ...", "url_pdf": "http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2012_RaikoVL12.pdf", "num_citations": 44, "cluster_id": "623608584055994978", "authors": "T Raiko, H Valpola, Y LeCun - International  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=623608584055994978&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 33, "url_citation": null, "title": "Representation learning: A review and new perspectives", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6472238", "url_versions": "http://scholar.google.com/scholar?cluster=559463397382443088&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract\u2014The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the  ...", "url_pdf": null, "num_citations": 685, "cluster_id": "559463397382443088", "authors": "Y Bengio, A Courville, P Vincent - Pattern Analysis and  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=559463397382443088&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "Learning two-layer contractive encodings", "url": "http://link.springer.com/chapter/10.1007/978-3-642-33269-2_78", "url_versions": "http://scholar.google.com/scholar?cluster=1430477992589026838&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract Unsupervised learning of feature hierarchies is often a good initialization for supervised training of deep architectures. In existing deep learning methods, these feature hierarchies are built layer by layer in a greedy fashion using auto-encoders or restricted  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "1430477992589026838", "authors": "H Schulz, S Behnke - Artificial Neural Networks and Machine Learning\u2013 \u2026", "url_citations": "http://scholar.google.com/scholar?cites=1430477992589026838&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Big neural networks waste capacity", "url": "http://arxiv.org/abs/1301.3583", "url_versions": "http://scholar.google.com/scholar?cluster=15203864254754138120&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting. Past research suggest diminishing returns when increasing the size of neural networks. Our experiments on ImageNet LSVRC-2010 show that this  ...", "url_pdf": null, "num_citations": 26, "cluster_id": "15203864254754138120", "authors": "YN Dauphin, Y Bengio - arXiv preprint arXiv:1301.3583", "url_citations": "http://scholar.google.com/scholar?cites=15203864254754138120&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Deep learning for signal and information processing", "url": "http://cs.tju.edu.cn/web/docs/2013-Deep%20Learning%20for%20Signal%20and%20Information%20Processing.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=7346768574939973182&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "ABSTRACT This short monograph contains the material expanded from two tutorials that the authors gave, one at APSIPA in October 2011 and the other at ICASSP in March 2012. Substantial updates have been made based on the literature up to March, 2013, covering  ...", "url_pdf": "http://cs.tju.edu.cn/web/docs/2013-Deep%20Learning%20for%20Signal%20and%20Information%20Processing.pdf", "num_citations": 9, "cluster_id": "7346768574939973182", "authors": "L Deng, D Yu - Microsoft Research Monograph", "url_citations": "http://scholar.google.com/scholar?cites=7346768574939973182&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Improved preconditioner for hessian free optimization", "url": "http://www.chapelle.cc/olivier/pub/precond.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=4369584637674824037&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2011", "excerpt": "Abstract We investigate the use of Hessian Free optimization for learning deep autoencoders. One of the critical components in that algorithm is the choice of the preconditioner. We argue in this paper that the Jacobi preconditioner leads to faster  ...", "url_pdf": "http://www.chapelle.cc/olivier/pub/precond.pdf", "num_citations": 15, "cluster_id": "4369584637674824037", "authors": "O Chapelle, D Erhan - NIPS Workshop on Deep Learning and  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=4369584637674824037&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Exploiting diversity for spoken term detection", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6639280", "url_versions": null, "year": "2013", "excerpt": "ABSTRACT The paper describes a state-of-the-art spoken term detection system in which significant improvements are obtained by diversifying the ASR engines used for indexing and combining the search results. First, we describe the design factors that, when varied,  ...", "url_pdf": null, "num_citations": 33, "cluster_id": "1677325262704499577", "authors": "L Mangu, H Soltau, HK Kuo\u2026 - \u2026 , Speech and Signal  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=1677325262704499577&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "url": "http://arxiv.org/abs/1502.03167", "url_versions": "http://scholar.google.com/scholar?cluster=9384364112097346204&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract: Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful  ...", "url_pdf": null, "num_citations": 47, "cluster_id": "9384364112097346204", "authors": "S Ioffe, C Szegedy - arXiv preprint arXiv:1502.03167", "url_citations": "http://scholar.google.com/scholar?cites=9384364112097346204&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "A comparison of deep neural network training methods for large vocabulary speech recognition", "url": "http://link.springer.com/chapter/10.1007/978-3-642-40585-3_6", "url_versions": "http://scholar.google.com/scholar?cluster=1459050142419828338&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract The introduction of deep neural networks to acoustic modelling has brought significant improvements in speech recognition accuracy. However, this technology has huge computational costs, even when the algorithms are implemented on graphic  ...", "url_pdf": null, "num_citations": 8, "cluster_id": "1459050142419828338", "authors": "L T\u00f3th, T Gr\u00f3sz - Text, Speech, and Dialogue", "url_citations": "http://scholar.google.com/scholar?cites=1459050142419828338&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 16, "url_citation": null, "title": "Deep sparse rectifier neural networks", "url": "http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_GlorotBB11.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=10040883758431450991&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2011", "excerpt": "Abstract While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield  ...", "url_pdf": "http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_GlorotBB11.pdf", "num_citations": 275, "cluster_id": "10040883758431450991", "authors": "X Glorot, A Bordes, Y Bengio - International  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=10040883758431450991&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 27, "url_citation": null, "title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6296526", "url_versions": "http://scholar.google.com/scholar?cluster=3674494786452480182&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes  ...", "url_pdf": null, "num_citations": 1010, "cluster_id": "3674494786452480182", "authors": "G Hinton, L Deng, D Yu, GE Dahl\u2026 - Signal Processing  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=3674494786452480182&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Phone recognition with deep sparse rectifier neural networks", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6639016", "url_versions": "http://scholar.google.com/scholar?cluster=12305065046743955542&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "ABSTRACT Rectifier neurons differ from standard ones only in that the sigmoid activation function is replaced by the rectifier function, max (0, x). This modification requires only minimal changes to any existing neural net implementation, but makes it more effective. In  ...", "url_pdf": null, "num_citations": 24, "cluster_id": "12305065046743955542", "authors": "L T\u00f3th - Acoustics, Speech and Signal Processing (ICASSP),  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=12305065046743955542&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Transition-based dependency parsing with stack long short-term memory", "url": "http://arxiv.org/abs/1505.08075", "url_versions": null, "year": "2015", "excerpt": "Abstract: We propose a technique for learning representations of parser states in transition-based dependency parsers. Our primary innovation is a new control structure for sequence-to-sequence neural networks---the stack LSTM. Like the conventional stack data  ...", "url_pdf": null, "num_citations": 10, "cluster_id": "14180674818440394404", "authors": "C Dyer, M Ballesteros, W Ling, A Matthews\u2026 - arXiv preprint arXiv: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=14180674818440394404&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "url": "http://arxiv.org/abs/1312.6120", "url_versions": "http://scholar.google.com/scholar?cluster=9090095758382098911&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by  ...", "url_pdf": null, "num_citations": 31, "cluster_id": "9090095758382098911", "authors": "AM Saxe, JL McClelland, S Ganguli - arXiv preprint arXiv:1312.6120", "url_citations": "http://scholar.google.com/scholar?cites=9090095758382098911&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Practical recommendations for gradient-based training of deep architectures", "url": "http://link.springer.com/chapter/10.1007/978-3-642-35289-8_26", "url_versions": "http://scholar.google.com/scholar?cluster=13214514639523956782&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract Learning algorithms related to artificial neural networks and in particular for Deep Learning may seem to involve many bells and whistles, called hyper-parameters. This chapter is meant as a practical guide with recommendations for some of the most  ...", "url_pdf": null, "num_citations": 91, "cluster_id": "13214514639523956782", "authors": "Y Bengio - Neural Networks: Tricks of the Trade", "url_citations": "http://scholar.google.com/scholar?cites=13214514639523956782&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Training neural networks with stochastic hessian-free optimization", "url": "http://arxiv.org/abs/1301.3641", "url_versions": "http://scholar.google.com/scholar?cluster=15998932101819720935&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: Hessian-free (HF) optimization has been successfully used for training deep autoencoders and recurrent networks. HF uses the conjugate gradient algorithm to construct update directions through curvature-vector products that can be computed on the same  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "15998932101819720935", "authors": "R Kiros - arXiv preprint arXiv:1301.3641", "url_citations": "http://scholar.google.com/scholar?cites=15998932101819720935&as_sdt=2005&sciodt=1,5&hl=en"}]