[{"num_versions": 4, "url_citation": null, "title": "Optimization techniques to improve training speed of deep neural networks for large speech tasks", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6619439", "url_versions": "http://scholar.google.com/scholar?cluster=8342459325676772309&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract\u2014While Deep Neural Networks (DNNs) have achieved tremendous success for large vocabulary continuous speech recognition (LVCSR) tasks, training these networks is slow. Even to date, the most common approach to train DNNs is via stochastic gradient  ...", "url_pdf": null, "num_citations": 21, "cluster_id": "8342459325676772309", "authors": "TN Sainath, B Kingsbury, H Soltau\u2026 - Audio, Speech, and  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=8342459325676772309&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Convergence rates of sub-sampled Newton methods", "url": "http://arxiv.org/abs/1508.02810", "url_versions": null, "year": "2015", "excerpt": "Abstract: We consider the problem of minimizing a sum of $ n $ functions over a convex parameter set $\\ mathcal {C}\\ subset\\ mathbb {R}^ p $ where $ n\\ gg p\\ gg 1$. In this regime, algorithms which utilize sub-sampling techniques are known to be effective. In this paper,  ...", "url_pdf": null, "num_citations": 0, "cluster_id": null, "authors": "MA Erdogdu, A Montanari - arXiv preprint arXiv:1508.02810", "url_citations": null}, {"num_versions": 17, "url_citation": null, "title": "Revisiting recurrent neural networks for robust ASR", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6288816", "url_versions": "http://scholar.google.com/scholar?cluster=9222172846140017196&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "ABSTRACT In this paper, we show how new training principles and optimization techniques for neural networks can be used for different network structures. In particular, we revisit the Recurrent Neural Network (RNN), which explicitly models the Markovian dynamics of a set  ...", "url_pdf": null, "num_citations": 49, "cluster_id": "9222172846140017196", "authors": "O Vinyals, SV Ravuri, D Povey - Acoustics, Speech and Signal  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=9222172846140017196&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Training neural networks with stochastic hessian-free optimization", "url": "http://arxiv.org/abs/1301.3641", "url_versions": "http://scholar.google.com/scholar?cluster=15998932101819720935&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: Hessian-free (HF) optimization has been successfully used for training deep autoencoders and recurrent networks. HF uses the conjugate gradient algorithm to construct update directions through curvature-vector products that can be computed on the same  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "15998932101819720935", "authors": "R Kiros - arXiv preprint arXiv:1301.3641", "url_citations": "http://scholar.google.com/scholar?cites=15998932101819720935&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "An adaptive low dimensional quasi-Newton sum of functions optimizer", "url": "http://ganguli-gang.stanford.edu/pdf/SFO.pdf", "url_versions": null, "year": "2013", "excerpt": "Abstract We present an algorithm for minimizing a sum of functions that combines the computational efficiency of stochastic gradient descent (SGD) with the second order curvature information accessible by quasi-Newton methods. We unify these disparate  ...", "url_pdf": "http://ganguli-gang.stanford.edu/pdf/SFO.pdf", "num_citations": 2, "cluster_id": "3212670083032126931", "authors": "J Sohl-Dickstein, B Poole\u2026 - CoRR abs/ \u2026", "url_citations": "http://scholar.google.com/scholar?cites=3212670083032126931&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Revisiting natural gradient for deep networks", "url": "http://arxiv.org/abs/1301.3584", "url_versions": "http://scholar.google.com/scholar?cluster=4887476036427842105&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: We evaluate natural gradient, an algorithm originally proposed in Amari (1997), for learning deep models. The contributions of this paper are as follows. We show the connection between natural gradient and three other recently proposed methods for  ...", "url_pdf": null, "num_citations": 30, "cluster_id": "4887476036427842105", "authors": "R Pascanu, Y Bengio - arXiv preprint arXiv:1301.3584", "url_citations": "http://scholar.google.com/scholar?cites=4887476036427842105&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Accelerating Hessian-free optimization for deep neural networks by implicit preconditioning and sampling", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6707747", "url_versions": "http://scholar.google.com/scholar?cluster=2293470901273086567&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Hessian-free training has become a popular parallel second order optimization technique for Deep Neural Network training. This study aims at speeding up Hessian-free training, both by means of decreasing the amount of data used for training, as well as through reduction  ...", "url_pdf": null, "num_citations": 4, "cluster_id": "2293470901273086567", "authors": "TN Sainath, L Horesh, B Kingsbury\u2026 - \u2026  (ASRU)", "url_citations": "http://scholar.google.com/scholar?cites=2293470901273086567&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "RMSProp and equilibrated adaptive learning rates for non-convex optimization", "url": "http://arxiv.org/abs/1502.04390", "url_versions": "http://scholar.google.com/scholar?cluster=18356366787403348938&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract: Parameter-specific adaptive learning rate methods are computationally efficient ways to reduce the ill-conditioning problems encountered when training large deep networks. Following recent work that strongly suggests that most of the critical points  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "18356366787403348938", "authors": "YN Dauphin, H de Vries, J Chung, Y Bengio - arXiv preprint arXiv: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=18356366787403348938&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Hybrid mlp/structured-svm tandem systems for large vocabulary and robust asr", "url": "http://scholar.google.com/https://mazsola.iit.uni-miskolc.hu/%7Eczap/letoltes/IS14/IS2014/PDF/AUTHOR/IS140399.PDF", "url_versions": "http://scholar.google.com/scholar?cluster=7677906558393594263&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract Tandem systems based on multi-layer perceptrons (MLPs) have improved the performance of automatic speech recognition systems on both large vocabulary and noisy tasks. One potential problem of the standard Tandem approach, however, is that the MLPs  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "7677906558393594263", "authors": "SV Ravuri - Proceedings of Interspeech, Sigapore", "url_citations": "http://scholar.google.com/scholar?cites=7677906558393594263&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "An empirical study of learning rates in deep neural networks for speech recognition", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6638963", "url_versions": "http://scholar.google.com/scholar?cluster=13453388075529867697&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "ABSTRACT Recent deep neural network systems for large vocabulary speech recognition are trained with minibatch stochastic gradient descent but use a variety of learning rate scheduling schemes. We investigate several of these schemes, particularly AdaGrad.  ...", "url_pdf": null, "num_citations": 34, "cluster_id": "13453388075529867697", "authors": "A Senior, G Heigold, MA Ranzato\u2026 - Acoustics, Speech and  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=13453388075529867697&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Deep learning for signal and information processing", "url": "http://cs.tju.edu.cn/web/docs/2013-Deep%20Learning%20for%20Signal%20and%20Information%20Processing.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=7346768574939973182&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "ABSTRACT This short monograph contains the material expanded from two tutorials that the authors gave, one at APSIPA in October 2011 and the other at ICASSP in March 2012. Substantial updates have been made based on the literature up to March, 2013, covering  ...", "url_pdf": "http://cs.tju.edu.cn/web/docs/2013-Deep%20Learning%20for%20Signal%20and%20Information%20Processing.pdf", "num_citations": 9, "cluster_id": "7346768574939973182", "authors": "L Deng, D Yu - Microsoft Research Monograph", "url_citations": "http://scholar.google.com/scholar?cites=7346768574939973182&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "Fast large-scale optimization by unifying stochastic gradient and quasi-Newton methods", "url": "http://arxiv.org/abs/1311.2115", "url_versions": "http://scholar.google.com/scholar?cluster=5987479414880920587&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: We present an algorithm for minimizing a sum of functions that combines the computational efficiency of stochastic gradient descent (SGD) with the second order curvature information leveraged by quasi-Newton methods. We unify these disparate  ...", "url_pdf": null, "num_citations": 12, "cluster_id": "5987479414880920587", "authors": "J Sohl-Dickstein, B Poole, S Ganguli - arXiv preprint arXiv:1311.2115", "url_citations": "http://scholar.google.com/scholar?cites=5987479414880920587&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Large vocabulary continuous speech recognition based on WFST structured classifiers and deep bottleneck features", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6639147", "url_versions": "http://scholar.google.com/scholar?cluster=16586910668180198347&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "ABSTRACT Recently, structured classification approaches have been considered important with a view to achieving unified modeling of the acoustic and linguistic aspects of speech recognizers. With these approaches, unified representation is achieved by directly  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "16586910668180198347", "authors": "Y Kubo, T Hori, A Nakamura - Acoustics, Speech and Signal  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=16586910668180198347&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Parallel Deep Neural Network Training for LVCSR Tasks using Blue Gene/Q", "url": "http://mazsola.iit.uni-miskolc.hu/%7Eczap/letoltes/IS14/IS2014/PDF/AUTHOR/IS140422.PDF", "url_versions": "http://scholar.google.com/scholar?cluster=17570746903888233157&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract While Deep Neural Networks (DNNs) have achieved tremendous success for LVCSR tasks, training these networks is slow. To date, the most common approach to train DNNs is via stochastic gradient descent (SGD), serially on a single GPU machine. Serial  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "17570746903888233157", "authors": "TN Sainath, I Chung\u2026 - \u2026  Conference of the  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=17570746903888233157&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Acoustic modeling based on deep conditional random fields", "url": "http://www.helwan.edu.eg/university/staff/%7Eyhifny/publications/dnn_crf.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=7966093255946522944&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract Acoustic modeling based on Hidden Markov Models (HMMs) is employed by state-of-theart stochastic speech recognition systems. In continuous density HMMs, the state scores are computed using Gaussian mixture models. On the other hand, Deep Neural  ...", "url_pdf": "http://www.helwan.edu.eg/university/staff/%7Eyhifny/publications/dnn_crf.pdf", "num_citations": 3, "cluster_id": "7966093255946522944", "authors": "Y Hifny - Deep Learning for Audio, Speech and Language  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=7966093255946522944&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Training recurrent neural networks", "url": "http://www.cs.utoronto.ca/%7Eilya/pubs/ilya_sutskever_phd_thesis.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=11547556497378421036&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Recurrent Neural Networks (RNNs) are artificial neural network models that are well-suited for pattern classification tasks whose inputs and outputs are sequences. The importance of developing methods for mapping sequences to sequences is exemplified by tasks such as  ...", "url_pdf": "http://www.cs.utoronto.ca/%7Eilya/pubs/ilya_sutskever_phd_thesis.pdf", "num_citations": 43, "cluster_id": "11547556497378421036", "authors": "I Sutskever -", "url_citations": "http://scholar.google.com/scholar?cites=11547556497378421036&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 13, "url_citation": null, "title": "Implementing neural networks efficiently", "url": "http://link.springer.com/chapter/10.1007/978-3-642-35289-8_28", "url_versions": "http://scholar.google.com/scholar?cluster=7301398305729577186&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract Neural networks and machine learning algorithms in general require a flexible environment where new algorithm prototypes and experiments can be set up as quickly as possible with best possible computational performance. To that end, we provide a new  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "7301398305729577186", "authors": "R Collobert, K Kavukcuoglu, C Farabet - Neural Networks: Tricks of the  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=7301398305729577186&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Training deep and recurrent networks with hessian-free optimization", "url": "http://link.springer.com/chapter/10.1007/978-3-642-35289-8_27", "url_versions": "http://scholar.google.com/scholar?cluster=3256736991833741484&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract In this chapter we will first describe the basic HF approach, and then examine well-known performance-improving techniques such as preconditioning which we have found to be beneficial for neural network training, as well as others of a more heuristic nature which  ...", "url_pdf": null, "num_citations": 34, "cluster_id": "3256736991833741484", "authors": "J Martens, I Sutskever - Neural Networks: Tricks of the Trade", "url_citations": "http://scholar.google.com/scholar?cites=3256736991833741484&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Identifying and attacking the saddle point problem in high-dimensional non-convex optimization", "url": "http://papers.nips.cc/paper/5486-sparse-pca-via-covariance-thresholding", "url_versions": "http://scholar.google.com/scholar?cluster=12321526113830855618&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract A central challenge to many fields of science and engineering involves minimizing non-convex error functions over continuous, high dimensional spaces. Gradient descent or quasi-Newton methods are almost ubiquitously used to perform such minimizations, and it  ...", "url_pdf": null, "num_citations": 32, "cluster_id": "12321526113830855618", "authors": "YN Dauphin, R Pascanu, C Gulcehre, K Cho\u2026 - Advances in Neural  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=12321526113830855618&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Parallel deep neural network training for big data on blue gene/Q", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7013048", "url_versions": "http://scholar.google.com/scholar?cluster=5227023182255212358&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract\u2014Deep Neural Networks (DNNs) have recently been shown to significantly outperform existing machine learning techniques in several pattern recognition tasks. DNNs are the state-of-the-art models used in image recognition, object detection, classification  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "5227023182255212358", "authors": "IH Chung, TN Sainath, B Ramabhadran\u2026 - \u2026  and Analysis, SC14: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=5227023182255212358&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 12, "url_citation": null, "title": "Foundations and Trends\u00ae in Signal Processing", "url": "http://research.microsoft.com:8082/pubs/209355/DeepLearning-NowPublishing-Vol7-SIG-039.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=15981304847159836793&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "7.1. Acoustic modeling for speech recognition 263 industrial researchers; see reviews in [8 9, 161]. The collaborative work started in phone recognition tasks [89, 100, 135, 136, 257, 260, 258, 309, 311, 334], demonstrating the power of hybrid DNN architectures discussed  ...", "url_pdf": "http://research.microsoft.com:8082/pubs/209355/DeepLearning-NowPublishing-Vol7-SIG-039.pdf", "num_citations": 3, "cluster_id": "15981304847159836793", "authors": "L Deng, Y Dong - Signal Processing", "url_citations": "http://scholar.google.com/scholar?cites=15981304847159836793&as_sdt=2005&sciodt=1,5&hl=en"}]