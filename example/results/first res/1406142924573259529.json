[{"num_versions": 9, "url_citation": null, "title": "Reinforcement learning and adaptive dynamic programming for feedback control", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5227780", "url_versions": "http://scholar.google.com/scholar?cluster=12709300483464030101&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "FL Lewis, D Vrabie - Circuits and Systems Magazine, IEEE", "excerpt": "Abstract Living organisms learn by acting on their environment, observing the resulting reward stimulus, and adjusting their actions accordingly to improve the reward. This actionbased or Reinforcement Learning can capture notions of optimal behavior occurring  ...", "url_pdf": null, "num_citations": 277, "cluster_id": "12709300483464030101", "year": "2009", "url_citations": "http://scholar.google.com/scholar?cites=12709300483464030101&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 12, "url_citation": null, "title": "A survey of collaborative filtering techniques", "url": "http://dl.acm.org/citation.cfm?id=1722966", "url_versions": "http://scholar.google.com/scholar?cluster=10005104099532699811&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "X Su, TM Khoshgoftaar - Advances in artificial intelligence", "excerpt": "Abstract As one of the most successful approaches to building recommender systems, collaborative filtering (CF) uses the known preferences of a group of users to make recommendations or predictions of the unknown preferences for other users. In this paper,  ...", "url_pdf": null, "num_citations": 1322, "cluster_id": "10005104099532699811", "year": "2009", "url_citations": "http://scholar.google.com/scholar?cites=10005104099532699811&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 33, "url_citation": null, "title": "Recent advances in hierarchical reinforcement learning", "url": "http://link.springer.com/article/10.1023/A:1022140919877", "url_versions": "http://scholar.google.com/scholar?cluster=15487186943679931860&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "AG Barto, S Mahadevan - Discrete Event Dynamic Systems", "excerpt": "Abstract Reinforcement learning is bedeviled by the curse of dimensionality: the number of parameters to be learned grows exponentially with the size of any compact encoding of a state. Recent attempts to combat the curse of dimensionality have turned to principled  ...", "url_pdf": null, "num_citations": 661, "cluster_id": "15487186943679931860", "year": "2003", "url_citations": "http://scholar.google.com/scholar?cites=15487186943679931860&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 21, "url_citation": null, "title": "A perspective view and survey of meta-learning", "url": "http://link.springer.com/article/10.1023/A:1019956318069", "url_versions": "http://scholar.google.com/scholar?cluster=4630399150623525617&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "R Vilalta, Y Drissi - Artificial Intelligence Review", "excerpt": "Abstract Different researchers hold different views of what the term meta-learning exactlymeans. The first part of this paper provides our own perspective view in which the goal isto build self-adaptive learners (ie learning algorithms that improve their bias  ...", "url_pdf": null, "num_citations": 337, "cluster_id": "4630399150623525617", "year": "2002", "url_citations": "http://scholar.google.com/scholar?cites=4630399150623525617&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 24, "url_citation": null, "title": "Affective learning\u2014a manifesto", "url": "http://link.springer.com/article/10.1023/B:BTTJ.0000047603.37042.33", "url_versions": "http://scholar.google.com/scholar?cluster=6564127566270062484&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "RW Picard, S Papert, W Bender, B Blumberg\u2026 - BT Technology  \u2026", "excerpt": "Abstract The use of the computer as a model, metaphor, and modelling tool has tended to privilege the'cognitive'over the'affective'by engendering theories in which thinking and learning are viewed as information processing and affect is ignored or marginalised. In the  ...", "url_pdf": null, "num_citations": 348, "cluster_id": "6564127566270062484", "year": "2004", "url_citations": "http://scholar.google.com/scholar?cites=6564127566270062484&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 11, "url_citation": null, "title": "Anytime point-based approximations for large POMDPs", "url": "http://www.jair.org/papers/paper2078.html", "url_versions": "http://scholar.google.com/scholar?cluster=6066517997526863348&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Pineau, G Gordon, S Thrun - Journal of Artificial Intelligence Research", "excerpt": "Abstract The Partially Observable Markov Decision Process has long been recognized as a rich framework for real-world planning and control problems, especially in robotics. However exact solutions in this framework are typically computationally intractable for all but the  ...", "url_pdf": null, "num_citations": 244, "cluster_id": "6066517997526863348", "year": "2006", "url_citations": "http://scholar.google.com/scholar?cites=6066517997526863348&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 43, "url_citation": null, "title": "R-max-a general polynomial time algorithm for near-optimal reinforcement learning", "url": "http://dl.acm.org/citation.cfm?id=944928", "url_versions": "http://scholar.google.com/scholar?cluster=9864822999783826074&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "RI Brafman, M Tennenholtz - The Journal of Machine Learning  \u2026", "excerpt": "Abstract R-MAX is a very simple model-based reinforcement learning algorithm which can attain near-optimal average reward in polynomial time. In R-MAX, the agent always maintains a complete, but possibly inaccurate model of its environment and acts based on  ...", "url_pdf": null, "num_citations": 586, "cluster_id": "9864822999783826074", "year": "2003", "url_citations": "http://scholar.google.com/scholar?cites=9864822999783826074&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Taxonomy and survey of RFID anti-collision protocols", "url": "http://www.sciencedirect.com/science/article/pii/S0140366405004718", "url_versions": "http://scholar.google.com/scholar?cluster=17690272223978292995&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "DH Shih, PL Sun, DC Yen, SM Huang - Computer communications", "excerpt": "Due to the limitless possibilities and low cost, Radio Frequency Identification (RFID) systems are used in a variety of applications to uniquely identify physical objects. The operation of RFID systems often involves a situation in which numerous tags are present in the  ...", "url_pdf": null, "num_citations": 307, "cluster_id": "17690272223978292995", "year": "2006", "url_citations": "http://scholar.google.com/scholar?cites=17690272223978292995&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 34, "url_citation": null, "title": "PEGASUS: A policy search method for large MDPs and POMDPs", "url": "http://dl.acm.org/citation.cfm?id=2073994", "url_versions": "http://scholar.google.com/scholar?cluster=17653476479171903737&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "AY Ng, M Jordan - Proceedings of the Sixteenth conference on  \u2026", "excerpt": "Abstract We propose a new approach to the problem of searching a space of policies for a Markov decision process (MDP) or a partially observable Markov decision process (POMDP), given a model. Our approach is based on the following observation: Any (PO)  ...", "url_pdf": null, "num_citations": 357, "cluster_id": "17653476479171903737", "year": "2000", "url_citations": "http://scholar.google.com/scholar?cites=17653476479171903737&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 35, "url_citation": null, "title": "Design patterns from biology for distributed computing", "url": "http://dl.acm.org/citation.cfm?id=1152937", "url_versions": "http://scholar.google.com/scholar?cluster=6988141751584327927&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "O Babaoglu, G Canright, A Deutsch, GAD Caro\u2026 - ACM Transactions on  \u2026", "excerpt": "Abstract Recent developments in information technology have brought about important changes in distributed computing. New environments such as massively large-scale, wide-area computer networks and mobile ad hoc networks have emerged. Common  ...", "url_pdf": null, "num_citations": 301, "cluster_id": "6988141751584327927", "year": "2006", "url_citations": "http://scholar.google.com/scholar?cites=6988141751584327927&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 18, "url_citation": null, "title": "Technical update: Least-squares temporal difference learning", "url": "http://link.springer.com/article/10.1023/A:1017936530646", "url_versions": "http://scholar.google.com/scholar?cluster=15695765017152043538&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "JA Boyan - Machine Learning", "excerpt": "Abstract TD. \u03bb/is a popular family of algorithms for approximate policy evaluation in large MDPs. TD. \u03bb/works by incrementally updating the value function after each observed transition. It has two major drawbacks: it may make inefficient use of data, and it requires  ...", "url_pdf": null, "num_citations": 249, "cluster_id": "15695765017152043538", "year": "2002", "url_citations": "http://scholar.google.com/scholar?cites=15695765017152043538&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 27, "url_citation": null, "title": "Combining online and offline knowledge in UCT", "url": "http://dl.acm.org/citation.cfm?id=1273531", "url_versions": "http://scholar.google.com/scholar?cluster=511093500991299005&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Gelly, D Silver - Proceedings of the 24th international conference on  \u2026", "excerpt": "Abstract The UCT algorithm learns a value function online using sample-based search. The TD (\u03bb) algorithm can learn a value function offline for the on-policy distribution. We consider three approaches for combining offline and online value functions in the UCT algorithm.  ...", "url_pdf": null, "num_citations": 388, "cluster_id": "511093500991299005", "year": "2007", "url_citations": "http://scholar.google.com/scholar?cites=511093500991299005&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 23, "url_citation": null, "title": "Research challenges of autonomic computing", "url": "http://dl.acm.org/citation.cfm?id=1062464", "url_versions": "http://scholar.google.com/scholar?cluster=10626991808897417975&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "JO Kephart - Proceedings of the 27th international conference on  \u2026", "excerpt": "Abstract Autonomic computing is a grand-challenge vision of the future in which computing systems will manage themselves in accordance with high-level objectives specified by humans. The IT industry recognizes that meeting this challenge is imperative; otherwise,  ...", "url_pdf": null, "num_citations": 337, "cluster_id": "10626991808897417975", "year": "2005", "url_citations": "http://scholar.google.com/scholar?cites=10626991808897417975&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 15, "url_citation": null, "title": "Searching in metric spaces", "url": "http://dl.acm.org/citation.cfm?id=502808", "url_versions": "http://scholar.google.com/scholar?cluster=246402142163978580&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "E Ch\u00e1vez, G Navarro, R Baeza-Yates\u2026 - ACM computing surveys  \u2026", "excerpt": "Abstract The problem of searching the elements of a set that are close to a given query element under some similarity criterion has a vast number of applications in many branches of computer science, from pattern recognition to textual and multimedia information  ...", "url_pdf": null, "num_citations": 1225, "cluster_id": "246402142163978580", "year": "2001", "url_citations": "http://scholar.google.com/scholar?cites=246402142163978580&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 31, "url_citation": null, "title": "Near-optimal reinforcement learning in polynomial time", "url": "http://link.springer.com/article/10.1023/A:1017984413808", "url_versions": "http://scholar.google.com/scholar?cluster=16451624874841151226&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "M Kearns, S Singh - Machine Learning", "excerpt": "Abstract We present new algorithms for reinforcement learning and prove that they have polynomial bounds on the resources required to achieve near-optimal return in general Markov decision processes. After observing that the number of actions required to  ...", "url_pdf": null, "num_citations": 531, "cluster_id": "16451624874841151226", "year": "2002", "url_citations": "http://scholar.google.com/scholar?cites=16451624874841151226&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 42, "url_citation": null, "title": "Finite-time analysis of the multiarmed bandit problem", "url": "http://link.springer.com/article/10.1023/a:1013689704352", "url_versions": "http://scholar.google.com/scholar?cluster=14556375097336785863&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "P Auer, N Cesa-Bianchi, P Fischer - Machine learning", "excerpt": "Abstract Reinforcement learning policies face the exploration versus exploitation dilemma, ie the search for a balance between exploring the environment to find profitable actions while taking the empirically best action as often as possible. A popular measure of a  ...", "url_pdf": null, "num_citations": 1778, "cluster_id": "14556375097336785863", "year": "2002", "url_citations": "http://scholar.google.com/scholar?cites=14556375097336785863&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 15, "url_citation": null, "title": "A survey of autonomic computing\u2014degrees, models, and applications", "url": "http://dl.acm.org/citation.cfm?id=1380585", "url_versions": "http://scholar.google.com/scholar?cluster=4832579246656302746&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "MC Huebscher, JA McCann - ACM Computing Surveys (CSUR)", "excerpt": "Abstract Autonomic Computing is a concept that brings together many fields of computing with the purpose of creating computing systems that self-manage. In its early days it was criticised as being a \u201chype topic\u201d or a rebadging of some Multi Agent Systems work. In this  ...", "url_pdf": null, "num_citations": 603, "cluster_id": "4832579246656302746", "year": "2008", "url_citations": "http://scholar.google.com/scholar?cites=4832579246656302746&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 15, "url_citation": null, "title": "Elevator group control using multiple reinforcement learning agents", "url": "http://link.springer.com/article/10.1023/A:1007518724497", "url_versions": "http://scholar.google.com/scholar?cluster=10963221272726557928&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "RH Crites, AG Barto - Machine Learning", "excerpt": "Abstract Recent algorithmic and theoretical advances in reinforcement learning (RL) have attracted widespread interest. RL algorithms have appeared that approximate dynamic programming on an incremental basis. They can be trained on the basis of real or  ...", "url_pdf": null, "num_citations": 276, "cluster_id": "10963221272726557928", "year": "1998", "url_citations": "http://scholar.google.com/scholar?cites=10963221272726557928&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 13, "url_citation": null, "title": "Learning to cooperate via policy search", "url": "http://dl.acm.org/citation.cfm?id=2074003", "url_versions": "http://scholar.google.com/scholar?cluster=7578093172783386304&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "L Peshkin, KE Kim, N Meuleau\u2026 - Proceedings of the  \u2026", "excerpt": "Abstract Cooperative games are those in which both agents share the same payoff structure. Value-based reinforcement-learning algorithms, such as variants of Q-learning, have been applied to learning cooperative games, but they only apply when the game state is  ...", "url_pdf": null, "num_citations": 273, "cluster_id": "7578093172783386304", "year": "2000", "url_citations": "http://scholar.google.com/scholar?cites=7578093172783386304&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 13, "url_citation": null, "title": "Online actor\u2013critic algorithm to solve the continuous-time infinite horizon optimal control problem", "url": "http://www.sciencedirect.com/science/article/pii/S0005109810000907", "url_versions": "http://scholar.google.com/scholar?cluster=13643844156595950812&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "KG Vamvoudakis, FL Lewis - Automatica", "excerpt": "In this paper we discuss an online algorithm based on policy iteration for learning the continuous-time (CT) optimal control solution with infinite horizon cost for nonlinear systems with known dynamics. That is, the algorithm learns online in real-time the solution to the  ...", "url_pdf": null, "num_citations": 252, "cluster_id": "13643844156595950812", "year": "2010", "url_citations": "http://scholar.google.com/scholar?cites=13643844156595950812&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 17, "url_citation": null, "title": "A tutorial on adaptive MCMC", "url": "http://link.springer.com/article/10.1007/s11222-008-9110-y", "url_versions": "http://scholar.google.com/scholar?cluster=11299600299439849663&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "C Andrieu, J Thoms - Statistics and Computing", "excerpt": "Abstract We review adaptive Markov chain Monte Carlo algorithms (MCMC) as a mean to optimise their performance. Using simple toy examples we review their theoretical underpinnings, and in particular show why adaptive MCMC algorithms might fail when  ...", "url_pdf": null, "num_citations": 291, "cluster_id": "11299600299439849663", "year": "2008", "url_citations": "http://scholar.google.com/scholar?cites=11299600299439849663&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 31, "url_citation": null, "title": "Perseus: Randomized point-based value iteration for POMDPs", "url": "http://www.jair.org/papers/paper1659.html", "url_versions": "http://scholar.google.com/scholar?cluster=4741917294529451345&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "MTJ Spaan, N Vlassis - Journal of artificial intelligence research", "excerpt": "Abstract Partially observable Markov decision processes (POMDPs) form an attractive and principled framework for agent planning under uncertainty. Point-based approximate techniques for POMDPs compute a policy based on a finite set of points collected in  ...", "url_pdf": null, "num_citations": 508, "cluster_id": "4741917294529451345", "year": "2005", "url_citations": "http://scholar.google.com/scholar?cites=4741917294529451345&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 18, "url_citation": null, "title": "Transfer learning for reinforcement learning domains: A survey", "url": "http://dl.acm.org/citation.cfm?id=1755839", "url_versions": "http://scholar.google.com/scholar?cluster=8985386711450788984&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "ME Taylor, P Stone - The Journal of Machine Learning Research", "excerpt": "Abstract The reinforcement learning paradigm is a popular way to address problems that have only limited environmental feedback, rather than correctly labeled examples, as is common in other machine learning contexts. While significant progress has been made to  ...", "url_pdf": null, "num_citations": 330, "cluster_id": "8985386711450788984", "year": "2009", "url_citations": "http://scholar.google.com/scholar?cites=8985386711450788984&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 14, "url_citation": null, "title": "Accuracy-based learning classifier systems: models, analysis and applications to classification tasks", "url": "http://www.mitpressjournals.org/doi/abs/10.1162/106365603322365289", "url_versions": "http://scholar.google.com/scholar?cluster=5953356189304724961&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "E Bernad\u00f3-Mansilla, JM Garrell-Guiu - Evolutionary computation", "excerpt": "Abstract Recently, Learning Classifier Systems (LCS) and particularly XCS have arisen as promising methods for classification tasks and data mining. This paper investigates two models of accuracy-based learning classifier systems on different types of classification  ...", "url_pdf": null, "num_citations": 256, "cluster_id": "5953356189304724961", "year": "2003", "url_citations": "http://scholar.google.com/scholar?cites=5953356189304724961&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 39, "url_citation": null, "title": "Hierarchical reinforcement learning with the MAXQ value function decomposition", "url": "http://www.jair.org/media/639/live-639-1833-jair.ps.Z", "url_versions": "http://scholar.google.com/scholar?cluster=14687718141557939219&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "TG Dietterich - J. Artif. Intell. Res.(JAIR)", "excerpt": "Abstract This paper presents a new approach to hierarchical reinforcement learning based on decomposing the target Markov decision process (MDP) into a hierarchy of smaller MDPs and decomposing the value function of the target MDP into an additive combination of the  ...", "url_pdf": null, "num_citations": 923, "cluster_id": "14687718141557939219", "year": "2000", "url_citations": "http://scholar.google.com/scholar?cites=14687718141557939219&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 29, "url_citation": null, "title": "Least-squares policy iteration", "url": "http://dl.acm.org/citation.cfm?id=964290", "url_versions": "http://scholar.google.com/scholar?cluster=6154525837768216314&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "MG Lagoudakis, R Parr - The Journal of Machine Learning Research", "excerpt": "Abstract We propose a new approach to reinforcement learning for control problems which combines value-function approximation with linear architectures and approximate policy iteration. This new approach is motivated by the least-squares temporal-difference  ...", "url_pdf": null, "num_citations": 805, "cluster_id": "6154525837768216314", "year": "2003", "url_citations": "http://scholar.google.com/scholar?cites=6154525837768216314&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 16, "url_citation": null, "title": "Eddies: Continuously adaptive query processing", "url": "http://dl.acm.org/citation.cfm?id=335420", "url_versions": "http://scholar.google.com/scholar?cluster=13049208738754012194&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "R Avnur, JM Hellerstein - ACM SIGMoD Record", "excerpt": "Abstract In large federated and shared-nothing databases, resources can exhibit widely fluctuating characteristics. Assumptions made at the time a query is submitted will rarely hold throughout the duration of query processing. As a result, traditional static query  ...", "url_pdf": null, "num_citations": 961, "cluster_id": "13049208738754012194", "year": "2000", "url_citations": "http://scholar.google.com/scholar?cites=13049208738754012194&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 76, "url_citation": null, "title": "Ant algorithms for discrete optimization", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6787854", "url_versions": "http://scholar.google.com/scholar?cluster=3095672968044935365&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "M Dorigo, GD Caro, LM Gambardella - Artificial life", "excerpt": "Abstract This article presents an overview of recent work on ant algorithms, that is, algorithms for discrete optimization that took inspiration from the observation of ant colonies' foraging behavior, and introduces the ant colony optimization (ACO) metaheuristic. In the  ...", "url_pdf": null, "num_citations": 2906, "cluster_id": "3095672968044935365", "year": "1999", "url_citations": "http://scholar.google.com/scholar?cites=3095672968044935365&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 23, "url_citation": null, "title": "Optimizing dialogue management with reinforcement learning: Experiments with the NJFun system", "url": "http://www.jair.org/papers/paper859.html", "url_versions": "http://scholar.google.com/scholar?cluster=11281102214699073136&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Singh, D Litman, M Kearns, M Walker - Journal of Artificial Intelligence  \u2026", "excerpt": "Abstract Designing the dialogue policy of a spoken dialogue system involves many nontrivial choices. This paper presents a reinforcement learning approach for automatically optimizing a dialogue policy, which addresses the technical challenges in applying  ...", "url_pdf": null, "num_citations": 281, "cluster_id": "11281102214699073136", "year": "2002", "url_citations": "http://scholar.google.com/scholar?cites=11281102214699073136&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 64, "url_citation": null, "title": "Learning deep architectures for AI", "url": "http://dl.acm.org/citation.cfm?id=1658424", "url_versions": "http://scholar.google.com/scholar?cluster=5331804836605365413&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Y Bengio - Foundations and trends\u00ae in Machine Learning", "excerpt": "Abstract Theoretical results suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (eg, in vision, language, and other AI-level tasks), one may need deep architectures. Deep architectures are composed of multiple levels of  ...", "url_pdf": null, "num_citations": 1847, "cluster_id": "5331804836605365413", "year": "2009", "url_citations": "http://scholar.google.com/scholar?cites=5331804836605365413&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 26, "url_citation": null, "title": "Metalearning and neuromodulation", "url": "http://www.sciencedirect.com/science/article/pii/S0893608002000448", "url_versions": "http://scholar.google.com/scholar?cluster=16707744385914625648&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "K Doya - Neural Networks", "excerpt": "This paper presents a computational theory on the roles of the ascending neuromodulatory systems from the viewpoint that they mediate the global signals that regulate the distributed learning mechanisms in the brain. Based on the review of experimental data and  ...", "url_pdf": null, "num_citations": 440, "cluster_id": "16707744385914625648", "year": "2002", "url_citations": "http://scholar.google.com/scholar?cites=16707744385914625648&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 32, "url_citation": null, "title": "Opponent interactions between serotonin and dopamine", "url": "http://www.sciencedirect.com/science/article/pii/S0893608002000527", "url_versions": "http://scholar.google.com/scholar?cluster=7604665086989227269&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "ND Daw, S Kakade, P Dayan - Neural Networks", "excerpt": "Anatomical and pharmacological evidence suggests that the dorsal raphe serotonin system and the ventral tegmental and substantia nigra dopamine system may act as mutual opponents. In the light of the temporal difference model of the involvement of the  ...", "url_pdf": null, "num_citations": 476, "cluster_id": "7604665086989227269", "year": "2002", "url_citations": "http://scholar.google.com/scholar?cites=7604665086989227269&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 20, "url_citation": null, "title": "Efficient selectivity and backup operators in Monte-Carlo tree search", "url": "http://link.springer.com/chapter/10.1007/978-3-540-75538-8_7", "url_versions": "http://scholar.google.com/scholar?cluster=3795826527361753347&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "R Coulom - Computers and games", "excerpt": "Abstract A Monte-Carlo evaluation consists in estimating a position by averaging the outcome of several random continuations. The method can serve as an evaluation function at the leaves of a min-max tree. This paper presents a new framework to combine tree  ...", "url_pdf": null, "num_citations": 450, "cluster_id": "3795826527361753347", "year": "2007", "url_citations": "http://scholar.google.com/scholar?cites=3795826527361753347&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 14, "url_citation": null, "title": "Congestion-dependent pricing of network services", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842140", "url_versions": "http://scholar.google.com/scholar?cluster=7478617630230788571&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "IC Paschalidis, JN Tsitsiklis - Networking, IEEE/ACM  \u2026", "excerpt": "Abstract\u2014We consider a service provider (SP) who provides access to a communication network or some other form of on-line services. Users initiate calls that belong to a set of diverse service classes, differing in resource requirements, demand pattern, and call  ...", "url_pdf": null, "num_citations": 351, "cluster_id": "7478617630230788571", "year": "2000", "url_citations": "http://scholar.google.com/scholar?cites=7478617630230788571&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 29, "url_citation": null, "title": "If multi-agent learning is the answer, what is the question?", "url": "http://www.sciencedirect.com/science/article/pii/S0004370207000495", "url_versions": "http://scholar.google.com/scholar?cluster=14654813392048754111&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Y Shoham, R Powers, T Grenager - Artificial Intelligence", "excerpt": "The area of learning in multi-agent systems is today one of the most fertile grounds for interaction between game theory and artificial intelligence. We focus on the foundational questions in this interdisciplinary area, and identify several distinct agendas that ought to,  ...", "url_pdf": null, "num_citations": 243, "cluster_id": "14654813392048754111", "year": "2007", "url_citations": "http://scholar.google.com/scholar?cites=14654813392048754111&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 28, "url_citation": null, "title": "Agent-based computational economics: Growing economies from the bottom up", "url": "http://www.mitpressjournals.org/doi/abs/10.1162/106454602753694765", "url_versions": "http://scholar.google.com/scholar?cluster=16419898962720328873&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "L Tesfatsion - Artificial life", "excerpt": "Abstract Agent-based computational economics (ACE) is the computational study of economies modeled as evolving systems of autonomous interacting agents. Thus, ACE is a specialization of economics of the basic complex adaptive systems paradigm. This study  ...", "url_pdf": null, "num_citations": 771, "cluster_id": "16419898962720328873", "year": "2002", "url_citations": "http://scholar.google.com/scholar?cites=16419898962720328873&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 20, "url_citation": null, "title": "Cooperative multi-agent learning: The state of the art", "url": "http://dl.acm.org/citation.cfm?id=1090753", "url_versions": "http://scholar.google.com/scholar?cluster=4539944020768348881&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "L Panait, S Luke - Autonomous Agents and Multi-Agent Systems", "excerpt": "Abstract Cooperative multi-agent systems (MAS) are ones in which several agents attempt, through their interaction, to jointly solve tasks or to maximize utility. Due to the interactions among the agents, multi-agent problem complexity can rise rapidly with the number of  ...", "url_pdf": null, "num_citations": 702, "cluster_id": "4539944020768348881", "year": "2005", "url_citations": "http://scholar.google.com/scholar?cites=4539944020768348881&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 21, "url_citation": null, "title": "Convergence results for single-step on-policy reinforcement-learning algorithms", "url": "http://link.springer.com/article/10.1023/A:1007678930559", "url_versions": "http://scholar.google.com/scholar?cluster=14446329391232201557&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Singh, T Jaakkola, ML Littman, C Szepesv\u00e1ri - Machine Learning", "excerpt": "Abstract An important application of reinforcement learning (RL) is to finite-state control problems and one of the most difficult problems in learning for control is balancing the exploration/exploitation tradeoff. Existing theoretical results for RL give very little guidance  ...", "url_pdf": null, "num_citations": 407, "cluster_id": "14446329391232201557", "year": "2000", "url_citations": "http://scholar.google.com/scholar?cites=14446329391232201557&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 33, "url_citation": null, "title": "Making working memory work: a computational model of learning in the prefrontal cortex and basal ganglia", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6789689", "url_versions": "http://scholar.google.com/scholar?cluster=5436275443219488449&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "RC O'Reilly, MJ Frank - Neural computation", "excerpt": "The prefrontal cortex has long been thought to subserve both working memory (the holding of information online for processing) and executive functions (deciding how to manipulate working memory and perform processing). Although many computational models of  ...", "url_pdf": null, "num_citations": 533, "cluster_id": "5436275443219488449", "year": "2006", "url_citations": "http://scholar.google.com/scholar?cites=5436275443219488449&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 17, "url_citation": null, "title": "An algorithmic description of XCS", "url": "http://link.springer.com/chapter/10.1007/3-540-44640-0_15", "url_versions": "http://scholar.google.com/scholar?cluster=18056372387448477514&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "MV Butz, SW Wilson - Advances in Learning Classifier Systems", "excerpt": "Abstract A concise description of the XCS classifier system's parameters, structures, and algorithms is presented as an aid to research. The algorithms are written in modularly structured pseudo code with accompanying explanations.", "url_pdf": null, "num_citations": 309, "cluster_id": "18056372387448477514", "year": "2001", "url_citations": "http://scholar.google.com/scholar?cites=18056372387448477514&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 21, "url_citation": null, "title": "A classification scheme for negotiation in electronic commerce", "url": "http://link.springer.com/chapter/10.1007/3-540-44682-6_2", "url_versions": "http://scholar.google.com/scholar?cluster=3995574680027119914&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "AR Lomuscio, M Wooldridge, NR Jennings - Agent Mediated Electronic  \u2026", "excerpt": "Abstract In the last few years we have witnessed a surge of business-to-consumer and business-to-business commerce operated on the Internet. However many of these systems are often nothing more than electronic catalogues on which the user can choose a product  ...", "url_pdf": null, "num_citations": 249, "cluster_id": "3995574680027119914", "year": "2001", "url_citations": "http://scholar.google.com/scholar?cites=3995574680027119914&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 41, "url_citation": null, "title": "Policy search for motor primitives in robotics", "url": "http://papers.nips.cc/paper/3545-policy-search-for-motor-primitives-in-robotics", "url_versions": "http://scholar.google.com/scholar?cluster=12175723072765799926&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Kober, JR Peters - Advances in neural information processing  \u2026", "excerpt": "Abstract Many motor skills in humanoid robotics can be learned using parametrized motor primitives as done in imitation learning. However, most interesting motor learning problems are high-dimensional reinforcement learning problems often beyond the reach of current  ...", "url_pdf": null, "num_citations": 250, "cluster_id": "12175723072765799926", "year": "2009", "url_citations": "http://scholar.google.com/scholar?cites=12175723072765799926&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 18, "url_citation": null, "title": "Using confidence bounds for exploitation-exploration trade-offs", "url": "http://dl.acm.org/citation.cfm?id=944941", "url_versions": "http://scholar.google.com/scholar?cluster=9040589232717839848&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "P Auer - The Journal of Machine Learning Research", "excerpt": "Abstract We show how a standard tool from statistics---namely confidence bounds---can be used to elegantly deal with situations which exhibit an exploitation-exploration trade-off. Our technique for designing and analyzing algorithms for such situations is general and can  ...", "url_pdf": null, "num_citations": 309, "cluster_id": "9040589232717839848", "year": "2003", "url_citations": "http://scholar.google.com/scholar?cites=9040589232717839848&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 14, "url_citation": null, "title": "Multiple model-based reinforcement learning", "url": "http://www.mitpressjournals.org/doi/abs/10.1162/089976602753712972", "url_versions": "http://scholar.google.com/scholar?cluster=17294833705705749571&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "K Doya, K Samejima, K Katagiri, M Kawato - Neural computation", "excerpt": "A big issue in the application of reinforcement learning (RL) to real-world control problems is how to deal with nonlinearity and nonstationarity. For a nonlinear, high-dimensional system, the conventional discretizing approach necessitates a huge number of states, which  ...", "url_pdf": null, "num_citations": 299, "cluster_id": "17294833705705749571", "year": "2002", "url_citations": "http://scholar.google.com/scholar?cites=17294833705705749571&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Adaptive dynamic programming: an introduction", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4840325", "url_versions": "http://scholar.google.com/scholar?cluster=3187085425393611481&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "FY Wang, H Zhang, D Liu - \u2026  Intelligence Magazine, IEEE", "excerpt": "Abstract: In this article, we introduce some recent research trends within the field of adaptive/approximate dynamic programming (ADP), including the variations on the structure of ADP schemes, the development of ADP algorithms and applications of ADP schemes.  ...", "url_pdf": null, "num_citations": 311, "cluster_id": "3187085425393611481", "year": "2009", "url_citations": "http://scholar.google.com/scholar?cites=3187085425393611481&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 21, "url_citation": null, "title": "Reinforcement learning in continuous time and space", "url": "http://www.mitpressjournals.org/doi/abs/10.1162/089976600300015961", "url_versions": "http://scholar.google.com/scholar?cluster=6940306061526307175&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "K Doya - Neural computation", "excerpt": "The performance of the proposed algorithms is first tested in a nonlinear control task of swinging a pendulum up with limited torque. It is shown in the simulations that (1) the task is accomplished by the continuous actor-critic method in a number of trials several times  ...", "url_pdf": null, "num_citations": 569, "cluster_id": "6940306061526307175", "year": "2000", "url_citations": "http://scholar.google.com/scholar?cites=6940306061526307175&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 22, "url_citation": null, "title": "Infinite-horizon policy-gradient estimation", "url": "http://www.jair.org/papers/paper806.html", "url_versions": "http://scholar.google.com/scholar?cluster=9191776830518090033&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Baxter, PL Bartlett - Journal of Artificial Intelligence Research", "excerpt": "Abstract Gradient-based approaches to direct policy search in reinforcement learning have received much recent attention as a means to solve problems of partial observability and to avoid some of the problems associated with policy degradation in value-function methods.  ...", "url_pdf": null, "num_citations": 470, "cluster_id": "9191776830518090033", "year": "2001", "url_citations": "http://scholar.google.com/scholar?cites=9191776830518090033&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "A graph-based evolutionary algorithm: genetic network programming (GNP) and its extension using reinforcement learning", "url": "http://www.mitpressjournals.org/doi/abs/10.1162/evco.2007.15.3.369", "url_versions": "http://scholar.google.com/scholar?cluster=5787769523084835237&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Mabu, K Hirasawa, J Hu - Evolutionary Computation", "excerpt": "Abstract This paper proposes a graph-based evolutionary algorithm called Genetic Network Programming (GNP). Our goal is to develop GNP, which can deal with dynamic environments efficiently and effectively, based on the distinguished expression ability of  ...", "url_pdf": null, "num_citations": 263, "cluster_id": "5787769523084835237", "year": "2007", "url_citations": "http://scholar.google.com/scholar?cites=5787769523084835237&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 24, "url_citation": null, "title": "Nash Q-learning for general-sum stochastic games", "url": "http://dl.acm.org/citation.cfm?id=964288", "url_versions": "http://scholar.google.com/scholar?cluster=15770908142918829857&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Hu, MP Wellman - The Journal of Machine Learning Research", "excerpt": "Abstract We extend Q-learning to a noncooperative multiagent context, using the framework of general-sum stochastic games. A learning agent maintains Q-functions over joint actions, and performs updates based on assuming Nash equilibrium behavior over the current Q- ...", "url_pdf": null, "num_citations": 484, "cluster_id": "15770908142918829857", "year": "2003", "url_citations": "http://scholar.google.com/scholar?cites=15770908142918829857&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 13, "url_citation": null, "title": "Neural fitted Q iteration\u2013first experiences with a data efficient neural reinforcement learning method", "url": "http://link.springer.com/chapter/10.1007/11564096_32", "url_versions": "http://scholar.google.com/scholar?cluster=8156369906861868334&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "M Riedmiller - Machine Learning: ECML", "excerpt": "Abstract This paper introduces NFQ, an algorithm for efficient and effective training of a Q-value function represented by a multi-layer perceptron. Based on the principle of storing and reusing transition experiences, a model-free, neural network based Reinforcement  ...", "url_pdf": null, "num_citations": 279, "cluster_id": "8156369906861868334", "year": "2005", "url_citations": "http://scholar.google.com/scholar?cites=8156369906861868334&as_sdt=2005&sciodt=1,5&hl=en"}]