[{"num_versions": 4, "url_citation": null, "title": "Deep Sentence Embedding Using the Long Short Term Memory Network: Analysis and Application to Information Retrieval", "url": "http://arxiv.org/abs/1502.06922", "url_versions": "http://scholar.google.com/scholar?cluster=7867332744119866686&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract: This paper develops a model that addresses sentence embedding using recurrent neural networks (RNN) with Long Short Term Memory (LSTM) cells. The proposed LSTM-RNN model sequentially takes each word in a sentence, extracts its information, and  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "7867332744119866686", "authors": "H Palangi, L Deng, Y Shen, J Gao, X He\u2026 - arXiv preprint arXiv: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=7867332744119866686&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "On the difficulty of training recurrent neural networks", "url": "http://arxiv.org/abs/1211.5063", "url_versions": "http://scholar.google.com/scholar?cluster=1123023677976606946&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract: There are two widely known issues with properly training Recurrent Neural Networks, the vanishing and the exploding gradient problems detailed in Bengio et al.(1994). In this paper we attempt to improve the understanding of the underlying issues  ...", "url_pdf": null, "num_citations": 105, "cluster_id": "1123023677976606946", "authors": "R Pascanu, T Mikolov, Y Bengio - arXiv preprint arXiv:1211.5063", "url_citations": "http://scholar.google.com/scholar?cites=1123023677976606946&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Fundamental Knowledge of Machine Learning", "url": "http://link.springer.com/chapter/10.1007/978-981-287-468-9_2", "url_versions": null, "year": "2015", "excerpt": "Abstract This chapter introduces the basic concepts and methods of machine learning that are related to this book. The classical machine learning methods, like neural network (CNN), support vector machine (SVM), clustering, Bayesian networks, sparse learning, Boosting,  ...", "url_pdf": null, "num_citations": 0, "cluster_id": null, "authors": "L Xu, W Lin, CCJ Kuo - Visual Quality Assessment by Machine Learning", "url_citations": null}, {"num_versions": 12, "url_citation": null, "title": "Foundations and Trends\u00ae in Signal Processing", "url": "http://research.microsoft.com:8082/pubs/209355/DeepLearning-NowPublishing-Vol7-SIG-039.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=15981304847159836793&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "7.1. Acoustic modeling for speech recognition 263 industrial researchers; see reviews in [8 9, 161]. The collaborative work started in phone recognition tasks [89, 100, 135, 136, 257, 260, 258, 309, 311, 334], demonstrating the power of hybrid DNN architectures discussed  ...", "url_pdf": "http://research.microsoft.com:8082/pubs/209355/DeepLearning-NowPublishing-Vol7-SIG-039.pdf", "num_citations": 3, "cluster_id": "15981304847159836793", "authors": "L Deng, Y Dong - Signal Processing", "url_citations": "http://scholar.google.com/scholar?cites=15981304847159836793&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Audio Chord Recognition with Recurrent Neural Networks.", "url": "http://www-etud.iro.umontreal.ca/%7Eboulanni/ISMIR2013.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=8644784458455419344&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "ABSTRACT In this paper, we present an audio chord recognition system based on a recurrent neural network. The audio features are obtained from a deep neural network optimized with a combination of chromagram targets and chord information, and  ...", "url_pdf": "http://www-etud.iro.umontreal.ca/%7Eboulanni/ISMIR2013.pdf", "num_citations": 17, "cluster_id": "8644784458455419344", "authors": "N Boulanger-Lewandowski, Y Bengio\u2026 - ISMIR", "url_citations": "http://scholar.google.com/scholar?cites=8644784458455419344&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "Deep learning of representations: Looking forward", "url": "http://link.springer.com/chapter/10.1007/978-3-642-39593-2_1", "url_versions": "http://scholar.google.com/scholar?cluster=16988628068303769209&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract Deep learning research aims at discovering learning algorithms that discover multiple levels of distributed representations, with higher levels representing more abstract concepts. Although the study of deep learning has already led to impressive theoretical  ...", "url_pdf": null, "num_citations": 86, "cluster_id": "16988628068303769209", "authors": "Y Bengio - Statistical Language and Speech Processing", "url_citations": "http://scholar.google.com/scholar?cites=16988628068303769209&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 16, "url_citation": null, "title": "New types of deep neural network learning for speech recognition and related applications: An overview", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6639344", "url_versions": "http://scholar.google.com/scholar?cluster=10871829039953032247&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "ABSTRACT In this paper, we provide an overview of the invited and contributed papers presented at the special session at ICASSP-2013, entitled \u201cNew Types of Deep Neural Network Learning for Speech Recognition and Related Applications,\u201d as organized by the  ...", "url_pdf": null, "num_citations": 82, "cluster_id": "10871829039953032247", "authors": "L Deng, G Hinton, B Kingsbury - Acoustics, Speech and Signal  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=10871829039953032247&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Recurrent Deep-Stacking Networks for sequence classification", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6889295", "url_versions": "http://scholar.google.com/scholar?cluster=13475775951960483399&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "ABSTRACT Deep Stacking Networks (DSNs) are constructed by stacking shallow feed-forward neural networks on top of each other using concatenated features derived from the lower modules of the DSN and the raw input data. DSNs do not have re current  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "13475775951960483399", "authors": "H Palangi, L Deng, RK Ward - Signal and Information  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=13475775951960483399&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Three classes of deep learning architectures and their applications: a tutorial survey", "url": "http://research.microsoft.com/pubs/192937/transactions-apsipa.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=6223016292750369967&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2012", "excerpt": "Abstract\u2014In this invited paper, my overview material on the same topic as presented in the plenary overview session of APSIPA-2011 and the tutorial material presented in the same conference (Deng, 2011) are expanded and updated to include more recent  ...", "url_pdf": "http://research.microsoft.com/pubs/192937/transactions-apsipa.pdf", "num_citations": 3, "cluster_id": "6223016292750369967", "authors": "L Deng - APSIPA transactions on signal and information  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=6223016292750369967&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Learning Stochastic Recurrent Networks", "url": "http://arxiv.org/abs/1411.7610", "url_versions": "http://scholar.google.com/scholar?cluster=11264229937258822687&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: Leveraging advances in variational inference, we propose to enhance recurrent neural networks with latent variables, resulting in Stochastic Recurrent Networks (STORNs). The model i) can be trained with stochastic gradient methods, ii) allows structured and  ...", "url_pdf": null, "num_citations": 4, "cluster_id": "11264229937258822687", "authors": "J Bayer, C Osendorfer - arXiv preprint arXiv:1411.7610", "url_citations": "http://scholar.google.com/scholar?cites=11264229937258822687&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "On fast dropout and its applicability to recurrent networks", "url": "http://arxiv.org/abs/1311.0701", "url_versions": "http://scholar.google.com/scholar?cluster=2288272496556220615&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: Recurrent Neural Networks (RNNs) are rich models for the processing of sequential data. Recent work on advancing the state of the art has been focused on the optimization or modelling of RNNs, mostly motivated by adressing the problems of the  ...", "url_pdf": null, "num_citations": 11, "cluster_id": "2288272496556220615", "authors": "J Bayer, C Osendorfer, D Korhammer, N Chen\u2026 - arXiv preprint arXiv: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=2288272496556220615&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Quaddirectional 2D-Recurrent Neural Networks For Image Labeling", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7118156", "url_versions": null, "year": "2015", "excerpt": "Abstract\u2014We adopt Convolutional Neural Networks (CNN) to learn discriminative features for local patch classification. We further introduce quaddirectional 2D Recurrent Neural Networks to model the long range dependencies among pixels. Our quaddirectional 2D- ...", "url_pdf": null, "num_citations": 1, "cluster_id": "13720065868238901658", "authors": "B Shuai, Z Zuo, W Gang -", "url_citations": "http://scholar.google.com/scholar?cites=13720065868238901658&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Sequence classification using the high-level features extracted from deep neural networks", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6854926", "url_versions": "http://scholar.google.com/scholar?cluster=17163378112260269094&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "ABSTRACT The recent success of deep neural networks (DNNs) in speech recognition can be attributed largely to their ability to extract a specific form of high-level features from raw acoustic data for subsequent sequence classification or recognition tasks. Among the  ...", "url_pdf": null, "num_citations": 18, "cluster_id": "17163378112260269094", "authors": "L Deng, J Chen - \u2026  and Signal Processing (ICASSP)", "url_citations": "http://scholar.google.com/scholar?cites=17163378112260269094&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Dynamic pre-training of Deep Recurrent Neural Networks for predicting environmental monitoring data", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7004302", "url_versions": null, "year": "2014", "excerpt": "Abstract\u2014In this paper, we introduce a Deep Recurrent Neural Network (DRNN) that is trained using a novel autoencoder pre-training method especially designed for the task of time series prediction. Our main objective is to perform predictions of environmental  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "3395923317977127696", "authors": "BT Ong, K Sugiura, K Zettsu - Big Data (Big Data)", "url_citations": "http://scholar.google.com/scholar?cites=3395923317977127696&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "A tutorial survey of architectures, algorithms, and applications for deep learning", "url": "http://journals.cambridge.org/abstract_S2048770313000097", "url_versions": "http://scholar.google.com/scholar?cluster=4381743472348703222&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract In this invited paper, my overview material on the same topic as presented in the plenary overview session of APSIPA-2011 and the tutorial material presented in the same conference [1] are expanded and updated to include more recent developments in deep  ...", "url_pdf": null, "num_citations": 18, "cluster_id": "4381743472348703222", "authors": "L Deng - APSIPA Transactions on Signal and Information  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=4381743472348703222&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "An RNN-based music language model for improving automatic music transcription", "url": "http://www.terasoft.com.tw/conf/ismir2014/proceedings/T011_142_Paper.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=8877216003959466755&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "ABSTRACT In this paper, we investigate the use of Music Language Models (MLMs) for improving Automatic Music Transcription performance. The MLMs are trained on sequences of symbolic polyphonic music from the Nottingham dataset. We train Recurrent Neural  ...", "url_pdf": "http://www.terasoft.com.tw/conf/ismir2014/proceedings/T011_142_Paper.pdf", "num_citations": 1, "cluster_id": "8877216003959466755", "authors": "S Sigtia, E Benetos, S Cherla, T Weyde\u2026 - \u2026  Society for Music  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=8877216003959466755&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Exploiting long-term temporal dependencies in NMF using recurrent neural networks with application to source separation", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6854951", "url_versions": "http://scholar.google.com/scholar?cluster=8921535488836128242&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "ABSTRACT This paper seeks to exploit high-level temporal information during feature extraction from audio signals via non-negative matrix factorization. Contrary to existing approaches that impose local temporal constraints, we train powerful recurrent neural  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "8921535488836128242", "authors": "N Boulanger-Lewandowski, GJ Mysore\u2026 - \u2026 , Speech and Signal  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=8921535488836128242&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 12, "url_citation": null, "title": "Phone sequence modeling with recurrent neural networks", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6854638", "url_versions": "http://scholar.google.com/scholar?cluster=14153365470577751388&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "ABSTRACT In this paper, we investigate phone sequence modeling with recurrent neural networks in the context of speech recognition. We introduce a hybrid architecture that combines a phonetic model with an arbitrary frame-level acoustic model and we propose  ...", "url_pdf": null, "num_citations": 4, "cluster_id": "14153365470577751388", "authors": "N Boulanger-Lewandowski, J Droppo\u2026 - \u2026 , Speech and Signal  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=14153365470577751388&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Compositional Distributional Semantics with Long Short Term Memory", "url": "http://arxiv.org/abs/1503.02510", "url_versions": "http://scholar.google.com/scholar?cluster=7969581961601997678&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract: We are proposing an extension of the recursive neural network that makes use of a variant of the long short-term memory architecture. The extension allows information low in parse trees to be stored in a memory register (thememory cell') and used much later  ...", "url_pdf": null, "num_citations": 4, "cluster_id": "7969581961601997678", "authors": "P Le, W Zuidema - arXiv preprint arXiv:1503.02510", "url_citations": "http://scholar.google.com/scholar?cites=7969581961601997678&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Deep learning for signal and information processing", "url": "http://cs.tju.edu.cn/web/docs/2013-Deep%20Learning%20for%20Signal%20and%20Information%20Processing.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=7346768574939973182&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "ABSTRACT This short monograph contains the material expanded from two tutorials that the authors gave, one at APSIPA in October 2011 and the other at ICASSP in March 2012. Substantial updates have been made based on the literature up to March, 2013, covering  ...", "url_pdf": "http://cs.tju.edu.cn/web/docs/2013-Deep%20Learning%20for%20Signal%20and%20Information%20Processing.pdf", "num_citations": 9, "cluster_id": "7346768574939973182", "authors": "L Deng, D Yu - Microsoft Research Monograph", "url_citations": "http://scholar.google.com/scholar?cites=7346768574939973182&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Recurrent neural networks and related models", "url": "http://link.springer.com/chapter/10.1007/978-1-4471-5779-3_13", "url_versions": null, "year": "2015", "excerpt": "Abstract A recurrent neural network (RNN) is a class of neural network models where many connections among its neurons form a directed cycle. This gives rise to the structure of internal states or memory in the RNN, endowing it with the dynamic temporal behavior not  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "2000137079705205072", "authors": "D Yu, L Deng - Automatic Speech Recognition", "url_citations": "http://scholar.google.com/scholar?cites=2000137079705205072&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Scaling Recurrent Neural Network Language Models", "url": "http://arxiv.org/abs/1502.00512", "url_versions": "http://scholar.google.com/scholar?cluster=16595224952443765130&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract: This paper investigates the scaling properties of Recurrent Neural Network Language Models (RNNLMs). We discuss how to train very large RNNs on GPUs and address the questions of how RNNLMs scale with respect to model size, training-set size,  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "16595224952443765130", "authors": "W Williams, N Prasad, D Mrva, T Ash\u2026 - arXiv preprint arXiv: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=16595224952443765130&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Variational inference of latent state sequences using Recurrent Networks", "url": "http://arxiv.org/abs/1406.1655", "url_versions": "http://scholar.google.com/scholar?cluster=5750301624839224521&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: Recent advances in the estimation of deep directed graphical models and recurrent networks let us contribute to the removal of a blind spot in the area of probabilistc modelling of time series. The proposed methods i) can infer distributed latent state-space  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "5750301624839224521", "authors": "J Bayer, C Osendorfer - arXiv preprint arXiv:1406.1655", "url_citations": "http://scholar.google.com/scholar?cites=5750301624839224521&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "url": "http://arxiv.org/abs/1412.3555", "url_versions": "http://scholar.google.com/scholar?cluster=8949247111056306593&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated  ...", "url_pdf": null, "num_citations": 27, "cluster_id": "8949247111056306593", "authors": "J Chung, C Gulcehre, KH Cho, Y Bengio - arXiv preprint arXiv:1412.3555", "url_citations": "http://scholar.google.com/scholar?cites=8949247111056306593&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Photonic Delay Systems as Machine Learning Implementations", "url": "http://arxiv.org/abs/1501.02592", "url_versions": "http://scholar.google.com/scholar?cluster=2370927469852718665&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract: Nonlinear photonic delay systems present interesting implementation platforms for machine learning models. They can be extremely fast, offer great degrees of parallelism and potentially consume far less power than digital processors. So far they have been  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "2370927469852718665", "authors": "M Hermans, M Soriano, J Dambre, P Bienstman\u2026 - arXiv preprint arXiv: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=2370927469852718665&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "A primal-dual method for training recurrent neural networks constrained by the echo-state property", "url": "http://arxiv.org/abs/1311.6091", "url_versions": "http://scholar.google.com/scholar?cluster=6487030979241587260&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: We present an architecture of a recurrent neural network (RNN) with a fully-connected deep neural network (DNN) as its feature extractor. The RNN is equipped with both causal temporal prediction and non-causal look-ahead, via auto-regression (AR) and  ...", "url_pdf": null, "num_citations": 14, "cluster_id": "6487030979241587260", "authors": "J Chen, L Deng - arXiv preprint arXiv:1311.6091", "url_citations": "http://scholar.google.com/scholar?cites=6487030979241587260&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Learning input and recurrent weight matrices in echo state networks", "url": "http://arxiv.org/abs/1311.2987", "url_versions": "http://scholar.google.com/scholar?cluster=3930878012502898282&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: Echo State Networks (ESNs) are a special type of the temporally deep network model, the Recurrent Neural Network (RNN), where the recurrent matrix is carefully designed and both the recurrent and input matrices are fixed. An ESN uses the linearity of  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "3930878012502898282", "authors": "H Palangi, L Deng, RK Ward - arXiv preprint arXiv:1311.2987", "url_citations": "http://scholar.google.com/scholar?cites=3930878012502898282&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Structured Recurrent Temporal Restricted Boltzmann Machines", "url": "http://machinelearning.wustl.edu/mlpapers/papers/icml2014c2_mittelman14", "url_versions": "http://scholar.google.com/scholar?cluster=16093425108681238378&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: The Recurrent temporal restricted Boltzmann machine (RTRBM) is a probabilistic model for temporal data, that has been shown to effectively capture both short and long-term dependencies in time-series. The topology of the RTRBM graphical model, however,  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "16093425108681238378", "authors": "R Mittelman, B Kuipers\u2026 - Proceedings of the  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=16093425108681238378&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Discriminative recurrent sparse auto-encoders", "url": "http://arxiv.org/abs/1301.3775", "url_versions": "http://scholar.google.com/scholar?cluster=3084213257915753558&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: We present the discriminative recurrent sparse auto-encoder model, comprising a recurrent encoder of rectified linear units, unrolled for a fixed number of iterations, and connected to two linear decoders that reconstruct the input and predict its supervised  ...", "url_pdf": null, "num_citations": 12, "cluster_id": "3084213257915753558", "authors": "JT Rolfe, Y LeCun - arXiv preprint arXiv:1301.3775", "url_citations": "http://scholar.google.com/scholar?cites=3084213257915753558&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 11, "url_citation": null, "title": "Recent advances in deep learning for speech research at Microsoft", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6639345", "url_versions": "http://scholar.google.com/scholar?cluster=14774739962596400760&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "ABSTRACT Deep learning is becoming a mainstream technology for speech recognition at industrial scale. In this paper, we provide an overview of the work by Microsoft speech researchers since 2009 in this area, focusing on more recent advances which shed light to  ...", "url_pdf": null, "num_citations": 99, "cluster_id": "14774739962596400760", "authors": "L Deng, J Li, JT Huang, K Yao, D Yu\u2026 - \u2026 , Speech and Signal  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=14774739962596400760&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 11, "url_citation": null, "title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "url": "http://arxiv.org/abs/1406.1078", "url_versions": "http://scholar.google.com/scholar?cluster=9119975171114587835&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract: In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the  ...", "url_pdf": null, "num_citations": 113, "cluster_id": "9119975171114587835", "authors": "K Cho, B Van Merri\u00ebnboer, C Gulcehre\u2026 - arXiv preprint arXiv: \u2026", "url_citations": "http://scholar.google.com/scholar?cites=9119975171114587835&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Deep dynamic models for learning hidden representations of speech features", "url": "http://link.springer.com/chapter/10.1007/978-1-4939-1456-2_6", "url_versions": "http://scholar.google.com/scholar?cluster=11557771487470342425&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2015", "excerpt": "Abstract Deep hierarchical structure with multiple layers of hidden space in human speech is intrinsically connected to its dynamic characteristics manifested in all levels of speech production and perception. The desire and an attempt to capitalize on a (superficial)  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "11557771487470342425", "authors": "L Deng, R Togneri - Speech and Audio Processing for Coding,  \u2026", "url_citations": "http://scholar.google.com/scholar?cites=11557771487470342425&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Training neural networks with stochastic hessian-free optimization", "url": "http://arxiv.org/abs/1301.3641", "url_versions": "http://scholar.google.com/scholar?cluster=15998932101819720935&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2013", "excerpt": "Abstract: Hessian-free (HF) optimization has been successfully used for training deep autoencoders and recurrent networks. HF uses the conjugate gradient algorithm to construct update directions through curvature-vector products that can be computed on the same  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "15998932101819720935", "authors": "R Kiros - arXiv preprint arXiv:1301.3641", "url_citations": "http://scholar.google.com/scholar?cites=15998932101819720935&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 17, "url_citation": null, "title": "Ensemble deep learning for speech recognition", "url": "http://193.6.4.39/%7Eczap/letoltes/IS14/IS2014/PDF/AUTHOR/IS140245.PDF", "url_versions": "http://scholar.google.com/scholar?cluster=5134188976545572527&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "year": "2014", "excerpt": "Abstract Deep learning systems have dramatically improved the accuracy of speech recognition, and various deep architectures and learning methods have been developed with distinct strengths and weaknesses in recent years. How can ensemble learning be  ...", "url_pdf": null, "num_citations": 8, "cluster_id": "5134188976545572527", "authors": "L Deng, JC Platt - Proceedings of the Annual Conference of International \u2026", "url_citations": "http://scholar.google.com/scholar?cites=5134188976545572527&as_sdt=2005&sciodt=1,5&hl=en"}]