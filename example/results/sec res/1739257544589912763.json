[{"num_versions": 3, "url_citation": null, "title": "Combining Language and Vision with a Multimodal Skip-gram Model", "url": "http://arxiv.org/abs/1501.02598", "url_versions": "http://scholar.google.com/scholar?cluster=810317863434591306&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "A Lazaridou, NT Pham, M Baroni - arXiv preprint arXiv:1501.02598", "excerpt": "Abstract: We extend the effective SKIP-GRAM model of Mikolov et al.(2013) by taking visual information into account. Like S KIP-GRAM, our multimodal models (MMSKIP-GRAM) build vector-based word representations by learning to predict linguistic contexts in text corpora.  ...", "url_pdf": null, "num_citations": 8, "cluster_id": "810317863434591306", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=810317863434591306&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 12, "url_citation": null, "title": "How transferable are features in deep neural networks?", "url": "http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks", "url_versions": "http://scholar.google.com/scholar?cluster=8833146761103838326&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Yosinski, J Clune, Y Bengio\u2026 - Advances in Neural  \u2026", "excerpt": "Abstract Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or  ...", "url_pdf": null, "num_citations": 50, "cluster_id": "8833146761103838326", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=8833146761103838326&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Viewpoints and keypoints", "url": "http://arxiv.org/abs/1411.6067", "url_versions": "http://scholar.google.com/scholar?cluster=13212199077198953855&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Tulsiani, J Malik - arXiv preprint arXiv:1411.6067", "excerpt": "Abstract: We characterize the problem of pose estimation for rigid objects in terms of determining viewpoint to explain coarse pose and keypoint prediction to capture the finer details. We address both these tasks in two different settings-the constrained setting with  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "13212199077198953855", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=13212199077198953855&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Translating videos to natural language using deep recurrent neural networks", "url": "http://arxiv.org/abs/1412.4729", "url_versions": "http://scholar.google.com/scholar?cluster=2018325242950133936&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Venugopalan, H Xu, J Donahue, M Rohrbach\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Solving the visual symbol grounding problem has long been a goal of artificial intelligence. The field appears to be advancing closer to this goal with recent breakthroughs in deep learning for natural language grounding in static images. In this paper, we  ...", "url_pdf": null, "num_citations": 22, "cluster_id": "2018325242950133936", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=2018325242950133936&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Video description generation incorporating spatio-temporal features and a soft-attention mechanism", "url": "http://arxiv.org/abs/1502.08029", "url_versions": "http://scholar.google.com/scholar?cluster=8761564837485893612&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "L Yao, A Torabi, K Cho, N Ballas, C Pal\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Recent progress in using recurrent neural networks (RNNs) for image description has motivated us to explore the application of RNNs to video description. Recent work has also suggested that attention mechanisms may be able to increase performance. To this  ...", "url_pdf": null, "num_citations": 9, "cluster_id": "8761564837485893612", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=8761564837485893612&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition", "url": "http://arxiv.org/abs/1412.6553", "url_versions": "http://scholar.google.com/scholar?cluster=3369289675757470591&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "V Lebedev, Y Ganin, M Rakhuba, I Oseledets\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: We propose a simple two-step approach for speeding up convolution layers within large convolutional neural networks based on tensor decomposition and discriminative fine-tuning. Given a layer, we use non-linear least squares to compute a low-rank CP- ...", "url_pdf": null, "num_citations": 9, "cluster_id": "3369289675757470591", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=3369289675757470591&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Accelerating t-sne using tree-based algorithms", "url": "http://dl.acm.org/citation.cfm?id=2697068", "url_versions": "http://scholar.google.com/scholar?cluster=9031542969544004346&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "L Van Der Maaten - The Journal of Machine Learning Research", "excerpt": "Abstract The paper investigates the acceleration of t-SNE--an embedding technique that is commonly used for the visualization of high-dimensional data in scatter plots--using two tree-based algorithms. In particular, the paper develops variants of the Barnes-Hut algorithm  ...", "url_pdf": null, "num_citations": 14, "cluster_id": "9031542969544004346", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=9031542969544004346&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Appearance-Based Gaze Estimation in the Wild", "url": "http://arxiv.org/abs/1504.02863", "url_versions": "http://scholar.google.com/scholar?cluster=8284646831790188439&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "X Zhang, Y Sugano, M Fritz, A Bulling - arXiv preprint arXiv:1504.02863", "excerpt": "Abstract: Appearance-based gaze estimation is believed to work well in real-world settings, but existing datasets have been collected under controlled laboratory conditions and methods have been not evaluated across multiple datasets. In this work we study  ...", "url_pdf": null, "num_citations": 4, "cluster_id": "8284646831790188439", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=8284646831790188439&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Understanding neural networks through deep visualization", "url": "http://arxiv.org/abs/1506.06579", "url_versions": null, "authors": "J Yosinski, J Clune, A Nguyen, T Fuchs\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Recent years have produced great advances in training large, deep neural networks (DNNs), including notable successes in training convolutional neural networks (convnets) to recognize natural images. However, our understanding of how these models  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "12802810408843165614", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=12802810408843165614&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Finding action tubes", "url": "http://arxiv.org/abs/1411.6031", "url_versions": "http://scholar.google.com/scholar?cluster=16050297232698269601&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "G Gkioxari, J Malik - arXiv preprint arXiv:1411.6031", "excerpt": "Abstract: We address the problem of action detection in videos. Driven by the latest progress in object detection from 2D images, we build action models using rich feature hierarchies derived from shape and kinematic cues. We incorporate appearance and motion in two  ...", "url_pdf": null, "num_citations": 9, "cluster_id": "16050297232698269601", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=16050297232698269601&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Deformable part models are convolutional neural networks", "url": "http://arxiv.org/abs/1409.5403", "url_versions": "http://scholar.google.com/scholar?cluster=8774363972263802138&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "R Girshick, F Iandola, T Darrell, J Malik - arXiv preprint arXiv:1409.5403", "excerpt": "Abstract: Deformable part models (DPMs) and convolutional neural networks (CNNs) are two widely used tools for visual recognition. They are typically viewed as distinct approaches: DPMs are graphical models (Markov random fields), while CNNs are\" black- ...", "url_pdf": null, "num_citations": 16, "cluster_id": "8774363972263802138", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=8774363972263802138&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Boosting convolutional features for robust object proposals", "url": "http://arxiv.org/abs/1503.06350", "url_versions": "http://scholar.google.com/scholar?cluster=393660656511466003&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "N Karianakis, TJ Fuchs, S Soatto - arXiv preprint arXiv:1503.06350", "excerpt": "Abstract: Deep Convolutional Neural Networks (CNNs) have demonstrated excellent performance in image classification, but still show room for improvement in object-detection tasks with many categories, in particular for cluttered scenes and occlusion. Modern  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "393660656511466003", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=393660656511466003&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Convolutional feature masking for joint object and stuff segmentation", "url": "http://arxiv.org/abs/1412.1283", "url_versions": "http://scholar.google.com/scholar?cluster=3867986733742388443&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Dai, K He, J Sun - arXiv preprint arXiv:1412.1283", "excerpt": "Abstract: The topic of semantic segmentation has witnessed considerable progress due to the powerful features learned by convolutional neural networks (CNNs). The current leading approaches for semantic segmentation exploit shape information by extracting CNN  ...", "url_pdf": null, "num_citations": 16, "cluster_id": "3867986733742388443", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=3867986733742388443&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Fast R-CNN", "url": "http://arxiv.org/abs/1504.08083", "url_versions": "http://scholar.google.com/scholar?cluster=16324699838103945745&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "R Girshick - arXiv preprint arXiv:1504.08083", "excerpt": "Abstract: This paper proposes Fast R-CNN, a clean and fast framework for object detection. Compared to traditional R-CNN, and its accelerated version SPPnet, Fast R-CNN trains networks using a multi-task loss in a single training stage. The multi-task loss simplifies  ...", "url_pdf": null, "num_citations": 15, "cluster_id": "16324699838103945745", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=16324699838103945745&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "SINGA: Putting Deep Learning in the Hands of Multimedia Users", "url": "http://www.comp.nus.edu.sg/%7Eooibc/singa-mm15.pdf", "url_versions": null, "authors": "W Wang, G Chen, TTA Dinh, J Gao, BC Ooi\u2026 - ACM  \u2026", "excerpt": "ABSTRACT Recently, deep learning techniques have enjoyed success in various multimedia applications, such as image classification and multimodal data analysis. Two key factors behind deep learning's remarkable achievement are the immense computing  ...", "url_pdf": "http://www.comp.nus.edu.sg/%7Eooibc/singa-mm15.pdf", "num_citations": 2, "cluster_id": "3008341242999454083", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=3008341242999454083&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "SINGA: A Distributed Deep Learning Platform", "url": "http://www.comp.nus.edu.sg/%7Eooibc/singaopen-mm15.pdf", "url_versions": null, "authors": "BC Ooi, KL Tan, S Wang, W Wang, Q Cai\u2026 - ACM Multimedia ( \u2026", "excerpt": "ABSTRACT Deep learning has shown outstanding performance in various machine learning tasks. However, the deep complex model structure and massive training data make it expensive to train. In this paper, we present a distributed deep learning system, called  ...", "url_pdf": "http://www.comp.nus.edu.sg/%7Eooibc/singaopen-mm15.pdf", "num_citations": 2, "cluster_id": "13432278972921259793", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=13432278972921259793&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Learning to detect vehicles by clustering appearance patterns", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7065305", "url_versions": "http://scholar.google.com/scholar?cluster=9905133943678891491&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "E Ohn-Bar, MM Trivedi -", "excerpt": "Abstract\u2014This paper studies efficient means in dealing with intracategory diversity in object detection. Strategies for occlusion and orientation handling are explored by learning an ensemble of detection models from visual and geometrical clusters of object instances. An  ...", "url_pdf": null, "num_citations": 4, "cluster_id": "9905133943678891491", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=9905133943678891491&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Learning a recurrent visual representation for image caption generation", "url": "http://arxiv.org/abs/1411.5654", "url_versions": "http://scholar.google.com/scholar?cluster=13741988278284568890&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "X Chen, CL Zitnick - arXiv preprint arXiv:1411.5654", "excerpt": "Abstract: In this paper we explore the bi-directional mapping between images and their sentence-based descriptions. We propose learning this mapping using a recurrent neural network. Unlike previous approaches that map both sentences and images to a common  ...", "url_pdf": null, "num_citations": 22, "cluster_id": "13741988278284568890", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=13741988278284568890&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Convolutional neural networks at constrained time cost", "url": "http://arxiv.org/abs/1412.1710", "url_versions": "http://scholar.google.com/scholar?cluster=13809464509695277885&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "K He, J Sun - arXiv preprint arXiv:1412.1710", "excerpt": "Abstract: Though recent advanced convolutional neural networks (CNNs) have been improving the image recognition accuracy, the models are getting more complex and time-consuming. For real-world applications in industrial and commercial scenarios, engineers  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "13809464509695277885", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=13809464509695277885&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Image-based Recommendations on Styles and Substitutes", "url": "http://dl.acm.org/citation.cfm?id=2767755", "url_versions": null, "authors": "J McAuley, C Targett, Q Shi\u2026 - Proceedings of the 38th  \u2026", "excerpt": "Abstract Humans inevitably develop a sense of the relationships between objects, some of which are based on their appearance. Some pairs of objects might be seen as being alternatives to each other (such as two pairs of jeans), while others may be seen as being  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "11036512089166259839", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=11036512089166259839&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Material recognition in the wild with the materials in context database", "url": "http://arxiv.org/abs/1412.0623", "url_versions": "http://scholar.google.com/scholar?cluster=12094637532696401921&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Bell, P Upchurch, N Snavely, K Bala - arXiv preprint arXiv:1412.0623", "excerpt": "Abstract: Recognizing materials in images in the wild is a challenging task. Real-world materials have rich surface texture, geometry, lighting conditions, and clutter, which combine to make the problem particularly difficult. Recently, deep learning combined with large  ...", "url_pdf": null, "num_citations": 7, "cluster_id": "12094637532696401921", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=12094637532696401921&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Do Convnets Learn Correspondence?", "url": "http://papers.nips.cc/paper/5420-do-convnets-learn-correspondence", "url_versions": "http://scholar.google.com/scholar?cluster=163870541144798819&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "JL Long, N Zhang, T Darrell - Advances in Neural Information  \u2026", "excerpt": "Abstract Convolutional neural nets (convnets) trained from massive labeled datasets have substantially improved the state-of-the-art in image classification and object detection. However, visual understanding requires establishing correspondence on a finer level than  ...", "url_pdf": null, "num_citations": 11, "cluster_id": "163870541144798819", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=163870541144798819&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Fisher kernel for deep neural activations", "url": "http://arxiv.org/abs/1412.1628", "url_versions": "http://scholar.google.com/scholar?cluster=647015071452369823&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "D Yoo, S Park, JY Lee, IS Kweon - arXiv preprint arXiv:1412.1628", "excerpt": "Abstract: Compared to image representation based on low-level local descriptors, deep neural activations of Convolutional Neural Networks (CNNs) are richer in mid-level representation, but poorer in geometric invariance properties. In this paper, we present a  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "647015071452369823", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=647015071452369823&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Learning activation functions to improve deep neural networks", "url": "http://arxiv.org/abs/1412.6830", "url_versions": "http://scholar.google.com/scholar?cluster=5255373738796360629&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "F Agostinelli, M Hoffman, P Sadowski\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Artificial neural networks typically have a fixed, non-linear activation function at each neuron. We have designed a novel form of piece-wise linear activation function that is learned independently for each neuron using standard gradient descent. With this learned  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "5255373738796360629", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=5255373738796360629&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "LSDA: Large scale detection through adaptation", "url": "http://papers.nips.cc/paper/5418-lsda-large-scale-detection-through-adaptation", "url_versions": "http://scholar.google.com/scholar?cluster=2452150234195977094&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Hoffman, S Guadarrama, ES Tzeng, R Hu\u2026 - Advances in Neural  \u2026", "excerpt": "Abstract A major challenge in scaling object detection is the difficulty of obtaining labeled images for large numbers of categories. Recently, deep convolutional neural networks (CNNs) have emerged as clear winners on object classification benchmarks, in part due to  ...", "url_pdf": null, "num_citations": 21, "cluster_id": "2452150234195977094", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=2452150234195977094&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "DeepEdge: A Multi-Scale Bifurcated Deep Network for Top-Down Contour Detection", "url": "http://arxiv.org/abs/1412.1123", "url_versions": "http://scholar.google.com/scholar?cluster=2089551699301366907&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "G Bertasius, J Shi, L Torresani - arXiv preprint arXiv:1412.1123", "excerpt": "Abstract: Contour detection has been a fundamental component in many image segmentation and object detection systems. Most previous work utilizes low-level features such as texture or saliency to detect contours and then use them as cues for a higher-level  ...", "url_pdf": null, "num_citations": 7, "cluster_id": "2089551699301366907", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=2089551699301366907&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Conditional random fields as recurrent neural networks", "url": "http://arxiv.org/abs/1502.03240", "url_versions": "http://scholar.google.com/scholar?cluster=4680896688857314530&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Zheng, S Jayasumana, B Romera-Paredes\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Pixel-level labelling tasks, such as semantic segmentation and depth estimation from single RGB image, play a central role in image understanding. Recent approaches have attempted to harness the capabilities of deep learning techniques for image  ...", "url_pdf": null, "num_citations": 15, "cluster_id": "4680896688857314530", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=4680896688857314530&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "What's Cookin'? Interpreting Cooking Videos using Text, Speech and Vision", "url": "http://arxiv.org/abs/1503.01558", "url_versions": "http://scholar.google.com/scholar?cluster=14331750832735428724&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Malmaud, J Huang, V Rathod, N Johnston\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: We present a novel method for aligning a sequence of instructions to a video of someone carrying out a task. In particular, we focus on the cooking domain, where the instructions correspond to the recipe. Our technique relies on an HMM to align the recipe  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "14331750832735428724", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=14331750832735428724&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Dropout as a Bayesian approximation: Representing model uncertainty in deep learning", "url": "http://arxiv.org/abs/1506.02142", "url_versions": null, "authors": "Y Gal, Z Ghahramani - arXiv preprint arXiv:1506.02142", "excerpt": "Abstract: Deep learning tools have recently gained much attention in applied machine learning. However such tools for regression and classification do not allow us to capture model uncertainty. Bayesian models offer us the ability to reason about model uncertainty,  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "13174052014464344175", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=13174052014464344175&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Faster r-cnn: Towards real-time object detection with region proposal networks", "url": "http://arxiv.org/abs/1506.01497", "url_versions": null, "authors": "S Ren, K He, R Girshick, J Sun - arXiv preprint arXiv:1506.01497", "excerpt": "Abstract: State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "16436232259506318906", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=16436232259506318906&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Feedforward semantic segmentation with zoom-out features", "url": "http://arxiv.org/abs/1412.0774", "url_versions": "http://scholar.google.com/scholar?cluster=9929395936205864976&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "M Mostajabi, P Yadollahpour\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: We introduce a purely feed-forward architecture for semantic segmentation. We map small image elements (superpixels) to rich feature representations extracted from a sequence of nested regions of increasing extent. These regions are obtained by\" zooming  ...", "url_pdf": null, "num_citations": 10, "cluster_id": "9929395936205864976", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=9929395936205864976&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 11, "url_citation": null, "title": "From captions to visual concepts and back", "url": "http://arxiv.org/abs/1411.4952", "url_versions": "http://scholar.google.com/scholar?cluster=9575578435613591482&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "H Fang, S Gupta, F Iandola, R Srivastava\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: This paper presents a novel approach for automatically generating image descriptions: visual detectors and language models learn directly from a dataset of image captions. We use Multiple Instance Learning to train visual detectors for words that  ...", "url_pdf": null, "num_citations": 41, "cluster_id": "9575578435613591482", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=9575578435613591482&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "C3D: generic features for video analysis", "url": "http://arxiv.org/abs/1412.0767", "url_versions": "http://scholar.google.com/scholar?cluster=11185204804331957918&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "D Tran, L Bourdev, R Fergus, L Torresani\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Videos have become ubiquitous due to the ease of capturing and sharing via social platforms like Youtube, Facebook, Instagram, and others. The computer vision community has tried to tackle various video analysis problems independently. As a  ...", "url_pdf": null, "num_citations": 12, "cluster_id": "11185204804331957918", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=11185204804331957918&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Deep neural networks are easily fooled: High confidence predictions for unrecognizable images", "url": "http://arxiv.org/abs/1412.1897", "url_versions": "http://scholar.google.com/scholar?cluster=7266201067420914383&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "A Nguyen, J Yosinski, J Clune - arXiv preprint arXiv:1412.1897", "excerpt": "Abstract: Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human- ...", "url_pdf": null, "num_citations": 33, "cluster_id": "7266201067420914383", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=7266201067420914383&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Mind's eye: A recurrent visual representation for image caption generation", "url": "http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2A_022_ext.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=16240885095975742190&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "X Chen, CL Zitnick - Neural computation", "excerpt": "A good image description is often said to \u201cpaint a picture in your mind's eye.\u201d The creation of a mental image may play a significant role in sentence comprehension in humans [3]. In fact, it is often this mental image that is remembered long after the exact sentence is forgotten [ ...", "url_pdf": "http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2A_022_ext.pdf", "num_citations": 9, "cluster_id": "16240885095975742190", "year": "1997", "url_citations": "http://scholar.google.com/scholar?cites=16240885095975742190&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 9, "url_citation": null, "title": "Long-term recurrent convolutional networks for visual recognition and description", "url": "http://arxiv.org/abs/1411.4389", "url_versions": "http://scholar.google.com/scholar?cluster=156001817367677897&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Donahue, LA Hendricks, S Guadarrama\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Models based on deep convolutional networks have dominated recent image interpretation tasks; we investigate whether models which are also recurrent, or\" temporally deep\", are effective for tasks involving sequences, visual and otherwise. We develop a  ...", "url_pdf": null, "num_citations": 72, "cluster_id": "156001817367677897", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=156001817367677897&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Learning both Weights and Connections for Efficient Neural Networks", "url": "http://arxiv.org/abs/1506.02626", "url_versions": null, "authors": "S Han, J Pool, J Tran, WJ Dally - arXiv preprint arXiv:1506.02626", "excerpt": "Abstract: Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems. Also, conventional networks fix the architecture before training starts; as a result, training cannot improve the architecture. To  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "3024080172411649140", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=3024080172411649140&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "cudnn: Efficient primitives for deep learning", "url": "http://arxiv.org/abs/1410.0759", "url_versions": "http://scholar.google.com/scholar?cluster=5899211555470942760&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Chetlur, C Woolley, P Vandermersch\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: We present a library that provides optimized implementations for deep learning primitives. Deep learning workloads are computationally intensive, and optimizing the kernels of deep learning workloads is difficult and time-consuming. As parallel  ...", "url_pdf": null, "num_citations": 18, "cluster_id": "5899211555470942760", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=5899211555470942760&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Memory bounded deep convolutional networks", "url": "http://arxiv.org/abs/1412.1442", "url_versions": "http://scholar.google.com/scholar?cluster=3438421693955924404&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "MD Collins, P Kohli - arXiv preprint arXiv:1412.1442", "excerpt": "Abstract: In this work, we investigate the use of sparsity-inducing regularizers during training of Convolution Neural Networks (CNNs). These regularizers encourage that fewer connections in the convolution and fully connected layers take non-zero values and in  ...", "url_pdf": null, "num_citations": 7, "cluster_id": "3438421693955924404", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=3438421693955924404&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Sequence to Sequence--Video to Text", "url": "http://arxiv.org/abs/1505.00487", "url_versions": "http://scholar.google.com/scholar?cluster=2341786742021115670&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Venugopalan, M Rohrbach, J Donahue\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Real-world videos often have complex dynamics; methods for generating open-domain video descriptions should be senstive to temporal structure and allow both input (sequence of frames) and output (sequence of words) of variable length. To approach this  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "2341786742021115670", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=2341786742021115670&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Fully convolutional networks for semantic segmentation", "url": "http://arxiv.org/abs/1411.4038", "url_versions": "http://scholar.google.com/scholar?cluster=4198330480927824223&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Long, E Shelhamer, T Darrell - arXiv preprint arXiv:1411.4038", "excerpt": "Abstract: Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build\"  ...", "url_pdf": null, "num_citations": 78, "cluster_id": "4198330480927824223", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=4198330480927824223&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Taking a deeper look at pedestrians", "url": "http://arxiv.org/abs/1501.05790", "url_versions": "http://scholar.google.com/scholar?cluster=12213861898695501044&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Hosang, M Omran, R Benenson, B Schiele - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: In this paper we study the use of convolutional neural networks (convnets) for the task of pedestrian detection. Despite their recent diverse successes, convnets historically underperform compared to other pedestrian detectors. We deliberately omit explicitly  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "12213861898695501044", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=12213861898695501044&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Egocentric video biometrics", "url": "http://arxiv.org/abs/1411.7591", "url_versions": "http://scholar.google.com/scholar?cluster=11678292798780574274&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Y Hoshen, S Peleg - arXiv preprint arXiv:1411.7591", "excerpt": "Abstract: Egocentric cameras are being worn by an increasing number of users, among them many security forces worldwide. GoPro cameras already penetrated the mass market, and Google Glass may follow soon. As head-worn cameras do not capture the face and  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "11678292798780574274", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=11678292798780574274&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Discriminative unsupervised feature learning with convolutional neural networks", "url": "http://papers.nips.cc/paper/5548-active-regression-by-stratification", "url_versions": "http://scholar.google.com/scholar?cluster=8846448899055428439&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "A Dosovitskiy, JT Springenberg\u2026 - Advances in Neural  \u2026", "excerpt": "Abstract Current methods for training convolutional neural networks depend on large amounts of labeled samples for supervised training. In this paper we present an approach for training a convolutional neural network using only unlabeled data. We train the  ...", "url_pdf": null, "num_citations": 14, "cluster_id": "8846448899055428439", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=8846448899055428439&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Learning to generate chairs with convolutional neural networks", "url": "http://arxiv.org/abs/1411.5928", "url_versions": "http://scholar.google.com/scholar?cluster=11824162980464259560&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "A Dosovitskiy, JT Springenberg, T Brox - arXiv preprint arXiv:1411.5928", "excerpt": "Abstract: We train a generative convolutional neural network which is able to generate images of objects given object type, viewpoint, and color. We train the network in a supervised manner on a dataset of rendered 3D chair models. Our experiments show that  ...", "url_pdf": null, "num_citations": 15, "cluster_id": "11824162980464259560", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=11824162980464259560&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Highly efficient forward and backward propagation of convolutional neural networks for pixelwise classification", "url": "http://arxiv.org/abs/1412.4526", "url_versions": "http://scholar.google.com/scholar?cluster=3128810805507251674&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "H Li, R Zhao, X Wang - arXiv preprint arXiv:1412.4526", "excerpt": "Abstract: We present highly efficient algorithms for performing forward and backward propagation of Convolutional Neural Network (CNN) for pixelwise classification on images. For pixelwise classification tasks, such as image segmentation and object detection,  ...", "url_pdf": null, "num_citations": 4, "cluster_id": "3128810805507251674", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=3128810805507251674&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Benchmarking classification of earth-observation data: from learning explicit features to convolutional networks", "url": "http://blesaux.free.fr/papers/blesaux-DFC2015-classif-benchmark.pdf", "url_versions": null, "authors": "A Lagrange, B Le Saux, A Beaupere, A Boulch\u2026 - Proc. of  \u2026", "excerpt": "ABSTRACT In this paper, we address the task of semantic labeling of multisource earth-observation (EO) data. Precisely, we benchmark several concurrent methods of the last 15 years, from expert classifiers, spectral support-vector classification and high-level features  ...", "url_pdf": "http://blesaux.free.fr/papers/blesaux-DFC2015-classif-benchmark.pdf", "num_citations": 2, "cluster_id": "6551169596552170722", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=6551169596552170722&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Fast convolutional nets with fbfft: A GPU performance evaluation", "url": "http://arxiv.org/abs/1412.7580", "url_versions": "http://scholar.google.com/scholar?cluster=12784858847491769698&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "N Vasilache, J Johnson, M Mathieu, S Chintala\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: We examine the performance profile of Convolutional Neural Network training on the current generation of NVIDIA Graphics Processing Units. We introduce two new Fast Fourier Transform convolution implementations: one based on NVIDIA's cuFFT library,  ...", "url_pdf": null, "num_citations": 14, "cluster_id": "12784858847491769698", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=12784858847491769698&as_sdt=2005&sciodt=1,5&hl=en"}]