[{"num_versions": 3, "url_citation": null, "title": "How to scale up kernel methods to be as good as deep neural nets", "url": "http://arxiv.org/abs/1411.4000", "url_versions": "http://scholar.google.com/scholar?cluster=5186887112232122572&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Z Lu, A May, K Liu, AB Garakani, D Guo\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: In this paper, we investigate how to scale up kernel methods to take on large-scale problems, on which deep neural networks have been prevailing. To this end, we leverage existing techniques and develop new ones. These techniques include approximating  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "5186887112232122572", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=5186887112232122572&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "A connection between extreme learning machine and neural network kernel", "url": "http://link.springer.com/chapter/10.1007/978-3-642-29764-9_8", "url_versions": "http://scholar.google.com/scholar?cluster=16580184211460710939&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "E Parviainen, J Riihim\u00e4ki - Knowledge Discovery, Knowledge Engineering  \u2026", "excerpt": "Abstract We study a connection between extreme learning machine (ELM) and neural network kernel (NNK). NNK is derived from a neural network with an infinite number of hidden units. We interpret ELM as an approximation to this infinite network. We show that  ...", "url_pdf": null, "num_citations": 4, "cluster_id": "16580184211460710939", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=16580184211460710939&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Deep Learning For Sequential Pattern Recognition", "url": "http://upcommons.upc.edu/handle/2099.1/20268", "url_versions": "http://scholar.google.com/scholar?cluster=7579635460474112892&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "P Safari -", "excerpt": "In recent years, deep learning has opened a new research line in pattern recognition tasks. It has been hypothesized that this kind of learning would capture more abstract patterns concealed in data. It is motivated by the new findings both in biological aspects of the  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "7579635460474112892", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=7579635460474112892&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "Kernel analysis of deep networks", "url": "http://dl.acm.org/citation.cfm?id=2078188", "url_versions": "http://scholar.google.com/scholar?cluster=6688977387479452631&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "G Montavon, ML Braun, KR M\u00fcller - The Journal of Machine Learning  \u2026", "excerpt": "Abstract When training deep networks it is common knowledge that an efficient and well generalizing representation of the problem is formed. In this paper we aim to elucidate what makes the emerging representation successful. We analyze the layer-wise evolution of the  ...", "url_pdf": null, "num_citations": 21, "cluster_id": "6688977387479452631", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=6688977387479452631&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning", "url": "http://arxiv.org/abs/1412.6614", "url_versions": "http://scholar.google.com/scholar?cluster=8011606804885210624&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "B Neyshabur, R Tomioka, N Srebro - arXiv preprint arXiv:1412.6614", "excerpt": "Abstract: We present experiments demonstrating that some other form of capacity control, different from network size, plays a central role in learning multilayer feed-forward networks. We argue, partially through analogy to matrix factorization, that this is an inductive bias  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "8011606804885210624", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=8011606804885210624&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 13, "url_citation": null, "title": "Random features for kernel deep convex network", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6638237", "url_versions": "http://scholar.google.com/scholar?cluster=10074069374038663944&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "PS Huang, L Deng\u2026 - Acoustics, Speech and \u2026", "excerpt": "ABSTRACT The recently developed deep learning architecture, a kernel version of the deep convex network (K-DCN), is improved to address the scalability problem when the training and testing samples become very large. We have developed a solution based on the use  ...", "url_pdf": null, "num_citations": 11, "cluster_id": "10074069374038663944", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=10074069374038663944&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 17, "url_citation": null, "title": "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion", "url": "http://dl.acm.org/citation.cfm?id=1953039", "url_versions": "http://scholar.google.com/scholar?cluster=13548556499559547747&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "P Vincent, H Larochelle, I Lajoie, Y Bengio\u2026 - The Journal of Machine \u2026", "excerpt": "Abstract We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoders which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of  ...", "url_pdf": null, "num_citations": 535, "cluster_id": "13548556499559547747", "year": "2010", "url_citations": "http://scholar.google.com/scholar?cites=13548556499559547747&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 12, "url_citation": null, "title": "Foundations and Trends\u00ae in Signal Processing", "url": "http://research.microsoft.com:8082/pubs/209355/DeepLearning-NowPublishing-Vol7-SIG-039.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=15981304847159836793&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "L Deng, Y Dong - Signal Processing", "excerpt": "7.1. Acoustic modeling for speech recognition 263 industrial researchers; see reviews in [8 9, 161]. The collaborative work started in phone recognition tasks [89, 100, 135, 136, 257, 260, 258, 309, 311, 334], demonstrating the power of hybrid DNN architectures discussed  ...", "url_pdf": "http://research.microsoft.com:8082/pubs/209355/DeepLearning-NowPublishing-Vol7-SIG-039.pdf", "num_citations": 3, "cluster_id": "15981304847159836793", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=15981304847159836793&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Analysis and extension of arc-cosine kernels for large margin classification", "url": "http://arxiv.org/abs/1112.3712", "url_versions": "http://scholar.google.com/scholar?cluster=3310552832444606442&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Y Cho, LK Saul - arXiv preprint arXiv:1112.3712", "excerpt": "Abstract: We investigate a recently proposed family of positive-definite kernels that mimic the computation in large neural networks. We examine the properties of these kernels using tools from differential geometry; specifically, we analyze the geometry of surfaces in  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "3310552832444606442", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=3310552832444606442&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "A supervised strategy for deep kernel machine", "url": "http://scholar.google.com/https://hal.archives-ouvertes.fr/hal-00668302/", "url_versions": "http://scholar.google.com/scholar?cluster=10653121237755702798&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "F Yger, M Berar, G Gasso\u2026 - \u2026  on Artificial Neural  \u2026", "excerpt": "This paper presents an alternative to the supervised KPCA based approach for learning a Multilayer Kernel Machine (MKM). In our proposed procedure, the hidden layers are learnt in a supervised fashion based on kernel partial least squares regression. The main interest  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "10653121237755702798", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=10653121237755702798&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 12, "url_citation": null, "title": "Breaking the curse of dimensionality with convex neural networks", "url": "http://arxiv.org/abs/1412.8690", "url_versions": "http://scholar.google.com/scholar?cluster=10807593167712429307&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "F Bach - arXiv preprint arXiv:1412.8690", "excerpt": "Abstract: We consider neural networks with a single hidden layer and non-decreasing homogeneous activa-tion functions like the rectified linear units. By letting the number of hidden units grow unbounded and using classical non-Euclidean regularization tools on  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "10807593167712429307", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=10807593167712429307&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Provable algorithms for machine learning problems", "url": "http://scholar.google.com/ftp://ftp.cs.princeton.edu/techreports/2014/968.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=17748484318529401322&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "R Ge -", "excerpt": "Abstract Modern machine learning algorithms can extract useful information from text, images and videos. All these applications involve solving NP-hard problems in average case using heuristics. What properties of the input allow it to be solved efficiently?  ...", "url_pdf": "http://scholar.google.com/ftp://ftp.cs.princeton.edu/techreports/2014/968.pdf", "num_citations": 3, "cluster_id": "17748484318529401322", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=17748484318529401322&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "An Introduction to Deep Learning.", "url": "http://scholar.google.com/https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2011-4.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=11089885089938549306&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "L Arnold, S Rebecchi, S Chevallier, H Paugam-Moisy - ESANN", "excerpt": "Abstract. The deep learning paradigm tackles problems on which shallow architectures (eg SVM) are affected by the curse of dimensionality. As part of a two-stage learning scheme involving multiple layers of nonlinear processing a set of statistically robust features is  ...", "url_pdf": "http://scholar.google.com/https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2011-4.pdf", "num_citations": 10, "cluster_id": "11089885089938549306", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=11089885089938549306&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Three classes of deep learning architectures and their applications: a tutorial survey", "url": "http://research.microsoft.com/pubs/192937/transactions-apsipa.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=6223016292750369967&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "L Deng - APSIPA transactions on signal and information  \u2026", "excerpt": "Abstract\u2014In this invited paper, my overview material on the same topic as presented in the plenary overview session of APSIPA-2011 and the tutorial material presented in the same conference (Deng, 2011) are expanded and updated to include more recent  ...", "url_pdf": "http://research.microsoft.com/pubs/192937/transactions-apsipa.pdf", "num_citations": 3, "cluster_id": "6223016292750369967", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=6223016292750369967&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Interpreting Extreme Learning Machine as an Approximation to an Infinite Neural Network.", "url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.377.8297&rep=rep1&type=pdf", "url_versions": "http://scholar.google.com/scholar?cluster=5691387114937028383&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "E Parviainen, J Riihim\u00e4ki, Y Miche, A Lendasse - KDIR", "excerpt": "Abstract: Extreme Learning Machine (ELM) is a neural network architecture in which hidden layer weights are randomly chosen and output layer weights determined analytically. We interpret ELM as an approximation to a network with infinite number of hidden units. The  ...", "url_pdf": null, "num_citations": 15, "cluster_id": "5691387114937028383", "year": "2010", "url_citations": "http://scholar.google.com/scholar?cites=5691387114937028383&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Studies on dimension reduction and feature spaces", "url": "http://scholar.google.com/https://aaltodoc.aalto.fi/handle/123456789/5067", "url_versions": "http://scholar.google.com/scholar?cluster=14255532641295725068&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "E Parviainen -", "excerpt": "Today's world produces and stores huge amounts of data, which calls for methods that can tackle both growing sizes and growing dimensionalities of data sets. Dimension reduction aims at answering the challenges posed by the latter. Many dimension reduction methods  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "14255532641295725068", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=14255532641295725068&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "Local deep kernel learning for efficient non-linear svm prediction", "url": "http://machinelearning.wustl.edu/mlpapers/papers/icml2013_jose13?ref=driverlayer.com/web", "url_versions": "http://scholar.google.com/scholar?cluster=9173382604628208393&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "C Jose, P Goyal, P Aggrwal\u2026 - Proceedings of the  \u2026", "excerpt": "Abstract: Our objective is to speed up non-linear SVM prediction while maintaining classification accuracy above an acceptable limit. We generalize Localized Multiple Kernel Learning so as to learn a primal feature space embedding which is high dimensional,  ...", "url_pdf": null, "num_citations": 17, "cluster_id": "9173382604628208393", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=9173382604628208393&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Kernel methods match deep neural networks on timit", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6853587", "url_versions": "http://scholar.google.com/scholar?cluster=17274219188329800913&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "PS Huang, H Avron, TN Sainath\u2026 - \u2026 , Speech and Signal  \u2026", "excerpt": "ABSTRACT Despite their theoretical appeal and grounding in tractable convex optimization techniques, kernel methods are often not the first choice for large-scale speech applications due to their significant memory requirements and computational expense. In recent years,  ...", "url_pdf": null, "num_citations": 11, "cluster_id": "17274219188329800913", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=17274219188329800913&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Feedforward kernel neural networks, generalized least learning machine, and its deep learning with application to image classification", "url": "http://www.sciencedirect.com/science/article/pii/S1568494615004809", "url_versions": null, "authors": "S Wang, Y Jiang, FL Chung, P Qian - Applied Soft Computing", "excerpt": "Abstract In this paper, the architecture of feedforward kernel neural networks (FKNN) is proposed, which can include a considerably large family of existing feedforward neural networks and hence can meet most practical requirements. Different from the common  ...", "url_pdf": null, "num_citations": 0, "cluster_id": null, "year": "2015", "url_citations": null}, {"num_versions": 3, "url_citation": null, "title": "A tutorial survey of architectures, algorithms, and applications for deep learning", "url": "http://journals.cambridge.org/abstract_S2048770313000097", "url_versions": "http://scholar.google.com/scholar?cluster=4381743472348703222&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "L Deng - APSIPA Transactions on Signal and Information  \u2026", "excerpt": "Abstract In this invited paper, my overview material on the same topic as presented in the plenary overview session of APSIPA-2011 and the tutorial material presented in the same conference [1] are expanded and updated to include more recent developments in deep  ...", "url_pdf": null, "num_citations": 18, "cluster_id": "4381743472348703222", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=4381743472348703222&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Machine Learning for Author Affiliation within Web Forums--Using Statistical Techniques on NLP Features for Online Group Identification", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6146951", "url_versions": "http://scholar.google.com/scholar?cluster=7332512941509690556&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Ellen, S Parameswaran - Machine Learning and Applications \u2026", "excerpt": "Abstract\u2014Although there have been previous studies performing authorship attribution to a specific individual; we find a shortage of efforts to group authors based on their affiliations. This paper presents our work on classification of website forum posts by the author's  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "7332512941509690556", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=7332512941509690556&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "Two-layer multiple kernel learning", "url": "http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_ZhuangTH11a.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=5599627217697212131&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Zhuang, IW Tsang, S Hoi - International  \u2026", "excerpt": "Abstract Multiple Kernel Learning (MKL) aims to learn kernel machines for solving a real machine learning problem (eg classification) by exploring the combinations of multiple kernels. The traditional MKL approach is in general \u201cshallow\u201d in the sense that the target  ...", "url_pdf": "http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_ZhuangTH11a.pdf", "num_citations": 17, "cluster_id": "5599627217697212131", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=5599627217697212131&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Deep learning for signal and information processing", "url": "http://cs.tju.edu.cn/web/docs/2013-Deep%20Learning%20for%20Signal%20and%20Information%20Processing.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=7346768574939973182&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "L Deng, D Yu - Microsoft Research Monograph", "excerpt": "ABSTRACT This short monograph contains the material expanded from two tutorials that the authors gave, one at APSIPA in October 2011 and the other at ICASSP in March 2012. Substantial updates have been made based on the literature up to March, 2013, covering  ...", "url_pdf": "http://cs.tju.edu.cn/web/docs/2013-Deep%20Learning%20for%20Signal%20and%20Information%20Processing.pdf", "num_citations": 9, "cluster_id": "7346768574939973182", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=7346768574939973182&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Provable bounds for learning some deep representations", "url": "http://arxiv.org/abs/1310.6343", "url_versions": "http://scholar.google.com/scholar?cluster=6184415841318740254&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Arora, A Bhaskara, R Ge, T Ma - arXiv preprint arXiv:1310.6343", "excerpt": "Abstract: We give algorithms with provable guarantees that learn a class of deep nets in the generative model view popularized by Hinton and others. Our generative model is an $ n $ node multilayer neural net that has degree at most $ n^{\\ gamma} $ for some $\\ gamma< 1 ...", "url_pdf": null, "num_citations": 24, "cluster_id": "6184415841318740254", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=6184415841318740254&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Unsupervised kernel dimension reduction", "url": "http://papers.nips.cc/paper/4122-unsupervised-kernel-dimension-reduction", "url_versions": "http://scholar.google.com/scholar?cluster=7192016207983725884&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "M Wang, F Sha, MI Jordan - Advances in Neural Information  \u2026", "excerpt": "Abstract We apply the framework of kernel dimension reduction, originally designed for supervised problems, to unsupervised dimensionality reduction. In this framework, kernel-based measures of independence are used to derive low-dimensional representations  ...", "url_pdf": null, "num_citations": 20, "cluster_id": "7192016207983725884", "year": "2010", "url_citations": "http://scholar.google.com/scholar?cites=7192016207983725884&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Deep Convolutional Networks are Hierarchical Kernel Machines", "url": "http://arxiv.org/abs/1508.01084", "url_versions": null, "authors": "F Anselmi, L Rosasco, C Tan, T Poggio - arXiv preprint arXiv:1508.01084", "excerpt": "Abstract: In i-theory a typical layer of a hierarchical architecture consists of HW modules pooling the dot products of the inputs to the layer with the transformations of a few templates under a group. Such layers include as special cases the convolutional layers of Deep  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "12818003712224214847", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=12818003712224214847&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Method of Evolving Non-stationary Multiple Kernel Learning", "url": "http://link.springer.com/chapter/10.1007/978-3-319-12640-1_3", "url_versions": null, "authors": "P Wu, Q Yin, P Guo - Neural Information Processing", "excerpt": "Abstract Recently, evolving multiple kernel learning methods have attracted researchers' attention due to the ability to find the composite kernel with the optimal mapping model in a large high-dimensional feature space. However, it is not suitable to compute the  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "14951863890737066946", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=14951863890737066946&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Understanding deep architectures and the effect of unsupervised pre-training", "url": "http://scholar.google.com/https://papyrus.bib.umontreal.ca/xmlui/handle/1866/5022", "url_versions": "http://scholar.google.com/scholar?cluster=11532436133818057314&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "D Erhan -", "excerpt": "Cette th\u00e8se porte sur une classe d'algorithmes d'apprentissage appel\u00e9s architectures profondes. Il existe des r\u00e9sultats qui indiquent que les repr\u00e9sentations peu profondes et locales ne sont pas suffisantes pour la mod\u00e9lisation des fonctions comportant plusieurs  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "11532436133818057314", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=11532436133818057314&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 22, "url_citation": null, "title": "Gated softmax classification", "url": "http://papers.nips.cc/paper/3895-gated-softmax-classification", "url_versions": "http://scholar.google.com/scholar?cluster=7290199501038970759&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "R Memisevic, C Zach, M Pollefeys\u2026 - Advances in Neural  \u2026", "excerpt": "Abstract We describe a log-bilinear\" model that computes class probabilities by combining an input vector multiplicatively with a vector of binary latent variables. Even though the latent variables can take on exponentially many possible combinations of values, we can  ...", "url_pdf": null, "num_citations": 25, "cluster_id": "7290199501038970759", "year": "2010", "url_citations": "http://scholar.google.com/scholar?cites=7290199501038970759&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 11, "url_citation": null, "title": "Avoiding pathologies in very deep networks", "url": "http://arxiv.org/abs/1402.5836", "url_versions": "http://scholar.google.com/scholar?cluster=3368909721886951994&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "D Duvenaud, O Rippel, RP Adams\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: Choosing appropriate architectures and regularization strategies for deep networks is crucial to good predictive performance. To shed light on this problem, we analyze the analogous problem of constructing useful priors on compositions of functions. Specifically,  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "3368909721886951994", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=3368909721886951994&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "Higher order contractive auto-encoder", "url": "http://link.springer.com/chapter/10.1007/978-3-642-23783-6_41", "url_versions": "http://scholar.google.com/scholar?cluster=993338279736361345&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Rifai, G Mesnil, P Vincent, X Muller, Y Bengio\u2026 - Machine Learning and  \u2026", "excerpt": "Abstract We propose a novel regularizer when training an auto-encoder for unsupervised feature extraction. We explicitly encourage the latent representation to contract the input space by regularizing the norm of the Jacobian (analytically) and the Hessian ( ...", "url_pdf": null, "num_citations": 49, "cluster_id": "993338279736361345", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=993338279736361345&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 12, "url_citation": null, "title": "Large-margin classification in infinite neural networks", "url": "http://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00018", "url_versions": "http://scholar.google.com/scholar?cluster=5398457185323160842&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Y Cho, LK Saul - Neural computation", "excerpt": "We introduce a new family of positive-definite kernels for large margin classification in support vector machines (SVMs). These kernels mimic the computation in large neural networks with one layer of hidden units. We also show how to derive new kernels, by  ...", "url_pdf": null, "num_citations": 13, "cluster_id": "5398457185323160842", "year": "2010", "url_citations": "http://scholar.google.com/scholar?cites=5398457185323160842&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Fisher Vectors Meet Neural Networks: A Hybrid Classification Architecture", "url": "http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_044.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=13605156542833141736&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "F Perronnin, D Larlus - Proceedings of the IEEE Conference on  \u2026", "excerpt": "Abstract Fisher Vectors (FV) and Convolutional Neural Networks (CNN) are two image classification pipelines with different strengths. While CNNs have shown superior accuracy on a number of classification tasks, FV classifiers are typically less costly to train and  ...", "url_pdf": "http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_044.pdf", "num_citations": 2, "cluster_id": "13605156542833141736", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=13605156542833141736&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Multi-Layer Support Vector Machines", "url": "http://scholar.google.com/https://books.google.com/books?hl=en&lr=&id=5Y_SBQAAQBAJ&oi=fnd&pg=PA457&ots=nwDrvasKyk&sig=xi8JhTmUNgBBYbg6yt3mQVXk34o", "url_versions": "http://scholar.google.com/scholar?cluster=2404654459639812631&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "MA Wiering, LRB Schomaker - \u2026 , Optimization, Kernels, and  \u2026", "excerpt": "Support vector machines (SVMs)[24, 8, 20, 22] and other learning algorithms based on kernels have been shown to obtain very good results on many different classification and regression datasets. SVMs have the advantage of generalizing very well, but the standard  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "2404654459639812631", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=2404654459639812631&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "A provably efficient algorithm for training deep networks", "url": "http://deeplearning.cs.cmu.edu/pdfs/1111/livni_provablyefficient.pdf", "url_versions": null, "authors": "R Livni, S Shalev-Shwartz\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract We consider deep neural networks (formally equivalent to sum-product networks [19]), in which the output of each node is a quadratic function of its inputs. Similar to other deep architectures, these networks can compactly represent any function on a finite  ...", "url_pdf": "http://deeplearning.cs.cmu.edu/pdfs/1111/livni_provablyefficient.pdf", "num_citations": 4, "cluster_id": "16573379337297918618", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=16573379337297918618&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Simnets: A generalization of convolutional networks", "url": "http://arxiv.org/abs/1410.0781", "url_versions": "http://scholar.google.com/scholar?cluster=3966216223457998753&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "N Cohen, A Shashua - arXiv preprint arXiv:1410.0781", "excerpt": "Abstract: We present a deep layered architecture that generalizes classical convolutional neural networks (ConvNets). The architecture, called SimNets, is driven by two operators, one being a similarity function whose family contains the convolution operator used in  ...", "url_pdf": null, "num_citations": 4, "cluster_id": "3966216223457998753", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=3966216223457998753&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Deep Fried Convnets", "url": "http://arxiv.org/abs/1412.7149", "url_versions": "http://scholar.google.com/scholar?cluster=11530585236220463260&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Z Yang, M Moczulski, M Denil, N de Freitas\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: The fully connected layers of a deep convolutional neural network typically contain over 90% of the network parameters, and consume the majority of the memory required to store the network parameters. Reducing the number of parameters while preserving  ...", "url_pdf": null, "num_citations": 4, "cluster_id": "11530585236220463260", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=11530585236220463260&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Deep Multiple Kernel Learning", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6784654", "url_versions": "http://scholar.google.com/scholar?cluster=3864317265086992162&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "EV Strobl, S Visweswaran - Machine Learning and Applications \u2026", "excerpt": "Abstract\u2014Deep learning methods have predominantly been applied to large artificial neural networks. Despite their state-ofthe-art performance, these large networks typically do not generalize well to datasets with limited sample sizes. In this paper, we take a different  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "3864317265086992162", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=3864317265086992162&as_sdt=2005&sciodt=1,5&hl=en"}]