[{"num_versions": 0, "url_citation": null, "title": "Asynchronous Parallel Stochastic Gradient for Nonconvex Optimization", "url": "http://arxiv.org/abs/1506.08272", "url_versions": null, "authors": "X Lian, Y Huang, Y Li, J Liu - arXiv preprint arXiv:1506.08272", "excerpt": "Abstract: Asynchronous parallel implementations of stochastic gradient (SG) have been broadly used in solving deep neural network and received many successes in practice recently. However, existing theories cannot explain their convergence and speedup  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "14750704835510307295", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=14750704835510307295&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "MALT: distributed data-parallelism for existing ML applications", "url": "http://dl.acm.org/citation.cfm?id=2741965", "url_versions": "http://scholar.google.com/scholar?cluster=16544884497804419730&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "H Li, A Kadav, E Kruus, C Ungureanu - Proceedings of the Tenth  \u2026", "excerpt": "Abstract Machine learning methods, such as SVM and neural networks, often improve their accuracy by using models with more parameters trained on large numbers of examples. Building such models on a single machine is often impractical because of the large  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "16544884497804419730", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=16544884497804419730&as_sdt=2005&sciodt=1,5&hl=en"}]