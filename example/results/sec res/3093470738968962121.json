[{"num_versions": 0, "url_citation": null, "title": "Speaker adaptation of hybrid NN/HMM model for speech recognition based on singular value decomposition", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6936583", "url_versions": null, "authors": "S Xue, H Jiang, L Dai - Chinese Spoken Language Processing  \u2026", "excerpt": "Abstract Recently several speaker adaptation methods have been proposed for deep neural network (DNN) in many large vocabulary continuous speech recognition (LVCSR) tasks. However, only a few methods rely on tuning the weight matrices in trained DNNs to  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "3085596359557733036", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=3085596359557733036&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Understanding image representations by measuring their equivariance and equivalence", "url": "http://arxiv.org/abs/1411.5908", "url_versions": "http://scholar.google.com/scholar?cluster=9059309894513410492&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "K Lenc, A Vedaldi - arXiv preprint arXiv:1411.5908", "excerpt": "Abstract: Despite the importance of image representations such as histograms of oriented gradients and deep Convolutional Neural Networks (CNN), our theoretical understanding of them remains limited. Aiming at filling this gap, we investigate three key mathematical  ...", "url_pdf": null, "num_citations": 8, "cluster_id": "9059309894513410492", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=9059309894513410492&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Flattened Convolutional Neural Networks for Feedforward Acceleration", "url": "http://arxiv.org/abs/1412.5474", "url_versions": "http://scholar.google.com/scholar?cluster=7847245353859028508&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Jin, A Dundar, E Culurciello - arXiv preprint arXiv:1412.5474", "excerpt": "Abstract: We present flattened convolutional neural networks that are designed for fast feedforward execution. The redundancy of the parameters, especially weights of the convolutional filters in convolutional neural networks has been extensively studied and  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "7847245353859028508", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=7847245353859028508&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Learning both Weights and Connections for Efficient Neural Networks", "url": "http://arxiv.org/abs/1506.02626", "url_versions": null, "authors": "S Han, J Pool, J Tran, WJ Dally - arXiv preprint arXiv:1506.02626", "excerpt": "Abstract: Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems. Also, conventional networks fix the architecture before training starts; as a result, training cannot improve the architecture. To  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "3024080172411649140", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=3024080172411649140&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Supervised Speech Separation Using Deep Neural Networks", "url": "http://scholar.google.com/https://etd.ohiolink.edu/%21etd.send_file?accession=osu1426366690&disposition=inline", "url_versions": "http://scholar.google.com/scholar?cluster=7741244194449769025&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Y Wang -", "excerpt": "ABSTRACT Speech is crucial for human communication. However, speech communication for both humans and automatic devices can be negatively impacted by background noise, which is common in real environments. Due to numerous applications, such as hearing  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "7741244194449769025", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=7741244194449769025&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Deep Fried Convnets", "url": "http://arxiv.org/abs/1412.7149", "url_versions": "http://scholar.google.com/scholar?cluster=11530585236220463260&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Z Yang, M Moczulski, M Denil, N de Freitas\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: The fully connected layers of a deep convolutional neural network typically contain over 90% of the network parameters, and consume the majority of the memory required to store the network parameters. Reducing the number of parameters while preserving  ...", "url_pdf": null, "num_citations": 4, "cluster_id": "11530585236220463260", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=11530585236220463260&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Compressing Neural Networks with the Hashing Trick", "url": "http://arxiv.org/abs/1504.04788", "url_versions": "http://scholar.google.com/scholar?cluster=5053947540904220409&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "W Chen, JT Wilson, S Tyree, KQ Weinberger\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: As deep nets are increasingly used in applications suited for mobile devices, a fundamental dilemma becomes apparent: the trend in deep learning is to grow models to absorb ever-increasing data set sizes; however mobile devices are designed with very  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "5053947540904220409", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=5053947540904220409&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Exploiting linear structure within convolutional networks for efficient evaluation", "url": "http://papers.nips.cc/paper/5544-bayesian-inference-for-structured-spike-and-slab-priors", "url_versions": "http://scholar.google.com/scholar?cluster=11064922358338176957&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "EL Denton, W Zaremba, J Bruna, Y LeCun\u2026 - Advances in Neural  \u2026", "excerpt": "Abstract We present techniques for speeding up the test-time evaluation of large convolutional networks, designed for object recognition tasks. These models deliver impressive accuracy, but each image evaluation requires millions of floating point  ...", "url_pdf": null, "num_citations": 32, "cluster_id": "11064922358338176957", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=11064922358338176957&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Unsupervised speaker adaptation of deep neural network based on the combination of speaker codes and singular value decomposition for speech recognition", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7178833", "url_versions": null, "authors": "S Xue, H Jiang, L Dai, Q Liu - Acoustics, Speech and Signal  \u2026", "excerpt": "ABSTRACT Recently, we have proposed a general adaptation scheme for deep neural network based on discriminant condition codes and applied it to supervised speaker adaptation in speech recognition based on either frame-level cross-entropy or sequence- ...", "url_pdf": null, "num_citations": 0, "cluster_id": null, "year": "2015", "url_citations": null}, {"num_versions": 10, "url_citation": null, "title": "Speeding up convolutional neural networks with low rank expansions", "url": "http://arxiv.org/abs/1405.3866", "url_versions": "http://scholar.google.com/scholar?cluster=15310264930290197418&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "M Jaderberg, A Vedaldi, A Zisserman - arXiv preprint arXiv:1405.3866", "excerpt": "Abstract: The focus of this paper is speeding up the evaluation of convolutional neural networks. While delivering impressive results across a range of computer vision and machine learning tasks, these networks are computationally demanding, limiting their  ...", "url_pdf": null, "num_citations": 27, "cluster_id": "15310264930290197418", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=15310264930290197418&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Learning Separable Filters", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6866160", "url_versions": "http://scholar.google.com/scholar?cluster=17772197639926832438&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "A Sironi, B Tekin, R Rigamonti\u2026 - Pattern Analysis and  \u2026", "excerpt": "Abstract\u2014Learning filters to produce sparse image representations in terms of overcomplete dictionaries has emerged as a powerful way to create image features for many different purposes. Unfortunately, these filters are usually both numerous and non-separable,  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "17772197639926832438", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=17772197639926832438&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 9, "url_citation": null, "title": "The loss surface of multilayer networks", "url": "http://arxiv.org/abs/1412.0233", "url_versions": "http://scholar.google.com/scholar?cluster=338235050395741201&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "A Choromanska, M Henaff, M Mathieu\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: We study the connection between the highly non-convex loss function of a simple model of the fully-connected feed-forward neural network and the Hamiltonian of the spherical spin-glass model under the assumptions of: i) variable independence, ii)  ...", "url_pdf": null, "num_citations": 13, "cluster_id": "338235050395741201", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=338235050395741201&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Compressing Deep Convolutional Networks using Vector Quantization", "url": "http://arxiv.org/abs/1412.6115", "url_versions": "http://scholar.google.com/scholar?cluster=17979567864307915708&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Y Gong, L Liu, M Yang, L Bourdev - arXiv preprint arXiv:1412.6115", "excerpt": "Abstract: Deep convolutional neural networks (CNN) has become the most promising method for object recognition, repeatedly demonstrating record breaking results for image classification and object detection in recent years. However, a very deep CNN generally  ...", "url_pdf": null, "num_citations": 8, "cluster_id": "17979567864307915708", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=17979567864307915708&as_sdt=2005&sciodt=1,5&hl=en"}]