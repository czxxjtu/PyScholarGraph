[{"num_versions": 3, "url_citation": null, "title": "Bounding the test log-likelihood of generative models", "url": "http://arxiv.org/abs/1311.6184", "url_versions": "http://scholar.google.com/scholar?cluster=18017364576419179310&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Y Bengio, L Yao, K Cho - arXiv preprint arXiv:1311.6184", "excerpt": "Abstract: Several interesting generative learning algorithms involve a complex probability distribution over many random variables, involving intractable normalization constants or latent variable normalization. Some of them may even not have an analytic expression for  ...", "url_pdf": null, "num_citations": 11, "cluster_id": "18017364576419179310", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=18017364576419179310&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Algorithmes d'apprentissage profonds supervis\u00e9s et non-supervis\u00e9s: applications et r\u00e9sultats th\u00e9oriques", "url": "http://scholar.google.com/https://papyrus.bib.umontreal.ca/xmlui/handle/1866/10689", "url_versions": "http://scholar.google.com/scholar?cluster=2843024304991296233&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "E Thibodeau-Laufer -", "excerpt": "La liste des domaines touch\u00e9s par l'apprentissage machine s' allonge rapidement. Au fur et \u00e0 mesure que la quantit\u00e9 de donn\u00e9es disponibles augmente, le d\u00e9veloppement d'algorithmes d'apprentissage de plus en plus puissants est crucial. Ce m\u00e9moire est  ...", "url_pdf": null, "num_citations": 0, "cluster_id": null, "year": "2014", "url_citations": null}, {"num_versions": 10, "url_citation": null, "title": "Deep learning of representations: Looking forward", "url": "http://link.springer.com/chapter/10.1007/978-3-642-39593-2_1", "url_versions": "http://scholar.google.com/scholar?cluster=16988628068303769209&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Y Bengio - Statistical Language and Speech Processing", "excerpt": "Abstract Deep learning research aims at discovering learning algorithms that discover multiple levels of distributed representations, with higher levels representing more abstract concepts. Although the study of deep learning has already led to impressive theoretical  ...", "url_pdf": null, "num_citations": 86, "cluster_id": "16988628068303769209", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=16988628068303769209&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Exponentially Increasing the Capacity-to-Computation Ratio for Conditional Computation in Deep Learning", "url": "http://arxiv.org/abs/1406.7362", "url_versions": "http://scholar.google.com/scholar?cluster=16820048063789970549&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "K Cho, Y Bengio - arXiv preprint arXiv:1406.7362", "excerpt": "Abstract: Many state-of-the-art results obtained with deep networks are achieved with the largest models that could be trained, and if more computation power was available, we might be able to exploit much larger datasets in order to improve generalization ability.  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "16820048063789970549", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=16820048063789970549&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Techniques for learning binary stochastic feedforward neural networks", "url": "http://arxiv.org/abs/1406.2989", "url_versions": "http://scholar.google.com/scholar?cluster=12715165618838965768&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "T Raiko, M Berglund, G Alain, L Dinh - arXiv preprint arXiv:1406.2989", "excerpt": "Abstract: Stochastic binary hidden units in a multi-layer perceptron (MLP) network give at least three potential benefits when compared to deterministic MLP networks.(1) They allow to learn one-to-many type of mappings.(2) They can be used in structured prediction  ...", "url_pdf": null, "num_citations": 6, "cluster_id": "12715165618838965768", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=12715165618838965768&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Automatic Speech Recognition", "url": "http://link.springer.com/content/pdf/10.1007/978-1-4471-5779-3.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=15129453519639737983&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "D Yu, L Deng -", "excerpt": "Automatic Speech Recognition (ASR), which is aimed to enable natural human\u2013machine interaction, has been an intensive research area for decades. Many core technologies, such as Gaussian mixture models (GMMs), hidden Markov models (HMMs), mel-frequency  ...", "url_pdf": "http://link.springer.com/content/pdf/10.1007/978-1-4471-5779-3.pdf", "num_citations": 20, "cluster_id": "15129453519639737983", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=15129453519639737983&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "Learning Factored Representations in a Deep Mixture of Experts", "url": "http://arxiv.org/abs/1312.4314", "url_versions": "http://scholar.google.com/scholar?cluster=2362959377164101721&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "D Eigen, MA Ranzato, I Sutskever - arXiv preprint arXiv:1312.4314", "excerpt": "Abstract: Mixtures of Experts combine the outputs of several\" expert\" networks, each of which specializes in a different part of the input space. This is achieved by training a\" gating\" network that maps each input to a distribution over the experts. Such models show  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "2362959377164101721", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=2362959377164101721&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Recurrent neural networks and related models", "url": "http://link.springer.com/chapter/10.1007/978-1-4471-5779-3_13", "url_versions": null, "authors": "D Yu, L Deng - Automatic Speech Recognition", "excerpt": "Abstract A recurrent neural network (RNN) is a class of neural network models where many connections among its neurons form a directed cycle. This gives rise to the structure of internal states or memory in the RNN, endowing it with the dynamic temporal behavior not  ...", "url_pdf": null, "num_citations": 2, "cluster_id": "2000137079705205072", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=2000137079705205072&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Deep directed generative autoencoders", "url": "http://arxiv.org/abs/1410.0630", "url_versions": "http://scholar.google.com/scholar?cluster=13319270084514804160&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Ozair, Y Bengio - arXiv preprint arXiv:1410.0630", "excerpt": "Abstract: For discrete data, the likelihood $ P (x) $ can be rewritten exactly and parametrized into $ P (X= x)= P (X= x| H= f (x)) P (H= f (x)) $ if $ P (X| H) $ has enough capacity to put no probability mass on any $ x'$ for which $ f (x')\\ neq f (x) $, where $ f (\\ cdot) $ is a  ...", "url_pdf": null, "num_citations": 5, "cluster_id": "13319270084514804160", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=13319270084514804160&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 2, "url_citation": null, "title": "GSNs: Generative Stochastic Networks", "url": "http://arxiv.org/abs/1503.05571", "url_versions": "http://scholar.google.com/scholar?cluster=10321016676192835414&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "G Alain, Y Bengio, L Yao, J Yosinski\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: We introduce a novel training principle for probabilistic models that is an alternative to maximum likelihood. The proposed Generative Stochastic Networks (GSN) framework is based on learning the transition operator of a Markov chain whose stationary distribution  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "10321016676192835414", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=10321016676192835414&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 13, "url_citation": null, "title": "Deep generative stochastic networks trainable by backprop", "url": "http://arxiv.org/abs/1306.1091", "url_versions": "http://scholar.google.com/scholar?cluster=16609644497959987803&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Y Bengio, E Thibodeau-Laufer, G Alain\u2026 - arXiv preprint arXiv: \u2026", "excerpt": "Abstract: We introduce a novel training principle for probabilistic models that is an alternative to maximum likelihood. The proposed Generative Stochastic Networks (GSN) framework is based on learning the transition operator of a Markov chain whose stationary distribution  ...", "url_pdf": null, "num_citations": 72, "cluster_id": "16609644497959987803", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=16609644497959987803&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Describing Multimedia Content using Attention-based Encoder\u2013Decoder Networks", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7243334", "url_versions": null, "authors": "K Cho, A Courville, Y Bengio -", "excerpt": "Abstract\u2014Whereas deep neural networks were first mostly used for classification tasks, they are rapidly expanding in the realm of structured output problems, where the observed target is composed of multiple random variables that have a rich joint distribution, given the input ...", "url_pdf": null, "num_citations": 1, "cluster_id": "12875719958826891977", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=12875719958826891977&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 9, "url_citation": null, "title": "Efficient gradient-based inference through transformations between bayes nets and neural nets", "url": "http://arxiv.org/abs/1402.0480", "url_versions": "http://scholar.google.com/scholar?cluster=10247073116756532709&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "DP Kingma, M Welling - arXiv preprint arXiv:1402.0480", "excerpt": "Abstract: Hierarchical Bayesian networks and neural networks with stochastic hidden units are commonly perceived as two separate types of models. We show that either of these types of models can often be transformed into an instance of the other, by switching  ...", "url_pdf": null, "num_citations": 11, "cluster_id": "10247073116756532709", "year": "2014", "url_citations": "http://scholar.google.com/scholar?cites=10247073116756532709&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Training neural networks with implicit variance", "url": "http://link.springer.com/chapter/10.1007/978-3-642-42042-9_17", "url_versions": "http://scholar.google.com/scholar?cluster=15385472405567854054&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Bayer, C Osendorfer, S Urban\u2026 - Neural Information  \u2026", "excerpt": "Abstract We present a novel method to train predictive Gaussian distributions p (z| x) for regression problems with neural networks. While most approaches either ignore or explicitly model the variance as another response variable, it is trained implicitly in our case.  ...", "url_pdf": null, "num_citations": 3, "cluster_id": "15385472405567854054", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=15385472405567854054&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 0, "url_citation": null, "title": "Deep Learning", "url": "http://www.iro.umontreal.ca/%7Ebengioy/dlbook/front_matter.pdf", "url_versions": null, "authors": "Y Bengio, IJ Goodfellow, A Courville -", "excerpt": "2.1 Scalars, Vectors, Matrices and Tensors . . . . . . . . . . . . . . . . . . . 20 2.2 Multiplying Matrices and Vectors . . . . . . . . . . . . . . . . . . . . . . 22 2.3 Identity and Inverse Matrices . . . . . . . . . . . . . . . . . . . . . . . . 24 2.4 Linear Dependence, Span, and Rank . . . . . . . . . . . . . . . . . . . . 25 2.5 Norms . . . . . .  ... ", "url_pdf": "http://www.iro.umontreal.ca/%7Ebengioy/dlbook/front_matter.pdf", "num_citations": 14, "cluster_id": "12148644736204109944", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=12148644736204109944&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Understanding dropout: training multi-layer perceptrons with auxiliary independent stochastic neurons", "url": "http://link.springer.com/chapter/10.1007/978-3-642-42054-2_59", "url_versions": "http://scholar.google.com/scholar?cluster=3057498576713890562&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "KH Cho - Neural Information Processing", "excerpt": "Abstract In this paper, a simple, general method of adding auxiliary stochastic neurons to a multi-layer perceptron is proposed. It is shown that the proposed method is a generalization of recently successful methods of dropout [5], explicit noise injection [12, 3] and semantic  ...", "url_pdf": null, "num_citations": 1, "cluster_id": "3057498576713890562", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=3057498576713890562&as_sdt=2005&sciodt=1,5&hl=en"}]