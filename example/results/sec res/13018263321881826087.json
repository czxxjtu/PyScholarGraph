[{"num_versions": 7, "url_citation": null, "title": "Better Representations: Invariant, Disentangled and Reusable", "url": "http://link.springer.com/chapter/10.1007/978-3-642-35289-8_29", "url_versions": "http://scholar.google.com/scholar?cluster=15569074998269429326&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "G Montavon, KR M\u00fcller -", "excerpt": "Preface In many cases, the amount of labeled data is limited and does not allow for fully identifying the function that needs to be learned. When labeled data is scarce, the learning algorithm is exposed to simultaneous underfitting and overfitting. The learning algorithm  ...", "url_pdf": null, "num_citations": 38, "cluster_id": "15569074998269429326", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=15569074998269429326&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 18, "url_citation": null, "title": "On the expressive power of deep architectures", "url": "http://link.springer.com/chapter/10.1007/978-3-642-24412-4_3", "url_versions": "http://scholar.google.com/scholar?cluster=3647764731908872051&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Y Bengio, O Delalleau - Algorithmic Learning Theory", "excerpt": "Abstract Deep architectures are families of functions corresponding to deep circuits. Deep Learning algorithms are based on parametrizing such circuits and tuning their parameters so as to approximately optimize some training objective. Whereas it was thought too  ...", "url_pdf": null, "num_citations": 59, "cluster_id": "3647764731908872051", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=3647764731908872051&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 9, "url_citation": null, "title": "Improved Bottleneck Features Using Pretrained Deep Neural Networks.", "url": "http://research.microsoft.com/pubs/153642/bottleneck-interspeech2011-pub.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=10630012346925912866&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "D Yu, ML Seltzer - INTERSPEECH", "excerpt": "Abstract Bottleneck features have been shown to be effective in improving the accuracy of automatic speech recognition (ASR) systems. Conventionally, bottleneck features are extracted from a multi-layer perceptron (MLP) trained to predict context-independent  ...", "url_pdf": "http://research.microsoft.com/pubs/153642/bottleneck-interspeech2011-pub.pdf", "num_citations": 96, "cluster_id": "10630012346925912866", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=10630012346925912866&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 13, "url_citation": null, "title": "On random weights and unsupervised feature learning", "url": "http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Saxe_551.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=2810915476760627169&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "A Saxe, PW Koh, Z Chen, M Bhand\u2026 - Proceedings of the  \u2026", "excerpt": "Abstract Recently two anomalous results in the literature have shown that certain feature learning architectures can yield useful features for object recognition tasks even with untrained, random weights. In this paper we pose the question: why do random weights  ...", "url_pdf": "http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Saxe_551.pdf", "num_citations": 111, "cluster_id": "2810915476760627169", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=2810915476760627169&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 15, "url_citation": null, "title": "Kernel methods for deep learning", "url": "http://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning", "url_versions": "http://scholar.google.com/scholar?cluster=13780742961636406443&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Y Cho, LK Saul - Advances in neural information processing systems", "excerpt": "Abstract We introduce a new family of positive-definite kernel functions that mimic the computation in large, multilayer neural nets. These kernel functions can be used in shallow architectures, such as support vector machines (SVMs), or in deep kernel-based  ...", "url_pdf": null, "num_citations": 55, "cluster_id": "13780742961636406443", "year": "2009", "url_citations": "http://scholar.google.com/scholar?cites=13780742961636406443&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 14, "url_citation": null, "title": "Real-time classification and sensor fusion with a spiking deep belief network", "url": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3792559/", "url_versions": "http://scholar.google.com/scholar?cluster=7776536154562292662&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "P O'Connor, D Neil, SC Liu, T Delbruck\u2026 - Frontiers in  \u2026", "excerpt": "Abstract Deep Belief Networks (DBNs) have recently shown impressive performance on a broad range of classification problems. Their generative properties allow better understanding of the performance, and provide a simpler solution for sensor fusion tasks.  ...", "url_pdf": null, "num_citations": 41, "cluster_id": "7776536154562292662", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=7776536154562292662&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 17, "url_citation": null, "title": "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion", "url": "http://dl.acm.org/citation.cfm?id=1953039", "url_versions": "http://scholar.google.com/scholar?cluster=13548556499559547747&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "P Vincent, H Larochelle, I Lajoie, Y Bengio\u2026 - The Journal of Machine \u2026", "excerpt": "Abstract We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoders which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of  ...", "url_pdf": null, "num_citations": 535, "cluster_id": "13548556499559547747", "year": "2010", "url_citations": "http://scholar.google.com/scholar?cites=13548556499559547747&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 23, "url_citation": null, "title": "Restricted Boltzmann machines are hard to approximately evaluate or simulate", "url": "http://machinelearning.wustl.edu/mlpapers/paper_files/icml2010_LongS10.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=16650437739542964828&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "PM Long, R Servedio - Proceedings of the 27th  \u2026", "excerpt": "Abstract Restricted Boltzmann Machines (RBMs) are a type of probability model over the Boolean cube {\u2212 1, 1} n that have recently received much attention. We establish the intractability of two basic computational tasks involving RBMs, even if only a coarse  ...", "url_pdf": "http://machinelearning.wustl.edu/mlpapers/paper_files/icml2010_LongS10.pdf", "num_citations": 20, "cluster_id": "16650437739542964828", "year": "2010", "url_citations": "http://scholar.google.com/scholar?cites=16650437739542964828&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 12, "url_citation": null, "title": "Learning algorithms for the classification restricted boltzmann machine", "url": "http://dl.acm.org/citation.cfm?id=2188407", "url_versions": "http://scholar.google.com/scholar?cluster=114088861233837212&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "H Larochelle, M Mandel, R Pascanu\u2026 - The Journal of Machine  \u2026", "excerpt": "Abstract Recent developments have demonstrated the capacity of restricted Boltzmann machines (RBM) to be powerful generative models, able to extract useful features from input data or construct deep artificial neural networks. In such settings, the RBM only yields a  ...", "url_pdf": null, "num_citations": 53, "cluster_id": "114088861233837212", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=114088861233837212&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 14, "url_citation": null, "title": "Tiled convolutional neural networks", "url": "http://papers.nips.cc/paper/4136-tiled-convolutional-neural-networks", "url_versions": "http://scholar.google.com/scholar?cluster=14282515616261813077&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Ngiam, Z Chen, D Chia, PW Koh, QV Le\u2026 - Advances in Neural  \u2026", "excerpt": "Abstract Convolutional neural networks (CNNs) have been successfully applied to many tasks such as digit and object recognition. Using convolutional (tied) weights signi\ufb01cantly reduces the number of parameters that have to be learned, and also allows translational  ...", "url_pdf": null, "num_citations": 103, "cluster_id": "14282515616261813077", "year": "2010", "url_citations": "http://scholar.google.com/scholar?cites=14282515616261813077&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Prediction as a candidate for learning deep hierarchical models of data", "url": "http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/6284/pdf/imm6284.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=15523961553761323777&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "RB Palm - Technical University of Denmark", "excerpt": "Abstract Recent findings [HOT06] have made possible the learning of deep layered hierarchical representations of data mimicking the brains working. It is hoped that this paradigm will unlock some of the power of the brain and lead to advances towards true AI.", "url_pdf": "http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/6284/pdf/imm6284.pdf", "num_citations": 80, "cluster_id": "15523961553761323777", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=15523961553761323777&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Deep architectures and deep learning in chemoinformatics: the prediction of aqueous solubility for drug-like molecules", "url": "http://pubs.acs.org/doi/abs/10.1021/ci400187y", "url_versions": "http://scholar.google.com/scholar?cluster=920429449933062031&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "A Lusci, G Pollastri, P Baldi - Journal of chemical information and  \u2026", "excerpt": "Shallow machine learning methods have been applied to chemoinformatics problems with some success. As more data becomes available and more complex problems are tackled, deep machine learning methods may also become useful. Here, we present a brief  ...", "url_pdf": null, "num_citations": 21, "cluster_id": "920429449933062031", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=920429449933062031&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 21, "url_citation": null, "title": "Deep belief networks using discriminative features for phone recognition", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5947494", "url_versions": "http://scholar.google.com/scholar?cluster=17626864473966847045&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "A Mohamed, TN Sainath, G Dahl\u2026 - \u2026 , Speech and Signal  \u2026", "excerpt": "ABSTRACT Deep Belief Networks (DBNs) are multi-layer generative models. They can be trained to model windows of coefficients extracted from speech and they discover multiple layers of features that capture the higher-order statistical structure of the data. These  ...", "url_pdf": null, "num_citations": 289, "cluster_id": "17626864473966847045", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=17626864473966847045&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 14, "url_citation": null, "title": "Deep learning in neural networks: An overview", "url": "http://www.sciencedirect.com/science/article/pii/S0893608014002135", "url_versions": "http://scholar.google.com/scholar?cluster=15932869302045479284&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Schmidhuber - Neural Networks", "excerpt": "Abstract In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow  ...", "url_pdf": null, "num_citations": 143, "cluster_id": "15932869302045479284", "year": "2015", "url_citations": "http://scholar.google.com/scholar?cites=15932869302045479284&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Roles of pre-training and fine-tuning in context-dependent DBN-HMMs for real-world speech recognition", "url": "http://www.msr-waypoint.com/pubs/143619/dbn4asr-nips2010.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=2085230840263552626&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "D Yu, L Deng, G Dahl - Proc. NIPS Workshop on Deep Learning  \u2026", "excerpt": "Abstract Recently, deep learning techniques have been successfully applied to automatic speech recognition tasks--first to phonetic recognition with context-independent deep belief network (DBN) hidden Markov models (HMMs) and later to large vocabulary continuous  ...", "url_pdf": "http://www.msr-waypoint.com/pubs/143619/dbn4asr-nips2010.pdf", "num_citations": 99, "cluster_id": "2085230840263552626", "year": "2010", "url_citations": "http://scholar.google.com/scholar?cites=2085230840263552626&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 11, "url_citation": null, "title": "Deep belief nets for natural language call-routing", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5947649", "url_versions": "http://scholar.google.com/scholar?cluster=15003765548951473858&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "R Sarikaya, GE Hinton\u2026 - Acoustics, Speech and  \u2026", "excerpt": "ABSTRACT This paper considers application of Deep Belief Nets (DBNs) to natural language call routing. DBNs have been successfully applied to a number of tasks, including image, audio and speech classification, thanks to the recent discovery of an efficient  ...", "url_pdf": null, "num_citations": 31, "cluster_id": "15003765548951473858", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=15003765548951473858&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Revisiting natural gradient for deep networks", "url": "http://arxiv.org/abs/1301.3584", "url_versions": "http://scholar.google.com/scholar?cluster=4887476036427842105&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "R Pascanu, Y Bengio - arXiv preprint arXiv:1301.3584", "excerpt": "Abstract: We evaluate natural gradient, an algorithm originally proposed in Amari (1997), for learning deep models. The contributions of this paper are as follows. We show the connection between natural gradient and three other recently proposed methods for  ...", "url_pdf": null, "num_citations": 30, "cluster_id": "4887476036427842105", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=4887476036427842105&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Understanding representations learned in deep architectures", "url": "http://www.iro.umontreal.ca/%7Elisa/pointeurs/invariances_techreport.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=8026134095191205003&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "D Erhan, A Courville, Y Bengio - Universit e de Montr eal/DIRO,  \u2026", "excerpt": "Abstract Deep architectures have demonstrated state-of-the-art performance in a variety of settings, especially with vision datasets. Deep learning algorithms are based on learning several levels of representation of the input. Beyond test-set performance, there is a need  ...", "url_pdf": "http://www.iro.umontreal.ca/%7Elisa/pointeurs/invariances_techreport.pdf", "num_citations": 24, "cluster_id": "8026134095191205003", "year": "2010", "url_citations": "http://scholar.google.com/scholar?cites=8026134095191205003&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Gaussian-bernoulli deep boltzmann machine", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6706831", "url_versions": "http://scholar.google.com/scholar?cluster=10356798405558013773&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "KH Cho, T Raiko, A Ilin - Neural Networks (IJCNN), The", "excerpt": "Gaussian-Bernoulli deep Boltzmann machine (GDBM) and discuss potential improvements in training the model. GDBM is designed to be applicable to continuous data and it is constructed from Gaussian-Bernoulli restricted Boltzmann machine (GRBM) by adding  ...", "url_pdf": null, "num_citations": 21, "cluster_id": "10356798405558013773", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=10356798405558013773&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Feature extraction with deep neural networks by a generalized discriminant analysis", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6149591", "url_versions": "http://scholar.google.com/scholar?cluster=16506148504778994727&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "A Stuhlsatz, J Lippel, T Zielke - Neural Networks and Learning  \u2026", "excerpt": "Abstract\u2014We present an approach to feature extraction that is a generalization of the classical linear discriminant analysis (LDA) on the basis of deep neural networks (DNNs). As for LDA, discriminative features generated from independent Gaussian class conditionals  ...", "url_pdf": null, "num_citations": 30, "cluster_id": "16506148504778994727", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=16506148504778994727&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "Enhanced gradient for training restricted Boltzmann machines", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6797339", "url_versions": "http://scholar.google.com/scholar?cluster=11663799906171406860&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "KH Cho, T Raiko, A Ilin - Neural computation", "excerpt": "Restricted Boltzmann machines (RBMs) are often used as building blocks in greedy learning of deep networks. However, training this simple model can be laborious. Traditional learning algorithms often converge only with the right choice of metaparameters that specify, for  ...", "url_pdf": null, "num_citations": 27, "cluster_id": "11663799906171406860", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=11663799906171406860&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Towards scaling up classification-based speech separation", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6473841", "url_versions": "http://scholar.google.com/scholar?cluster=220901135250906487&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Y Wang, DL Wang - Audio, Speech, and Language Processing, \u2026", "excerpt": "Abstract\u2014Formulating speech separation as a binary clas-sification problem has been shown to be effective. While good separation performance is achieved in matched test conditions using kernel support vector machines (SVMs), separation in unmatched  ...", "url_pdf": null, "num_citations": 73, "cluster_id": "220901135250906487", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=220901135250906487&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "Random search for hyper-parameter optimization", "url": "http://dl.acm.org/citation.cfm?id=2188395", "url_versions": "http://scholar.google.com/scholar?cluster=7473940110210462469&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Bergstra, Y Bengio - The Journal of Machine Learning Research", "excerpt": "Abstract Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid.  ...", "url_pdf": null, "num_citations": 324, "cluster_id": "7473940110210462469", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=7473940110210462469&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 10, "url_citation": null, "title": "Image denoising and inpainting with deep neural networks", "url": "http://papers.nips.cc/paper/4686-image-denoising-and-inpainting-with-deep-neural-networks", "url_versions": "http://scholar.google.com/scholar?cluster=6118112247085297920&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Xie, L Xu, E Chen - Advances in Neural Information Processing  \u2026", "excerpt": "Abstract We present a novel approach to low-level vision problems that combines sparse coding and deep networks pre-trained with denoising auto-encoder (DA). We propose an alternative training scheme that successfully adapts DA, originally designed for  ...", "url_pdf": null, "num_citations": 48, "cluster_id": "6118112247085297920", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=6118112247085297920&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 9, "url_citation": null, "title": "Deep learning via Hessian-free optimization", "url": "http://machinelearning.wustl.edu/mlpapers/paper_files/icml2010_Martens10.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=15502119379559163003&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Martens - \u2026  of the 27th International Conference on  \u2026", "excerpt": "Abstract We develop a 2nd-order optimization method based on the \u201cHessian-free\u201d approach, and apply it to training deep auto-encoders. Without using pre-training, we obtain results superior to those reported by Hinton & Salakhutdinov (2006) on the same tasks  ...", "url_pdf": "http://machinelearning.wustl.edu/mlpapers/paper_files/icml2010_Martens10.pdf", "num_citations": 212, "cluster_id": "15502119379559163003", "year": "2010", "url_citations": "http://scholar.google.com/scholar?cites=15502119379559163003&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "An overview of deep-structured learning for information processing", "url": "http://131.107.65.14/pubs/155609/DENG-APSIPA.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=1255369059227179273&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "L Deng - Proceedings of Asian-Pacific Signal & Information  \u2026", "excerpt": "Abstract\u2014In this paper, I will introduce to the APSIPA audience an emerging area of machine learning, deep-structured learning. It refers to a class of machine learning techniques, developed mostly since 2006, where many layers of information processing  ...", "url_pdf": "http://131.107.65.14/pubs/155609/DENG-APSIPA.pdf", "num_citations": 22, "cluster_id": "1255369059227179273", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=1255369059227179273&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 9, "url_citation": null, "title": "Unsupervised cross-lingual knowledge transfer in DNN-based LVCSR", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6424230", "url_versions": "http://scholar.google.com/scholar?cluster=6677741692555220574&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "P Swietojanski, A Ghoshal\u2026 - \u2026  Workshop (SLT)", "excerpt": "ABSTRACT We investigate the use of cross-lingual acoustic data to initialise deep neural network (DNN) acoustic models by means of unsupervised restricted Boltzmann machine (RBM) pretraining. DNNs for German are pretrained using one or all of German,  ...", "url_pdf": null, "num_citations": 46, "cluster_id": "6677741692555220574", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=6677741692555220574&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 13, "url_citation": null, "title": "Learning speaker-specific characteristics with a deep neural architecture", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6026951", "url_versions": "http://scholar.google.com/scholar?cluster=10989193960928354096&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "K Chen, A Salman - Neural Networks, IEEE Transactions on", "excerpt": "Abstract\u2014Speech signals convey various yet mixed informa-tion ranging from linguistic to speaker-specific information. However, most of acoustic representations characterize all different kinds of information as whole, which could hinder either a speech or a speaker  ...", "url_pdf": null, "num_citations": 27, "cluster_id": "10989193960928354096", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=10989193960928354096&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 5, "url_citation": null, "title": "Deep neural network features and semi-supervised training for low resource speech recognition", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6638959", "url_versions": "http://scholar.google.com/scholar?cluster=8450207791195783413&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Thomas, ML Seltzer, K Church\u2026 - Acoustics, Speech and \u2026", "excerpt": "ABSTRACT We propose a new technique for training deep neural networks (DNNs) as data-driven feature front-ends for large vocabulary continuous speech recognition (LVCSR) in low resource settings. To circumvent the lack of sufficient training data for acoustic  ...", "url_pdf": null, "num_citations": 24, "cluster_id": "8450207791195783413", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=8450207791195783413&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Knowledge matters: Importance of prior information for optimization", "url": "http://arxiv.org/abs/1301.4083", "url_versions": "http://scholar.google.com/scholar?cluster=16555444433184520296&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "\u00c7 G\u00fcl\u00e7ehre, Y Bengio - arXiv preprint arXiv:1301.4083", "excerpt": "Abstract: We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans  ...", "url_pdf": null, "num_citations": 19, "cluster_id": "16555444433184520296", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=16555444433184520296&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Transfer learning for Latin and Chinese characters with deep neural networks", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6252544", "url_versions": "http://scholar.google.com/scholar?cluster=7452424507909578812&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "DC Cire\u015fan, U Meier\u2026 - Neural Networks (IJCNN),  \u2026", "excerpt": "Abstract\u2014We analyze transfer learning with Deep Neural Networks (DNN) on various character recognition tasks. DNN trained on digits are perfectly capable of recognizing uppercase letters with minimal retraining. They are on par with DNN fully trained on  ...", "url_pdf": null, "num_citations": 29, "cluster_id": "7452424507909578812", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=7452424507909578812&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 15, "url_citation": null, "title": "Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5740583", "url_versions": "http://scholar.google.com/scholar?cluster=1536831630272977838&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "GE Dahl, D Yu, L Deng, A Acero - Audio, Speech, and  \u2026", "excerpt": "Abstract\u2014We propose a novel context-dependent (CD) model for large-vocabulary speech recognition (LVSR) that leverages recent advances in using deep belief networks for phone recognition. We describe a pre-trained deep neural network hidden Markov model (DNN- ...", "url_pdf": null, "num_citations": 739, "cluster_id": "1536831630272977838", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=1536831630272977838&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 33, "url_citation": null, "title": "Representation learning: A review and new perspectives", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6472238", "url_versions": "http://scholar.google.com/scholar?cluster=559463397382443088&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Y Bengio, A Courville, P Vincent - Pattern Analysis and  \u2026", "excerpt": "Abstract\u2014The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the  ...", "url_pdf": null, "num_citations": 685, "cluster_id": "559463397382443088", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=559463397382443088&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 12, "url_citation": null, "title": "Stacked convolutional auto-encoders for hierarchical feature extraction", "url": "http://link.springer.com/chapter/10.1007/978-3-642-21735-7_7", "url_versions": "http://scholar.google.com/scholar?cluster=3821637361680157370&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "J Masci, U Meier, D Cire\u015fan, J Schmidhuber - Artificial Neural Networks  \u2026", "excerpt": "Abstract We present a novel convolutional auto-encoder (CAE) for unsupervised feature learning. A stack of CAEs forms a convolutional neural network (CNN). Each CAE is trained using conventional on-line gradient descent without additional regularization terms. A max ...", "url_pdf": null, "num_citations": 52, "cluster_id": "3821637361680157370", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=3821637361680157370&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 15, "url_citation": null, "title": "Autoencoders, unsupervised learning, and deep architectures", "url": "http://ww.mtome.com/Publications/CiML/CiML-v7-book.pdf#page=53", "url_versions": "http://scholar.google.com/scholar?cluster=8658082583446518784&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "P Baldi - Unsupervised and Transfer Learning Challenges in  \u2026", "excerpt": "Abstract Autoencoders play a fundamental role in unsupervised learning and in deep architectures for transfer learning and other tasks. In spite of their fundamental role, only linear autoencoders over the real numbers have been solved analytically. Here we  ...", "url_pdf": null, "num_citations": 40, "cluster_id": "8658082583446518784", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=8658082583446518784&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Deep belief networks based voice activity detection", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6362186", "url_versions": "http://scholar.google.com/scholar?cluster=14664371952535429034&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "XL Zhang, J Wu - Audio, Speech, and Language Processing,  \u2026", "excerpt": "Abstract Fusing the advantages of multiple acoustic features is important for the robustness of voice activity detection (VAD). Recently, the machine-learning-based VADs have shown a superiority to traditional VADs on multiple feature fusion tasks. However, existing machine ...", "url_pdf": null, "num_citations": 51, "cluster_id": "14664371952535429034", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=14664371952535429034&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "Modeling mutual visibility relationship in pedestrian detection", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6619258", "url_versions": "http://scholar.google.com/scholar?cluster=3066194108872458567&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "W Ouyang, X Zeng, X Wang - Computer Vision and Pattern  \u2026", "excerpt": "Abstract Detecting pedestrians in cluttered scenes is a challenging problem in computer vision. The difficulty is added when several pedestrians overlap in images and occlude each other. We observe, however, that the occlusion/visibility statuses of overlapping  ...", "url_pdf": null, "num_citations": 38, "cluster_id": "3066194108872458567", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=3066194108872458567&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 9, "url_citation": null, "title": "The manifold tangent classifier", "url": "http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2011_1240.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=8931227741868367171&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "S Rifai, YN Dauphin, P Vincent\u2026 - Advances in  \u2026", "excerpt": "Abstract We combine three important ideas present in previous work for building classifiers: the semi-supervised hypothesis (the input distribution contains information about the classifier), the unsupervised manifold hypothesis (data density concentrates near low- ...", "url_pdf": "http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2011_1240.pdf", "num_citations": 66, "cluster_id": "8931227741868367171", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=8931227741868367171&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 3, "url_citation": null, "title": "Big neural networks waste capacity", "url": "http://arxiv.org/abs/1301.3583", "url_versions": "http://scholar.google.com/scholar?cluster=15203864254754138120&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "YN Dauphin, Y Bengio - arXiv preprint arXiv:1301.3583", "excerpt": "Abstract: This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting. Past research suggest diminishing returns when increasing the size of neural networks. Our experiments on ImageNet LSVRC-2010 show that this  ...", "url_pdf": null, "num_citations": 26, "cluster_id": "15203864254754138120", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=15203864254754138120&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 19, "url_citation": null, "title": "Krylov subspace descent for deep learning", "url": "http://arxiv.org/abs/1111.4259", "url_versions": "http://scholar.google.com/scholar?cluster=9397394098242250506&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "O Vinyals, D Povey - arXiv preprint arXiv:1111.4259", "excerpt": "Abstract: In this paper, we propose a second order optimization method to learn models where both the dimensionality of the parameter space and the number of training samples is high. In our method, we construct on each iteration a Krylov subspace formed by the  ...", "url_pdf": null, "num_citations": 33, "cluster_id": "9397394098242250506", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=9397394098242250506&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 4, "url_citation": null, "title": "Advances in optimizing recurrent networks", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6639349", "url_versions": "http://scholar.google.com/scholar?cluster=56668020054253477&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Y Bengio, N Boulanger-Lewandowski\u2026 - \u2026 , Speech and Signal  \u2026", "excerpt": "ABSTRACT After a more than decade-long period of relatively little research activity in the area of recurrent neural networks, several new developments will be reviewed here that have allowed substantial progress both in understanding and in technical solutions  ...", "url_pdf": null, "num_citations": 54, "cluster_id": "56668020054253477", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=56668020054253477&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 23, "url_citation": null, "title": "Multi-column deep neural networks for image classification", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6248110", "url_versions": "http://scholar.google.com/scholar?cluster=17557578126851891884&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "D Ciresan, U Meier\u2026 - Computer Vision and  \u2026", "excerpt": "Abstract Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs. Our biologically plausible, wide and deep artificial neural network architectures can. Small ( ...", "url_pdf": null, "num_citations": 480, "cluster_id": "17557578126851891884", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=17557578126851891884&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Practical recommendations for gradient-based training of deep architectures", "url": "http://link.springer.com/chapter/10.1007/978-3-642-35289-8_26", "url_versions": "http://scholar.google.com/scholar?cluster=13214514639523956782&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "Y Bengio - Neural Networks: Tricks of the Trade", "excerpt": "Abstract Learning algorithms related to artificial neural networks and in particular for Deep Learning may seem to involve many bells and whistles, called hyper-parameters. This chapter is meant as a practical guide with recommendations for some of the most  ...", "url_pdf": null, "num_citations": 91, "cluster_id": "13214514639523956782", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=13214514639523956782&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 16, "url_citation": null, "title": "Deep sparse rectifier neural networks", "url": "http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_GlorotBB11.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=10040883758431450991&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "X Glorot, A Bordes, Y Bengio - International  \u2026", "excerpt": "Abstract While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield  ...", "url_pdf": "http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_GlorotBB11.pdf", "num_citations": 275, "cluster_id": "10040883758431450991", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=10040883758431450991&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 14, "url_citation": null, "title": "A connection between score matching and denoising autoencoders", "url": "http://www.mitpressjournals.org/doi/abs/10.1162/neco_a_00142", "url_versions": "http://scholar.google.com/scholar?cluster=11530775616703258262&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "P Vincent - Neural computation", "excerpt": "Denoising autoencoders have been previously shown to be competitive alternatives to restricted Boltzmann machines for unsupervised pretraining of each layer of a deep architecture. We show that a simple denoising autoencoder training criterion is equivalent  ...", "url_pdf": null, "num_citations": 57, "cluster_id": "11530775616703258262", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=11530775616703258262&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 7, "url_citation": null, "title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "url": "http://arxiv.org/abs/1312.6120", "url_versions": "http://scholar.google.com/scholar?cluster=9090095758382098911&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "AM Saxe, JL McClelland, S Ganguli - arXiv preprint arXiv:1312.6120", "excerpt": "Abstract: Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by  ...", "url_pdf": null, "num_citations": 31, "cluster_id": "9090095758382098911", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=9090095758382098911&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 22, "url_citation": null, "title": "Visualizing non-metric similarities in multiple maps", "url": "http://link.springer.com/article/10.1007/s10994-011-5273-4", "url_versions": "http://scholar.google.com/scholar?cluster=3783740809840469918&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "L Van der Maaten, G Hinton - Machine learning", "excerpt": "Abstract Techniques for multidimensional scaling visualize objects as points in a low-dimensional metric map. As a result, the visualizations are subject to the fundamental limitations of metric spaces. These limitations prevent multidimensional scaling from  ...", "url_pdf": null, "num_citations": 23, "cluster_id": "3783740809840469918", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=3783740809840469918&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 8, "url_citation": null, "title": "The hierarchical beta process for convolutional factor analysis and deep learning", "url": "http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Chen_251.pdf", "url_versions": "http://scholar.google.com/scholar?cluster=6798646340201925463&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "B Chen, G Polatkan, G Sapiro\u2026 - Proceedings of the  \u2026", "excerpt": "Abstract A convolutional factor-analysis model is developed, with the number of filters (factors) inferred via the beta process (BP) and hierarchical BP, for single-task and multi-task learning, respectively. The computation of the model parameters is implemented within a  ...", "url_pdf": "http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Chen_251.pdf", "num_citations": 19, "cluster_id": "6798646340201925463", "year": "2011", "url_citations": "http://scholar.google.com/scholar?cites=6798646340201925463&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 13, "url_citation": null, "title": "Deep gaussian processes", "url": "http://arxiv.org/abs/1211.0358", "url_versions": "http://scholar.google.com/scholar?cluster=4442302240700999572&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "AC Damianou, ND Lawrence - arXiv preprint arXiv:1211.0358", "excerpt": "Abstract: In this paper we introduce deep Gaussian process (GP) models. Deep GPs are a deep belief network based on Gaussian process mappings. The data is modeled as the output of a multivariate GP. The inputs to that Gaussian process are then governed by  ...", "url_pdf": null, "num_citations": 41, "cluster_id": "4442302240700999572", "year": "2012", "url_citations": "http://scholar.google.com/scholar?cites=4442302240700999572&as_sdt=2005&sciodt=1,5&hl=en"}, {"num_versions": 6, "url_citation": null, "title": "Multi-stage contextual deep learning for pedestrian detection", "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6751124", "url_versions": "http://scholar.google.com/scholar?cluster=14207808099969801710&hl=en&as_sdt=1,5&sciodt=1,5&as_vis=1", "authors": "X Zeng, W Ouyang, X Wang - Computer Vision (ICCV)", "excerpt": "Abstract Cascaded classifiers1 have been widely used in pedestrian detection and achieved great success. These classifiers are trained sequentially without joint optimization. In this paper, we propose a new deep model that can jointly train multi-stage classifiers through  ...", "url_pdf": null, "num_citations": 29, "cluster_id": "14207808099969801710", "year": "2013", "url_citations": "http://scholar.google.com/scholar?cites=14207808099969801710&as_sdt=2005&sciodt=1,5&hl=en"}]